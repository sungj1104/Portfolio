{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90263c24",
   "metadata": {},
   "source": [
    "# LLM 개념\n",
    "\n",
    "- 인공지능의 한 분야로, 대규모 데이터로 학습한 결과를 이용해서 인간의 언어를 처리하고, 생성하며, 맥락을 이해하는데 사용됨\n",
    "- Large Language Model의 약자\n",
    "    - 인간의 언어를 처리하는 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8799c38",
   "metadata": {},
   "source": [
    "## 언어 모델(Language Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862ee8a7",
   "metadata": {},
   "source": [
    "### 통계적 언어 모델\n",
    "\n",
    "- 초기의 언어 모델\n",
    "    - 통계적 방법에 기반\n",
    "    - 컴퓨터가 문장이나 단어를 얼마나 자연스럽게 표현할지를 수학적으로 계산\n",
    "\n",
    "- 언어 모델에서 사용하는 확률/통계적 방법 : n-gram\n",
    "    - 언어의 통계적 패턴을 학습해서 문장을 이해하고 새로운 문장을 만들어 내는 데에 도움을 줌\n",
    "    - 단점\n",
    "        - 가능한 모든 n-gram을 데이터베이스에 저장하고 있어야 하므로 데이터베이스를 사전에 만들어 두어야 함\n",
    "        - n이 커질수록 문맥을 제대로 이해하지 못하는 경우가 많음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb423887",
   "metadata": {},
   "source": [
    "### 신경망 언어 모델\n",
    "\n",
    "- 신경망을 기반으로 하는 언어 모델\n",
    "    - 머신러닝의 발전으로 등장\n",
    "    - RNN\n",
    "        - 과거의 정보가 현재의 결정에 영향을 미침\n",
    "        - 번역, 주식 가격, 날씨 변화 등 시간에 따라 변화하는 데이터를 분석하여 미래를 예측\n",
    "        - 과거의 데이터를 저장하기 위한 공간이 작기 때문에 매우 긴 데이터를 처리하기에는 부적합\n",
    "        \n",
    "    - LSTM\n",
    "        - RNN의 한계를 극복하기 위해 고안된 모델\n",
    "        - 긴 시퀀스 정보를 기억하고 필요에 따라 삭제하거나 업데이트 할 수 있는 메커니즘을 가지고 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882357c1",
   "metadata": {},
   "source": [
    "### 트랜스포머\n",
    "\n",
    "- 2017년 구글 브레인(Google Brain)에서 발표한 논문 Attention Is All You Need 에서 트랜스포머 아키텍처가 도입\n",
    "- 이전의 언어 모델은 각 단어를 개별적으로 이해하고 처리하는 데 중점\n",
    "    - 트랜스포머는 문장과 단락 전체를 처리\n",
    "    - 자연어에서 인간의 의도를 심층적이고 맥락에 맞게 이해할 수 있게 되었음\n",
    "        - 텍스트 생성, 문장 요약 등 활용 범위가 넓어짐\n",
    "        \n",
    "- 트랜스포머를 이용한 대표적인 모델들\n",
    "    - 버트(Bidirectional Encoder Representations form Transformers, BERT)\n",
    "        - 텍스트를 양방향으로 분석하여 맥락을 이해하는 언어 모델\n",
    "        - 언어 모델이 단어의 앞 뒤 문맥을 모두 고려하여 그 단어의 의미를 이해\n",
    "            - 이전까지의 언어모델은 주로 한 방향으로만 문맥을 이해하고 다음 단어를 예측\n",
    "            - 실제 인간의 언어는 전체적인 문장의 맥락을 통해 이루어지므로, 양방향으로 문맥을 이해하는 것이 자연스러움\n",
    "            \n",
    "    - GPT(Generative Pretrained Transformer)\n",
    "        - 오픈AI에 의해 개발된 인간의 언어를 처리하는 인공지능 언어 모델\n",
    "        - 2018년 처음으로 GPT-1 모델을 발표\n",
    "        - 2022년 ChatGPT 발표\n",
    "        - 2023년 GPT-4 모델을 발표\n",
    "        - 다른 언어 모델에 비해 자연스러운 텍스트 생성 및 높은 수준의 대화로 각광받고 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0493642",
   "metadata": {},
   "source": [
    "# 거대 언어 모델(Large Language Model)\n",
    "\n",
    "- 대규모 데이터로 훈련된, 매우 큰 규모의 인공지능 기반 언어 모델\n",
    "    - 예) GPT-3 모델을 학습할 때 학습 데이터의 크기 : 45TB\n",
    "    - 많은 양의 데이터를 학습했다고 해서 모두 거대 언어 모델이라고 이름 붙일 수는 없음\n",
    "        - 모델의 크기도 커야 함(모델 파라미터의 수)\n",
    "        - GPT-3의 파라미터 수 : 약 1,750억 개\n",
    "        - GPT-2의 파라미터 수 : 약 15억 개\n",
    "        - 모델의 파라미터 수가 증가할수록 모델의 이해력과 텍스트 생성 능력이 크게 향상됨        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1047eb9a",
   "metadata": {},
   "source": [
    "# LLM 특징\n",
    "\n",
    "- 텍스트, 책, 논문, 기사 등 다양하고 방대한 양의 텍스트 데이터 학습\n",
    "\n",
    "- 언어를 이해하고 생성하는 데 특화\n",
    "    - 질의응답, 글 작성, 대화(챗봇) 등의 생성적 작업을 자연스러운 언어로 수행 가능\n",
    "    \n",
    "- 특정 작업을 위해 파인튜닝할 수 있음\n",
    "    - 파인튜닝 : 챗GPT와 같은 언어모델을 기업의 데이터로 추가 학습을 시키는 과정\n",
    "        - 특화된 분야에 더욱 정교하게 사용할 수 있음\n",
    "        \n",
    "- 모델 훈련과 운영에 상당한 컴퓨팅 자원이 필요\n",
    "    - 주로 GPU나 TPU 같은 하드웨어를 말함\n",
    "    \n",
    "- LLM의 예\n",
    "    - GPT-3.5 Turbo\n",
    "    - GPT-4\n",
    "    - BERT\n",
    "    - Gemini(제미나이)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3e8b9d",
   "metadata": {},
   "source": [
    "# LLM 활용\n",
    "\n",
    "- 학습이 완료된 모델을 챗봇 같은 서비스에서 API를 가져와서 사용\n",
    "- 대부분 LLM은 API를 제공\n",
    "- 자체적으로 LLM을 만드는 방법은 현실적이지 못함\n",
    "    - 일반 기업에서는 공개된 LLM 모델을 잘 활용하는 방법에 집중"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3321b986",
   "metadata": {},
   "source": [
    "## 파인튜닝(Fine-Tuning)\n",
    "\n",
    "<img src = \"./image/transfer-learning-vs-fine-tuning.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4eb68b",
   "metadata": {},
   "source": [
    "- 기존의 LLM을 특정한 작업이나 상황에 맞게 조금 더 훈련시키는 과정\n",
    "    - 특별한 상황에 더 잘 맞게 가르치는 것\n",
    "    \n",
    "- 한 분야에서 배운 지식을 다른 분야의 문제 해결에 사용하는 방법을 전이 학습(Transfer_Learning)이라고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a49fc1",
   "metadata": {},
   "source": [
    "## RAG(Retrieval-Augmented Generation)\n",
    "\n",
    "<img src = \"./image/jumpstart-fm-rag.jpg\">\n",
    "\n",
    "- 정보 검색과 생성을 결합한 인공지능 모델\n",
    "- 복잡하고 정보가 필요한 질문에 답변하기 위해 설계됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b245aea0",
   "metadata": {},
   "source": [
    "- RAG의 과정\n",
    "    - 정보 검색 단계\n",
    "        - 질문 : 사용자로부터 입력된 질문\n",
    "        - 쿼리(문서 검색) : 대규모의 문서 데이터베이스나 콘텐츠 저장소에서 질문과 관련된 문서나 정보를 검색\n",
    "        - 정보 검색 결과 : 검색 결과 중에서 가장 관련성 높은 문서와 사용자의 질문을 결합하여 LLM에 전달\n",
    "        \n",
    "    - 텍스트 생성 단계\n",
    "        - 정보 전달 : 선택된 문서의 내용이 사용자의 질문과 함께 모델에 전달\n",
    "            - 문서의 정보를 활용하여 질문에 대한 의미를 이해\n",
    "        - 텍스트 생성 : 전달받은 정보를 바탕으로 질문에 대한 답변을 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb34feef",
   "metadata": {},
   "source": [
    "## 퓨샷 러닝(Few Shot Learning)\n",
    "\n",
    "- 매우 적은 양의 데이터로 학습하는 능력\n",
    "- 모델이 기존에 학습한 지식을 바탕으로 매우 제한된 예시로부터 새로운 작업에 빠르게 적용\n",
    "\n",
    "- 제로샷 러닝(Zero Shot Learning)\n",
    "    - 모델이 학습 과정에서 보지 못한 데이터에 대해 예측을 수행할 수 있는 것\n",
    "    - 학습한 데이터가 방대하면서도 높은 수준의 추상적 사고와 일반화 능력을 갖추어야 함\n",
    "    \n",
    "- 원 샷 러닝(One Shot Learning)\n",
    "    - 하나의 이미지를 학습하여 잘 예측을 수행할 수 있게 하는 것\n",
    "\n",
    "- 퓨샷 러닝(Few Shot Learning)\n",
    "    - 여러 개의 데이터를 학습한 이후 잘 예측을 수행할 수 있게 하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7add05a7",
   "metadata": {},
   "source": [
    "## LLM 활용 시 주의 사항\n",
    "\n",
    "- LLM은 강력한 언어모델이므로 보안 및 규제 측면에서 제약이 많음\n",
    "- 누군가에 의해 악의적으로 사용된다면 사회적 이슈가 제기될 수도 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54461940",
   "metadata": {},
   "source": [
    "### 정보 필터링\n",
    "\n",
    "- LLM을 이용하는 사용자의 질문은 반드시 필터링을 해야함\n",
    "    - 일반인을 상대로 서비스하는 경우, 어떤 내용이 입력될 지 알 수 없음\n",
    "    - 이러한 경우엔 반드시 입력 및 출력 텍스트를 필터링 해야함\n",
    "        - 특히 개인정보가 입력되지 않도록 필터링하는 것이 중요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca41f0c",
   "metadata": {},
   "source": [
    "### 법적인 규제\n",
    "\n",
    "- 특히 공공기관 및 금융산업에서 중요\n",
    "- 산업 특성상 국가에서 규정하는 법규 및 권고 사항을 지켜야 함\n",
    "    - 정부가 정의해둔 규제가 어떤 것들이 있는지 사전에 확인해야함\n",
    "    - 사내 보안팀에서 정의한 규정들도 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27f58c8",
   "metadata": {},
   "source": [
    "### 할루시네이션(hallucination)\n",
    "\n",
    "- 언어 모델이 부정확하거나 관련 없는 정보를 생성하는 현상\n",
    "- LLM이 생성한 답변의 부정확한 할루시네이션 현상은 최소화해야함\n",
    "- LLM 구현 과정 중 할루시네이션 필터링을 추가함으로써 방지할 수도 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165f0b63",
   "metadata": {},
   "source": [
    "### 보안\n",
    "\n",
    "- LLM 모델의 경우 모든 사용자가 모델을 공유하므로 사용자가 입력한 데이터가 학습에 활용될 수 있음\n",
    "- 보안을 강화하기 위해서는\n",
    "    - 마이크로소프트 애저(Azure) 오픈 AI 프라이빗 엔드포인트 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4775b60",
   "metadata": {},
   "source": [
    "# LLM의 한계\n",
    "\n",
    "- LLM이 우리의 삶에 큰 변화를 가져온, 혁신적인 서비스지만 LLM은 이제 막 시작하는 단계임\n",
    "\n",
    "- 편향과 공정성\n",
    "    - 만약 LLM이 주로 남성 엔지니어의 데이터를 학습했다면 \"엔지니어\"라는 단어에 대해 남성 이미지를 더 자주 연상시키는 문장을 생성할 수 있음\n",
    "    \n",
    "- 투명성\n",
    "    - LLM이 어떤 질문에 대해 특정 대답을 하는 경우 왜 그런 대답을 했는지 그 이유를 사용자에게 설명\n",
    "    \n",
    "- 데이터 의존성\n",
    "    - LLM은 특정 언어, 특정 분야에 한정되어서 데이터를 학습하지 않음\n",
    "    - 따라서 다양한 질문에 대해 답변할 수 있지만 모델이 특정 국가의 소설로만 학습을 할 경우에는 다른 지역의 문화적 맥락을 반영한 텍스트를 생성하는 데 한계가 있을 수 있음\n",
    "    \n",
    "- 정보의 일반화\n",
    "    - 데이터 의존성과 반대되는 개념\n",
    "    - LLM이 너무 다양한 데이터를 학습했기 때문에 특정 산업에 특화된 질문을 할 경우 정밀한 답변을 얻지 못할 수 있음\n",
    "    \n",
    "- 오류 가능성\n",
    "    - LLM이 잘못된 정보를 기반으로 문서를 작성할 수 있으며 이는 가짜 뉴스의 확산과 같은 문제를 야기할 수 있음\n",
    "    \n",
    "- 개인정보 보호\n",
    "    - 학습 데이터에 포함된 개인정보(예 : 이름, 위치, 개인적 선호 등)를 모델이 학습하고 이를 생성과정에서 노출시킬 수 있음\n",
    "    \n",
    "- 새로운 정보의 결여\n",
    "    - 모델이 학습한 데이터 이후에 발생한 사건이나 정보에 대해서는 알지 못하고 과거의 정보를 기반으로 응답할 수 있음\n",
    "    \n",
    "- 기업 내 데이터 미활용\n",
    "    - LLM을 그대로 기업에서 활용할 경우 기업이 가진 데이터를 활용할 수 없음\n",
    "        - LLM이 학습한 데이터에 각 기업 내부 데이터가 없기 때문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff85da0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
