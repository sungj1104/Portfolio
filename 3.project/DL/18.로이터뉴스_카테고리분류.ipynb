{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "894464cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import reuters\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "173f9cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
      "\u001b[1m2110848/2110848\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d22a26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8982,), (2246,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9208204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "        34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45], dtype=int64),\n",
       " array([  55,  432,   74, 3159, 1949,   17,   48,   16,  139,  101,  124,\n",
       "         390,   49,  172,   26,   20,  444,   39,   66,  549,  269,  100,\n",
       "          15,   41,   62,   92,   24,   15,   48,   19,   45,   39,   32,\n",
       "          11,   50,   10,   49,   19,   19,   24,   36,   30,   13,   21,\n",
       "          12,   18], dtype=int64))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d5007a",
   "metadata": {},
   "source": [
    "- 로이터 뉴스 카테고리 분류 데이터\n",
    "    - 총 11258개의 뉴스 기사 데이터\n",
    "    - 46개의 카테고리 분류\n",
    "    - 예)\n",
    "        - 중부 지방은 대체로 맑겠으나, 남부 지방은 구름이 많겠습니다 -> 날씨\n",
    "        - 올 초부터 유동성의 힘으로 주가가 일정하게 상승했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c15397e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
      "\u001b[1m550378/550378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2us/step\n"
     ]
    }
   ],
   "source": [
    "word_index = reuters.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7ec29f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mdbl': 10996,\n",
       " 'fawc': 16260,\n",
       " 'degussa': 12089,\n",
       " 'woods': 8803,\n",
       " 'hanging': 13796,\n",
       " 'localized': 20672,\n",
       " 'sation': 20673,\n",
       " 'chanthaburi': 20675,\n",
       " 'refunding': 10997,\n",
       " 'hermann': 8804,\n",
       " 'passsengers': 20676,\n",
       " 'stipulate': 20677,\n",
       " 'heublein': 8352,\n",
       " 'screaming': 20713,\n",
       " 'tcby': 16261,\n",
       " 'four': 185,\n",
       " 'grains': 1642,\n",
       " 'broiler': 20680,\n",
       " 'wooden': 12090,\n",
       " 'wednesday': 1220,\n",
       " 'highveld': 13797,\n",
       " 'duffour': 7593,\n",
       " '0053': 20681,\n",
       " 'elections': 3914,\n",
       " '270': 2563,\n",
       " '271': 3551,\n",
       " '272': 5113,\n",
       " '273': 3552,\n",
       " '274': 3400,\n",
       " 'rudman': 7975,\n",
       " '276': 3401,\n",
       " '277': 3478,\n",
       " '278': 3632,\n",
       " '279': 4309,\n",
       " 'dormancy': 9381,\n",
       " 'errors': 7247,\n",
       " 'deferred': 3086,\n",
       " 'sptnd': 20683,\n",
       " 'cooking': 8805,\n",
       " 'stratabit': 20684,\n",
       " 'designing': 16262,\n",
       " 'metalurgicos': 20685,\n",
       " 'databank': 13798,\n",
       " '300er': 20686,\n",
       " 'shocks': 20687,\n",
       " 'nawg': 7972,\n",
       " 'tnta': 20688,\n",
       " 'perforations': 20689,\n",
       " 'affiliates': 2891,\n",
       " '27p': 20690,\n",
       " 'ching': 16263,\n",
       " 'china': 595,\n",
       " 'wagyu': 16264,\n",
       " 'affiliated': 3189,\n",
       " 'chino': 16265,\n",
       " 'chinh': 16266,\n",
       " 'slickline': 20692,\n",
       " 'doldrums': 13799,\n",
       " 'kids': 12092,\n",
       " 'climbed': 3028,\n",
       " 'controversy': 6693,\n",
       " 'kidd': 20693,\n",
       " 'spotty': 12093,\n",
       " 'rebel': 12639,\n",
       " 'millimetres': 9382,\n",
       " 'golden': 4007,\n",
       " 'projection': 5689,\n",
       " 'stern': 12094,\n",
       " \"hudson's\": 7903,\n",
       " 'dna': 10066,\n",
       " 'dnc': 20695,\n",
       " 'hodler': 20696,\n",
       " 'lme': 2394,\n",
       " 'insolvancy': 20697,\n",
       " 'music': 13800,\n",
       " 'therefore': 1984,\n",
       " 'dns': 10998,\n",
       " 'distortions': 6959,\n",
       " 'thassos': 13801,\n",
       " 'populations': 20698,\n",
       " 'meteorologist': 8806,\n",
       " 'loss': 43,\n",
       " 'exco': 9383,\n",
       " 'adventist': 20813,\n",
       " 'murchison': 16267,\n",
       " 'locked': 10999,\n",
       " 'kampala': 13802,\n",
       " 'arndt': 20699,\n",
       " 'nakasone': 1267,\n",
       " 'steinweg': 20700,\n",
       " \"india's\": 3633,\n",
       " 'wang': 3029,\n",
       " 'wane': 10067,\n",
       " 'unjust': 13803,\n",
       " 'titanium': 13804,\n",
       " 'want': 850,\n",
       " 'pinto': 20701,\n",
       " \"institutes'\": 16268,\n",
       " 'absolute': 7973,\n",
       " 'travel': 4677,\n",
       " 'cutback': 6422,\n",
       " 'nazmi': 16269,\n",
       " 'modest': 1858,\n",
       " 'shopwell': 16270,\n",
       " 'sedi': 20702,\n",
       " 'adoped': 20703,\n",
       " 'tulis': 16271,\n",
       " '18th': 20704,\n",
       " \"wmc's\": 20705,\n",
       " 'menlo': 20706,\n",
       " 'reiners': 11000,\n",
       " 'farmlands': 12095,\n",
       " 'nonsensical': 20707,\n",
       " 'elisra': 20708,\n",
       " 'welcomed': 2461,\n",
       " 'peup': 20709,\n",
       " \"holiday's\": 16272,\n",
       " 'activating': 20711,\n",
       " 'avondale': 16273,\n",
       " 'interational': 16274,\n",
       " 'welcomes': 20712,\n",
       " 'fip': 16275,\n",
       " 'tailings': 11001,\n",
       " 'fit': 4205,\n",
       " 'lifeline': 16276,\n",
       " 'bringing': 1916,\n",
       " 'fix': 4819,\n",
       " '624': 6164,\n",
       " 'naturalite': 12096,\n",
       " 'wales': 6165,\n",
       " 'fin': 8807,\n",
       " 'fio': 11129,\n",
       " 'ceremenony': 20714,\n",
       " 'sovr': 20715,\n",
       " \"yeo's\": 20716,\n",
       " 'effects': 1788,\n",
       " 'sixteen': 13805,\n",
       " 'undeveloped': 8808,\n",
       " 'glutted': 13806,\n",
       " 'barton': 20717,\n",
       " 'froday': 20718,\n",
       " 'arrow': 10089,\n",
       " 'stabilises': 11002,\n",
       " 'allan': 6960,\n",
       " '374p': 20719,\n",
       " '393': 3891,\n",
       " '392': 4008,\n",
       " '391': 4206,\n",
       " '390': 3079,\n",
       " '397': 4550,\n",
       " '396': 6166,\n",
       " '395': 6423,\n",
       " '394': 4207,\n",
       " '399': 6961,\n",
       " '398': 4208,\n",
       " 'stabilised': 7595,\n",
       " 'smelters': 5114,\n",
       " 'oprah': 20720,\n",
       " 'orginially': 20721,\n",
       " \"tvx's\": 20722,\n",
       " 'ponomarev': 16278,\n",
       " 'enviroment': 20723,\n",
       " \"reeves'\": 20724,\n",
       " 'mason': 8363,\n",
       " 'encourage': 1670,\n",
       " 'adapt': 7596,\n",
       " 'abbott': 12776,\n",
       " 'stamping': 13808,\n",
       " 'colquiri': 20726,\n",
       " 'ambrit': 11003,\n",
       " 'strata': 8353,\n",
       " 'corrects': 4821,\n",
       " 'sandra': 11922,\n",
       " 'estimate': 859,\n",
       " 'universally': 20727,\n",
       " 'chlorine': 20728,\n",
       " 'competes': 16279,\n",
       " 'leiner': 10068,\n",
       " 'ministries': 8809,\n",
       " 'disturbed': 8810,\n",
       " 'competed': 13809,\n",
       " 'juergen': 8811,\n",
       " 'kfw': 13810,\n",
       " 'turben': 11004,\n",
       " 'reintroduced': 9384,\n",
       " 'maladies': 20729,\n",
       " 'chevron': 4101,\n",
       " 'lazere': 16280,\n",
       " 'antilles': 8812,\n",
       " 'dti': 11907,\n",
       " 'specially': 9070,\n",
       " 'bilzerian': 4678,\n",
       " 'bakelite': 13811,\n",
       " 'renovated': 20730,\n",
       " 'service': 568,\n",
       " 'payless': 16281,\n",
       " 'spiegler': 20731,\n",
       " 'needed': 831,\n",
       " 'wigglesworth': 16282,\n",
       " 'master': 6962,\n",
       " 'antonson': 13812,\n",
       " 'genesis': 20732,\n",
       " 'vismara': 13813,\n",
       " 'organically': 20734,\n",
       " \"accords'\": 20735,\n",
       " 'task': 5940,\n",
       " 'positively': 7974,\n",
       " 'feasibility': 3479,\n",
       " 'ahmed': 6963,\n",
       " \"suralco's\": 13814,\n",
       " 'awacs': 20736,\n",
       " 'idly': 16283,\n",
       " 'regulator': 20737,\n",
       " 'pseudorabies': 12097,\n",
       " 'staubli': 16284,\n",
       " 'nzi': 8813,\n",
       " 'feeling': 5115,\n",
       " '275': 3127,\n",
       " '6819': 20738,\n",
       " 'gorman': 16285,\n",
       " 'sustaining': 8354,\n",
       " 'spectrum': 9385,\n",
       " 'consenting': 20739,\n",
       " 'recapitalized': 12098,\n",
       " 'sailed': 11562,\n",
       " 'dozen': 7597,\n",
       " 'affairs': 1985,\n",
       " 'courier': 2253,\n",
       " 'kremlin': 8355,\n",
       " 'shipments': 895,\n",
       " \"aquino's\": 16286,\n",
       " 'committing': 10070,\n",
       " 'sugarcane': 5293,\n",
       " 'diminishing': 9386,\n",
       " 'vexing': 16287,\n",
       " 'simplify': 11005,\n",
       " 'mouth': 6167,\n",
       " 'steinhardt': 7248,\n",
       " 'conceded': 8814,\n",
       " 'bradford': 9387,\n",
       " 'singer': 7976,\n",
       " '5602': 20740,\n",
       " \"1987's\": 13816,\n",
       " 'tech': 4950,\n",
       " 'teck': 6424,\n",
       " 'majv': 20741,\n",
       " 'saying': 666,\n",
       " 'dickey': 16477,\n",
       " 'sweetner': 20742,\n",
       " 'teresa': 21149,\n",
       " 'ulcer': 20743,\n",
       " 'cheaply': 13817,\n",
       " 'thai': 2361,\n",
       " 'orleans': 6964,\n",
       " 'excavator': 16290,\n",
       " 'rico': 6168,\n",
       " 'lube': 12099,\n",
       " 'rick': 13818,\n",
       " 'rich': 4679,\n",
       " 'kerna': 13819,\n",
       " 'rice': 950,\n",
       " 'rica': 4209,\n",
       " 'plate': 5503,\n",
       " 'platt': 16291,\n",
       " 'altogether': 8356,\n",
       " 'jaguar': 8815,\n",
       " 'dynair': 20744,\n",
       " 'patch': 8816,\n",
       " 'ldp': 2892,\n",
       " 'boarded': 13820,\n",
       " 'precluding': 16292,\n",
       " 'clarified': 11006,\n",
       " 'sensitivity': 16293,\n",
       " 'alternative': 1511,\n",
       " 'clarifies': 11007,\n",
       " 'lots': 5116,\n",
       " 'irs': 7598,\n",
       " 'irv': 20745,\n",
       " 'iri': 13821,\n",
       " 'ira': 13822,\n",
       " 'timber': 5690,\n",
       " 'ire': 20746,\n",
       " 'discipline': 5219,\n",
       " 'extend': 1937,\n",
       " 'nature': 3634,\n",
       " \"amb's\": 16295,\n",
       " 'dunhill': 16296,\n",
       " 'extent': 2142,\n",
       " 'restrcitions': 20747,\n",
       " 'heating': 2396,\n",
       " \"mannesmann's\": 11008,\n",
       " 'outsanding': 20748,\n",
       " 'multimillions': 20749,\n",
       " 'sarcinelli': 13824,\n",
       " 'southeastern': 6694,\n",
       " 'eradicate': 10071,\n",
       " 'libyan': 9388,\n",
       " 'foreclosing': 20750,\n",
       " 'maclaine': 12101,\n",
       " 'fra': 20751,\n",
       " 'union': 353,\n",
       " 'frn': 11009,\n",
       " 'much': 386,\n",
       " 'fry': 12102,\n",
       " 'mothball': 20752,\n",
       " 'chlorazepate': 10072,\n",
       " 'dxns': 12103,\n",
       " 'toyko': 19981,\n",
       " 'spit': 20753,\n",
       " '007050': 16297,\n",
       " 'freehold': 16298,\n",
       " 'davy': 13825,\n",
       " 'dave': 11010,\n",
       " 'spie': 12177,\n",
       " 'aguayo': 10117,\n",
       " 'wildcat': 12104,\n",
       " 'fecs': 10069,\n",
       " 'kennan': 20754,\n",
       " 'intal': 16299,\n",
       " 'contingencies': 9389,\n",
       " 'professionally': 16551,\n",
       " 'microbiological': 16300,\n",
       " 'misconstrued': 20756,\n",
       " 'k': 409,\n",
       " 'securitiesd': 20757,\n",
       " 'deferring': 16301,\n",
       " 'kohl': 5941,\n",
       " 'conditioned': 3030,\n",
       " 'fnhb': 20758,\n",
       " \"october's\": 16302,\n",
       " 'memorial': 13954,\n",
       " 'democracies': 6965,\n",
       " 'conformed': 27520,\n",
       " 'split': 464,\n",
       " \"bond's\": 12105,\n",
       " 'thinly': 11112,\n",
       " 'dunkirk': 16515,\n",
       " 'cavanaugh': 16303,\n",
       " \"securities'\": 13827,\n",
       " 'marches': 21345,\n",
       " 'issam': 16304,\n",
       " 'workforce': 2020,\n",
       " 'meinert': 12106,\n",
       " 'boiler': 13828,\n",
       " \"bp's\": 5294,\n",
       " 'torpedoed': 16305,\n",
       " 'indidate': 20762,\n",
       " 'downwardly': 13829,\n",
       " 'viviez': 20763,\n",
       " 'vladiminovich': 20764,\n",
       " 'academic': 16306,\n",
       " 'architecural': 20765,\n",
       " 'corporate': 1117,\n",
       " 'appropriately': 16307,\n",
       " 'teicc': 20766,\n",
       " \"hanover's\": 20767,\n",
       " 'aristech': 8817,\n",
       " 'portrayed': 20768,\n",
       " 'raffineries': 21383,\n",
       " 'hai': 20770,\n",
       " 'hal': 7599,\n",
       " 'ham': 13830,\n",
       " 'han': 10073,\n",
       " 'e15b': 20771,\n",
       " 'had': 61,\n",
       " 'hay': 20772,\n",
       " 'botchwey': 13831,\n",
       " 'haq': 10074,\n",
       " 'has': 37,\n",
       " 'hat': 13832,\n",
       " 'hav': 20773,\n",
       " 'fortin': 20774,\n",
       " 'municipal': 8818,\n",
       " 'osman': 20775,\n",
       " 'fsical': 20776,\n",
       " 'elders': 3480,\n",
       " 'survival': 12107,\n",
       " 'unequivocally': 16308,\n",
       " 'objective': 2519,\n",
       " 'indicative': 6695,\n",
       " 'shadow': 10075,\n",
       " 'riskiness': 21411,\n",
       " 'positiive': 20778,\n",
       " \"american's\": 10076,\n",
       " 'alick': 16309,\n",
       " 'harima': 16310,\n",
       " 'alice': 12108,\n",
       " 'altschul': 20779,\n",
       " 'festivities': 16311,\n",
       " 'medecines': 20780,\n",
       " 'beneficial': 2942,\n",
       " 'yoweri': 12109,\n",
       " 'crowd': 13833,\n",
       " 'crowe': 9390,\n",
       " 'crown': 3553,\n",
       " 'topping': 13679,\n",
       " 'captive': 8819,\n",
       " 'billboard': 12110,\n",
       " 'fiduciary': 6169,\n",
       " 'bottom': 3402,\n",
       " 'plucked': 20782,\n",
       " 'locksmithing': 20783,\n",
       " 'ecopetrol': 9391,\n",
       " 'pipestone': 24018,\n",
       " \"growers'\": 5505,\n",
       " 'borrows': 20785,\n",
       " 'eduard': 16312,\n",
       " 'venpres': 13834,\n",
       " 'bamboo': 16313,\n",
       " 'foolish': 13835,\n",
       " 'uruguyan': 20786,\n",
       " 'officeholders': 20787,\n",
       " 'economiques': 20788,\n",
       " 'aden': 16314,\n",
       " 'maxwell': 4822,\n",
       " 'marshall': 4680,\n",
       " 'honeymoon': 16315,\n",
       " 'administer': 16316,\n",
       " 'shoots': 20790,\n",
       " 'rubbertech': 16317,\n",
       " 'johsen': 16318,\n",
       " 'reciprocity': 10077,\n",
       " 'fabric': 13836,\n",
       " 'suffice': 20791,\n",
       " 'spokemsan': 20792,\n",
       " \"sonora's\": 20793,\n",
       " '5865': 16319,\n",
       " \"systems'\": 16320,\n",
       " 'perfumes': 20794,\n",
       " 'halycon': 20795,\n",
       " 'nonvoting': 20796,\n",
       " 'safeguard': 7250,\n",
       " 'sawdust': 21538,\n",
       " \"else's\": 20797,\n",
       " 'arrays': 13837,\n",
       " 'aza': 20798,\n",
       " 'smasher': 20799,\n",
       " 'complications': 12111,\n",
       " 'pesos': 1813,\n",
       " 'relabelling': 20800,\n",
       " 'passenger': 3722,\n",
       " \"avon's\": 12112,\n",
       " 'megahertz': 20801,\n",
       " 'mirror': 10683,\n",
       " 'minas': 8357,\n",
       " 'bourdain': 16322,\n",
       " 'crownx': 20802,\n",
       " 'eventual': 6425,\n",
       " 'crowns': 1207,\n",
       " 'role': 1369,\n",
       " 'obliges': 20803,\n",
       " 'rolf': 16323,\n",
       " 'vegetative': 13838,\n",
       " 'rolm': 20804,\n",
       " 'roll': 4419,\n",
       " 'intend': 2463,\n",
       " 'palms': 16324,\n",
       " 'denys': 19255,\n",
       " 'transported': 13839,\n",
       " 'moresby': 20805,\n",
       " 'devon': 16325,\n",
       " 'intent': 1351,\n",
       " \"camco's\": 20806,\n",
       " 'variable': 5942,\n",
       " 'transporter': 20807,\n",
       " 'danske': 16326,\n",
       " 'friedhelm': 13840,\n",
       " 'hawker': 8358,\n",
       " \"sand's\": 17774,\n",
       " 'preseving': 20808,\n",
       " '80386': 12113,\n",
       " 'bnls': 16328,\n",
       " 'ordination': 19984,\n",
       " 'overturned': 11011,\n",
       " 'erred': 16329,\n",
       " 'cincinnati': 6696,\n",
       " 'corps': 16710,\n",
       " 'whoever': 20809,\n",
       " 'osp': 16330,\n",
       " 'osr': 13841,\n",
       " 'ost': 12114,\n",
       " 'chair': 16331,\n",
       " '690': 5647,\n",
       " 'grapples': 20810,\n",
       " 'megawatts': 13842,\n",
       " 'photocopiers': 20811,\n",
       " 'sconninx': 20812,\n",
       " 'circumstances': 2274,\n",
       " 'oversight': 13843,\n",
       " \"paradyne's\": 20814,\n",
       " '691': 6363,\n",
       " 'paychecks': 20815,\n",
       " \"stadelmann's\": 13844,\n",
       " 'choice': 3241,\n",
       " 'vastagh': 11012,\n",
       " 'embark': 8820,\n",
       " 'gloomy': 9392,\n",
       " 'stays': 9393,\n",
       " 'exact': 4009,\n",
       " 'minute': 5117,\n",
       " 'kittiwake': 11892,\n",
       " 'picul': 20816,\n",
       " 'skewed': 20817,\n",
       " 'cooke': 11013,\n",
       " 'defaults': 10078,\n",
       " 'reimpose': 11014,\n",
       " 'hindered': 9394,\n",
       " 'lengthened': 20818,\n",
       " 'chopping': 16333,\n",
       " 'mckiernan': 13845,\n",
       " 'collaspe': 20819,\n",
       " 'corazon': 7251,\n",
       " 'antwerp': 7600,\n",
       " 'abdullah': 13846,\n",
       " 'goldston': 13847,\n",
       " '300': 442,\n",
       " 'cassa': 20821,\n",
       " 'casse': 20822,\n",
       " '695': 4081,\n",
       " 'ground': 2979,\n",
       " 'boost': 839,\n",
       " 'azusa': 16334,\n",
       " 'drafted': 9395,\n",
       " '303': 4823,\n",
       " 'climbs': 13848,\n",
       " 'honour': 7601,\n",
       " 'vanderbilt': 20823,\n",
       " '305': 3968,\n",
       " 'address': 3031,\n",
       " 'dwindling': 8821,\n",
       " 'benson': 7252,\n",
       " 'enroll': 12115,\n",
       " 'revenues': 501,\n",
       " 'impacted': 12116,\n",
       " 'queue': 20826,\n",
       " 'accomplished': 10079,\n",
       " 'throughput': 7602,\n",
       " 'influx': 9396,\n",
       " 'stockbuilding': 10080,\n",
       " 'aproximates': 20827,\n",
       " 'petroleo': 13849,\n",
       " 'sistemas': 16335,\n",
       " 'feretti': 14053,\n",
       " 'opposes': 5943,\n",
       " 'working': 882,\n",
       " 'perished': 20829,\n",
       " 'oldham': 13850,\n",
       " '27000': 20830,\n",
       " 'optimize': 19245,\n",
       " 'vigour': 20832,\n",
       " 'opposed': 1580,\n",
       " 'liberalizing': 16336,\n",
       " 'wvz': 20833,\n",
       " 'dampness': 20834,\n",
       " 'approving': 13851,\n",
       " 'sierra': 13496,\n",
       " 'entrepot': 20835,\n",
       " 'currency': 224,\n",
       " 'originally': 1499,\n",
       " 'tindemans': 20837,\n",
       " 'valorem': 16337,\n",
       " 'following': 477,\n",
       " 'fossen': 20838,\n",
       " 'locke': 11016,\n",
       " 'employess': 20839,\n",
       " 'rotberg': 12117,\n",
       " 'parachute': 16338,\n",
       " 'locks': 11017,\n",
       " 'incremental': 12255,\n",
       " 'woolowrth': 16339,\n",
       " 'listens': 20841,\n",
       " 'litre': 7253,\n",
       " 'edouard': 3554,\n",
       " 'ounce': 1377,\n",
       " 'nicanor': 20843,\n",
       " 'sucocitrico': 20844,\n",
       " 'minicomputers': 16340,\n",
       " \"silva's\": 16341,\n",
       " 'restitutions': 11018,\n",
       " 'custer': 16342,\n",
       " '3rd': 2590,\n",
       " 'fueled': 10081,\n",
       " 'trydahl': 20845,\n",
       " 'aice': 11019,\n",
       " 'harmon': 12118,\n",
       " 'conscious': 10082,\n",
       " 'herbicidesand': 20846,\n",
       " 'subdivisions': 20847,\n",
       " \"veslefrikk's\": 20848,\n",
       " 'swollen': 11020,\n",
       " 'pulled': 7978,\n",
       " 'tilney': 20849,\n",
       " 'years': 203,\n",
       " 'structuring': 20850,\n",
       " 'episodes': 20851,\n",
       " 'sportscene': 16343,\n",
       " \"northair's\": 16344,\n",
       " 'jig': 20852,\n",
       " 'jin': 20853,\n",
       " 'jim': 3403,\n",
       " 'troubles': 8359,\n",
       " 'workforces': 13852,\n",
       " 'suspension': 2362,\n",
       " 'troubled': 3892,\n",
       " 'fondiaria': 16345,\n",
       " 'modestly': 6697,\n",
       " 'recipients': 12119,\n",
       " 'civilian': 7979,\n",
       " 'indigenous': 13853,\n",
       " 'overpowering': 20854,\n",
       " 'drilling': 1051,\n",
       " 'sorted': 16346,\n",
       " 'lichtenstein': 16347,\n",
       " 'bedevil': 20855,\n",
       " 'dispite': 20856,\n",
       " 'battleships': 16843,\n",
       " 'instability': 4824,\n",
       " 'quarter': 95,\n",
       " 'salado': 20857,\n",
       " 'honduras': 5692,\n",
       " \"chevron's\": 13855,\n",
       " \"lazere's\": 12273,\n",
       " 'receipt': 2660,\n",
       " 'sponsor': 8360,\n",
       " 'entering': 4825,\n",
       " \"kcbt's\": 16349,\n",
       " 'nowicki': 19987,\n",
       " 'salads': 13856,\n",
       " 'augar': 16351,\n",
       " '797': 7980,\n",
       " '796': 7254,\n",
       " '795': 8361,\n",
       " '794': 5295,\n",
       " '793': 5118,\n",
       " '792': 6170,\n",
       " '791': 5296,\n",
       " '790': 4826,\n",
       " \"nikko's\": 20858,\n",
       " 'unsaleable': 20859,\n",
       " '799': 5720,\n",
       " '798': 5693,\n",
       " 'seriously': 2143,\n",
       " 'trauma': 16352,\n",
       " 'tvbh': 20860,\n",
       " 'macedon': 20861,\n",
       " 'disintegrated': 21906,\n",
       " 'adddition': 21909,\n",
       " 'incentives': 2244,\n",
       " 'complicated': 5944,\n",
       " 'reevaluating': 20864,\n",
       " 'thatching': 21921,\n",
       " 'brasil': 7981,\n",
       " '79p': 20865,\n",
       " 'wrong': 4951,\n",
       " 'initiate': 8822,\n",
       " 'aboard': 16353,\n",
       " 'saving': 7255,\n",
       " 'spoken': 8823,\n",
       " 'parkinson': 16364,\n",
       " 'one': 65,\n",
       " 'ont': 20867,\n",
       " 'concert': 7256,\n",
       " \"boston's\": 16354,\n",
       " 'stifled': 13859,\n",
       " 'types': 4622,\n",
       " 'lingering': 20868,\n",
       " 'surges': 16356,\n",
       " 'hurdman': 20869,\n",
       " 'herds': 16357,\n",
       " 'absorbs': 14114,\n",
       " 'surged': 4681,\n",
       " 'dalkon': 14211,\n",
       " 'crossroads': 13860,\n",
       " 'shakeup': 20870,\n",
       " 'disasterous': 20871,\n",
       " 'illness': 11021,\n",
       " 'turned': 3242,\n",
       " 'locations': 3801,\n",
       " 'tyranite': 12120,\n",
       " 'minesweepers': 13861,\n",
       " 'turner': 7257,\n",
       " 'borough': 20872,\n",
       " 'underlines': 12358,\n",
       " \"bancorporation's\": 20873,\n",
       " 'fashionable': 20874,\n",
       " \"ae's\": 20875,\n",
       " 'dilutions': 16358,\n",
       " 'goodman': 9472,\n",
       " 'unlawfully': 10510,\n",
       " 'mayer': 16359,\n",
       " 'printer': 16360,\n",
       " 'offload': 20877,\n",
       " 'opposite': 13862,\n",
       " 'buffer': 738,\n",
       " 'printed': 9398,\n",
       " 'pequiven': 16361,\n",
       " 'panoche': 13863,\n",
       " 'knowingly': 20878,\n",
       " 'ecusta': 16362,\n",
       " 'thsl': 20879,\n",
       " 'phil': 8825,\n",
       " 'jitters': 13864,\n",
       " 'touche': 16363,\n",
       " 'jittery': 20881,\n",
       " 'friction': 3291,\n",
       " 'fecal': 16365,\n",
       " 'resurgance': 22068,\n",
       " 'heeding': 20882,\n",
       " 'soviets': 2363,\n",
       " 'imagined': 16366,\n",
       " 'transact': 16367,\n",
       " 'califoirnia': 20883,\n",
       " \"chrysler's\": 9399,\n",
       " 'respecitvely': 16368,\n",
       " 'presse': 16369,\n",
       " 'euromarket': 10084,\n",
       " 'guarded': 12121,\n",
       " 'satisfacotry': 16371,\n",
       " 'authroization': 20884,\n",
       " 'simplistic': 20885,\n",
       " 'monde': 20886,\n",
       " 'awaiting': 4102,\n",
       " 'recombinant': 13865,\n",
       " 'refinancement': 20887,\n",
       " 'comserv': 20888,\n",
       " 'kitakyushu': 20889,\n",
       " 'pima': 16372,\n",
       " 'basle': 11022,\n",
       " '6250': 20891,\n",
       " 'choudhury': 16373,\n",
       " 'vision': 8826,\n",
       " 'interruptible': 20892,\n",
       " 'weatherford': 13866,\n",
       " '832': 7982,\n",
       " '833': 5694,\n",
       " '830': 4420,\n",
       " '831': 5119,\n",
       " '836': 5297,\n",
       " '837': 4553,\n",
       " '834': 6172,\n",
       " '835': 4952,\n",
       " 'alarming': 22144,\n",
       " '838': 5695,\n",
       " '839': 6173,\n",
       " '524p': 20893,\n",
       " 'sponsorship': 20894,\n",
       " 'vendex': 12122,\n",
       " \"amsouth's\": 20895,\n",
       " 'kilometer': 20896,\n",
       " 'enjoys': 10086,\n",
       " 'illiberal': 20897,\n",
       " 'punta': 6174,\n",
       " 'punte': 20898,\n",
       " 'girozentrale': 10087,\n",
       " 'missstatements': 20899,\n",
       " 'marietta': 10088,\n",
       " 'awards': 6175,\n",
       " 'concentrated': 3635,\n",
       " '83p': 20900,\n",
       " 'developpement': 13867,\n",
       " 'rhodes': 13868,\n",
       " 'matheson': 5696,\n",
       " '1720': 20901,\n",
       " 'paring': 20902,\n",
       " 's': 35,\n",
       " 'concentrates': 4953,\n",
       " \"can's\": 16374,\n",
       " 'polysaturated': 22183,\n",
       " 'parini': 20903,\n",
       " 'baden': 13869,\n",
       " 'bader': 20904,\n",
       " 'buoyancy': 12123,\n",
       " 'erdem': 20905,\n",
       " 'properites': 16375,\n",
       " 'comparitive': 20906,\n",
       " 'practises': 12124,\n",
       " 'collides': 20907,\n",
       " 'west': 189,\n",
       " 'wess': 20908,\n",
       " 'collided': 13870,\n",
       " 'practised': 20909,\n",
       " \"amalgamated's\": 20910,\n",
       " 'motives': 20911,\n",
       " 'wants': 1378,\n",
       " 'formed': 1273,\n",
       " 'readings': 20912,\n",
       " 'geothermal': 12125,\n",
       " 'tightened': 7315,\n",
       " \"d'or\": 11023,\n",
       " 'former': 1109,\n",
       " 'venezulean': 20913,\n",
       " 'curd': 19935,\n",
       " 'squeezes': 12126,\n",
       " 'newspaper': 1019,\n",
       " 'situation': 817,\n",
       " 'ivey': 13871,\n",
       " 'engaged': 3636,\n",
       " 'dubious': 13872,\n",
       " 'cayacq': 17061,\n",
       " 'cobol': 20916,\n",
       " 'limping': 20917,\n",
       " 'technology': 883,\n",
       " 'koerner': 20919,\n",
       " 'debilitating': 16376,\n",
       " 'verified': 7983,\n",
       " 'otto': 4010,\n",
       " '7770': 20920,\n",
       " 'emulsions': 16377,\n",
       " \"onic's\": 16378,\n",
       " 'slate': 9075,\n",
       " 'wires': 20921,\n",
       " 'edged': 5506,\n",
       " 'assigns': 20922,\n",
       " 'singapore': 1341,\n",
       " 'deflate': 20923,\n",
       " \"strategy's\": 20924,\n",
       " 'walesa': 16379,\n",
       " 'advertisement': 4554,\n",
       " 'luyten': 20925,\n",
       " 'shrortly': 20926,\n",
       " 'corpoartion': 20927,\n",
       " 'preferance': 22290,\n",
       " 'tracking': 16380,\n",
       " 'sunnyvale': 13874,\n",
       " 'colorants': 20928,\n",
       " 'persistently': 16381,\n",
       " \"officers'\": 16382,\n",
       " \"his's\": 20929,\n",
       " 'being': 367,\n",
       " 'divestitures': 7259,\n",
       " 'steamer': 20930,\n",
       " 'rover': 20931,\n",
       " 'grounded': 8362,\n",
       " \"businessmen's\": 16383,\n",
       " 'cyanidation': 16384,\n",
       " 'overthrow': 20932,\n",
       " 'partnerhip': 20933,\n",
       " 'sumt': 16385,\n",
       " 'sums': 8827,\n",
       " 'oelmuehle': 16386,\n",
       " 'unveil': 16387,\n",
       " 'gestures': 13875,\n",
       " 'penta': 20934,\n",
       " 'traffic': 2544,\n",
       " 'preference': 2428,\n",
       " 'sumi': 20935,\n",
       " 'world': 166,\n",
       " 'postal': 9400,\n",
       " 'bced': 16388,\n",
       " 'dornbush': 12128,\n",
       " 'confine': 14215,\n",
       " '2555': 20936,\n",
       " \"zambia's\": 5945,\n",
       " 'superiority': 20937,\n",
       " 'militate': 20938,\n",
       " 'satisfactory': 2395,\n",
       " 'superintendent': 20939,\n",
       " 'tvx': 5946,\n",
       " 'tvt': 16389,\n",
       " 'magma': 6698,\n",
       " 'diving': 20940,\n",
       " 'tvb': 15548,\n",
       " 'seaman': 13876,\n",
       " 'matsunaga': 11025,\n",
       " '919': 4827,\n",
       " '918': 5298,\n",
       " 'refundable': 17070,\n",
       " '914': 5947,\n",
       " '917': 7260,\n",
       " '916': 6699,\n",
       " '911': 5507,\n",
       " '910': 4828,\n",
       " 'restoring': 10213,\n",
       " '912': 4555,\n",
       " 'squabble': 20942,\n",
       " 'retains': 7261,\n",
       " \"partner's\": 20943,\n",
       " 'leadership': 5300,\n",
       " 'graaf': 11026,\n",
       " 'spacelab': 20944,\n",
       " 'thailand': 1800,\n",
       " 'graan': 9402,\n",
       " 'exasperating': 20945,\n",
       " 'hartmarx': 12129,\n",
       " 'frights': 16390,\n",
       " 'niall': 20946,\n",
       " 'johnston': 11027,\n",
       " '91p': 16391,\n",
       " 'sensitively': 16392,\n",
       " 'porsche': 6016,\n",
       " 'prepares': 15494,\n",
       " 'lively': 12130,\n",
       " 'stoppages': 10686,\n",
       " \"associated's\": 16394,\n",
       " 'pivot': 12131,\n",
       " 'series': 1037,\n",
       " 'sese': 24050,\n",
       " 'bubble': 7604,\n",
       " 'trusses': 16395,\n",
       " 'interestate': 20949,\n",
       " 'continents': 20950,\n",
       " 'societal': 20951,\n",
       " 'with': 28,\n",
       " 'pull': 6176,\n",
       " 'rush': 6700,\n",
       " 'monopoly': 6222,\n",
       " 'operationally': 20953,\n",
       " 'dirty': 20954,\n",
       " 'abuses': 10090,\n",
       " 'prudhoe': 7262,\n",
       " 'pulp': 5949,\n",
       " 'rust': 16396,\n",
       " 'hellman': 20955,\n",
       " 'amdec': 20956,\n",
       " 'australasian': 16397,\n",
       " 'watches': 13878,\n",
       " 'hypertension': 20957,\n",
       " \"hemdale's\": 20958,\n",
       " 'formulation': 16398,\n",
       " 'watched': 7605,\n",
       " 'jargon': 20959,\n",
       " 'cream': 13879,\n",
       " 'ideally': 9404,\n",
       " 'ryavec': 11028,\n",
       " 'microoganisms': 20960,\n",
       " 'indemnify': 13880,\n",
       " 'wincenty': 20961,\n",
       " 'waving': 20962,\n",
       " \"multifood's\": 20963,\n",
       " 'midges': 20964,\n",
       " 'natalie': 11029,\n",
       " 'crosbie': 13881,\n",
       " 'posible': 20965,\n",
       " 'omnibus': 13882,\n",
       " 'assetsof': 20966,\n",
       " 'tricks': 13883,\n",
       " 'rs': 16399,\n",
       " 'kilogram': 20967,\n",
       " 'pruning': 25363,\n",
       " 'dyer': 13884,\n",
       " 'dyes': 20968,\n",
       " 'legislatures': 20969,\n",
       " 'scm': 16400,\n",
       " 'sci': 9405,\n",
       " 'riedel': 20970,\n",
       " 'ceramic': 16401,\n",
       " 'unitholders': 6701,\n",
       " 'scb': 13885,\n",
       " 'dn11': 20971,\n",
       " 'conditionality': 20972,\n",
       " \"stock's\": 13807,\n",
       " 'masland': 20973,\n",
       " 'causes': 7606,\n",
       " 'riots': 10091,\n",
       " 'norf': 20974,\n",
       " 'nord': 9406,\n",
       " 'midwest': 3893,\n",
       " 'tamils': 13886,\n",
       " 'ofthe': 16402,\n",
       " \"colombia's\": 3421,\n",
       " '24th': 11030,\n",
       " 'sant': 20975,\n",
       " 'moines': 10092,\n",
       " 'electrotechnical': 22577,\n",
       " 'proceeded': 24534,\n",
       " 'sanz': 20976,\n",
       " 'insufficiently': 13887,\n",
       " 'sang': 20977,\n",
       " 'sand': 5950,\n",
       " 'bracho': 16404,\n",
       " 'small': 805,\n",
       " 'workloads': 20978,\n",
       " 'sank': 6702,\n",
       " 'kemper': 20979,\n",
       " 'abbreviated': 16405,\n",
       " 'quicker': 13888,\n",
       " '199': 3802,\n",
       " '198': 3243,\n",
       " '195': 2661,\n",
       " '194': 3080,\n",
       " '197': 4310,\n",
       " '196': 3894,\n",
       " '191': 2850,\n",
       " '190': 2199,\n",
       " '193': 3481,\n",
       " '192': 3350,\n",
       " 'past': 582,\n",
       " 'fractionation': 20980,\n",
       " 'displays': 20981,\n",
       " 'pass': 3081,\n",
       " 'investment': 202,\n",
       " 'quals': 27062,\n",
       " 'quicken': 16406,\n",
       " \"centronic's\": 20983,\n",
       " 'menswear': 20984,\n",
       " 'clock': 16407,\n",
       " 'teape': 20985,\n",
       " 'teapa': 20986,\n",
       " 'prevailed': 10093,\n",
       " 'hebei': 9407,\n",
       " ...}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f901ad14",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {0 : \"<PAD>\", 1 : \"<S>\", 2 : \"<UNK>\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52719a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word.update({value + 3 : key for key, value in word_index.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b85e828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<S> mcgrath rentcorp said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(map(lambda x: idx2word[x], x_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "986117e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "580"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\" \".join(map(lambda x: idx2word[x], x_train[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "245945ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30982"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f008d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53ea124e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = pad_sequences(x_train, maxlen = 300)\n",
    "val_seq = pad_sequences(x_val, maxlen = 300)\n",
    "test_seq = pad_sequences(x_test, maxlen = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b63e12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(5000, 300, input_shape = (300,)))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Conv1D(64, 5, activation = \"relu\"))\n",
    "model.add(keras.layers.MaxPool1D(4))\n",
    "model.add(keras.layers.LSTM(55))\n",
    "model.add(keras.layers.Dense(1, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7b5d298",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 4, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac86e1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 634ms/step - accuracy: 0.0535 - loss: -33.6446 - val_accuracy: 0.0467 - val_loss: -93.6428\n",
      "Epoch 2/50\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 592ms/step - accuracy: 0.0485 - loss: -102.9329 - val_accuracy: 0.0467 - val_loss: -120.8807\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(train_seq, y_train, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m, epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m      2\u001b[0m                     validation_data \u001b[38;5;241m=\u001b[39m (val_seq, y_val), callbacks \u001b[38;5;241m=\u001b[39m [early_stopping_cb])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:324\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m--> 324\u001b[0m         callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m    325\u001b[0m         logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    326\u001b[0m         callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(\n\u001b[0;32m    327\u001b[0m             step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    328\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\callbacks\\callback_list.py:98\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_begin\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m     96\u001b[0m         callback\u001b[38;5;241m.\u001b[39mon_epoch_end(epoch, logs)\n\u001b[1;32m---> 98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_begin\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     99\u001b[0m     logs \u001b[38;5;241m=\u001b[39m logs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_seq, y_train, batch_size = 128, epochs = 50,\n",
    "                    validation_data = (val_seq, y_val), callbacks = [early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcba879e",
   "metadata": {},
   "source": [
    "# 맛집코드분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9c699b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카테고리당 100개로 산정\n",
    "# 4600 -> 1000으로 수정\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5db3f344",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = np.array([len(x) for x in x_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e026ce0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145.5398574927633 95.0 13 2376\n"
     ]
    }
   ],
   "source": [
    "# 길이 평균값과 중간값\n",
    "print(np.mean(length), np.median(length), np.min(length), np.max(length))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd46bbca",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "25983fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_list = [j for i in x_train for j in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5fd30139",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(whole_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b7ef874f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0\n",
       "0   1\n",
       "1   2\n",
       "2   2\n",
       "3   8\n",
       "4  43"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "055c74b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1307239, 1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "df960f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"count\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0309bd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = df.groupby(0).sum().sort_values(by = \"count\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2a1cf517",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count[\"word\"] = pd.Series(df_count.index).map(lambda x: idx2word[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e5a52926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>284013</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65949</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33791</td>\n",
       "      <td>said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32262</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26309</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    count  word\n",
       "0              \n",
       "2  284013    of\n",
       "4   65949    in\n",
       "5   33791  said\n",
       "6   32262   and\n",
       "7   26309     a"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9985de53",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_list = df_count[df_count[\"count\"] >= len(x_train)/2][\"word\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9dbb4be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_list.remove(\"<S>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a5d6fc56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 1,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word_index[i] for i in remove_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094106ab",
   "metadata": {},
   "source": [
    "## 데이터 분할 및 간단한 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e5f97cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6602b1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 길이 150 -> 100으로 수정\n",
    "train_seq = pad_sequences(x_train, maxlen = 100, truncating = \"post\")\n",
    "val_seq = pad_sequences(x_val, maxlen = 100, truncating = \"post\")\n",
    "test_seq = pad_sequences(x_test, maxlen = 100, truncating = \"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "87bd5c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_oh_train = keras.utils.to_categorical(y_train)\n",
    "y_oh_val = keras.utils.to_categorical(y_val)\n",
    "y_oh_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fe0457",
   "metadata": {},
   "source": [
    "## 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "73827930",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sungj\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\embedding.py:81: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(1000, 100, input_shape = (100,)))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Conv1D(64, 5, activation = \"relu\"))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.MaxPool1D(4))\n",
    "model.add(keras.layers.LSTM(55))\n",
    "model.add(keras.layers.Dense(46, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3708d886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 강시님 모델\n",
    "model2 = keras.Sequential()\n",
    "model2.add(keras.layers.Embedding(1000, 100, input_shape = (100,)))\n",
    "model2.add(keras.layers.Dropout(0.5))\n",
    "model2.add(keras.layers.Conv1D(64, 5, activation = \"relu\"))\n",
    "model2.add(keras.layers.BatchNormalization())\n",
    "model2.add(keras.layers.MaxPool1D(4))\n",
    "model2.add(keras.layers.LSTM(128, dropout = 0.5))\n",
    "model2.add(keras.layers.Dropout(0.5))\n",
    "model2.add(keras.layers.Dense(46, activation = \"softmax\"))\n",
    "\n",
    "rmsprop = keras.optimizers.RMSprop(learning_rate = 5e-4)\n",
    "model2.compile(loss = \"categorical_crossentropy\", optimizer = rmsprop, metrics = [\"accuracy\"])\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 8, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c46883d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,000</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,064</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">26,400</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,576</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m100,000\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m400\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │          \u001b[38;5;34m32,064\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)                  │          \u001b[38;5;34m26,400\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m)                  │           \u001b[38;5;34m2,576\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">161,696</span> (631.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m161,696\u001b[0m (631.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">161,368</span> (630.34 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m161,368\u001b[0m (630.34 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">328</span> (1.28 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m328\u001b[0m (1.28 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ceda2967",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsprop = keras.optimizers.RMSprop(learning_rate = 5e-4)\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = rmsprop, metrics = [\"accuracy\"])\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 8, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f98fc7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - accuracy: 0.4184 - loss: 2.4429 - val_accuracy: 0.0000e+00 - val_loss: 4.3821\n",
      "Epoch 2/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 66ms/step - accuracy: 0.6152 - loss: 1.5856 - val_accuracy: 0.2499 - val_loss: 3.5740\n",
      "Epoch 3/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 70ms/step - accuracy: 0.6812 - loss: 1.3853 - val_accuracy: 0.6856 - val_loss: 1.4051\n",
      "Epoch 4/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 68ms/step - accuracy: 0.7024 - loss: 1.2624 - val_accuracy: 0.7229 - val_loss: 1.2036\n",
      "Epoch 5/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 64ms/step - accuracy: 0.7330 - loss: 1.1372 - val_accuracy: 0.7284 - val_loss: 1.1668\n",
      "Epoch 6/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 69ms/step - accuracy: 0.7639 - loss: 1.0412 - val_accuracy: 0.7568 - val_loss: 1.0640\n",
      "Epoch 7/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 66ms/step - accuracy: 0.7702 - loss: 0.9764 - val_accuracy: 0.7769 - val_loss: 1.0024\n",
      "Epoch 8/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 64ms/step - accuracy: 0.7817 - loss: 0.8946 - val_accuracy: 0.7819 - val_loss: 0.9726\n",
      "Epoch 9/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 70ms/step - accuracy: 0.7990 - loss: 0.8645 - val_accuracy: 0.7874 - val_loss: 0.9321\n",
      "Epoch 10/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 73ms/step - accuracy: 0.8138 - loss: 0.7789 - val_accuracy: 0.7952 - val_loss: 0.9068\n",
      "Epoch 11/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 71ms/step - accuracy: 0.8259 - loss: 0.7335 - val_accuracy: 0.7991 - val_loss: 0.9013\n",
      "Epoch 12/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 65ms/step - accuracy: 0.8269 - loss: 0.7023 - val_accuracy: 0.8047 - val_loss: 0.8699\n",
      "Epoch 13/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 68ms/step - accuracy: 0.8362 - loss: 0.6594 - val_accuracy: 0.8052 - val_loss: 0.8578\n",
      "Epoch 14/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 78ms/step - accuracy: 0.8437 - loss: 0.6557 - val_accuracy: 0.8080 - val_loss: 0.8305\n",
      "Epoch 15/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 88ms/step - accuracy: 0.8476 - loss: 0.6232 - val_accuracy: 0.8130 - val_loss: 0.8340\n",
      "Epoch 16/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 67ms/step - accuracy: 0.8588 - loss: 0.5916 - val_accuracy: 0.8175 - val_loss: 0.8334\n",
      "Epoch 17/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 66ms/step - accuracy: 0.8712 - loss: 0.5546 - val_accuracy: 0.8164 - val_loss: 0.8258\n",
      "Epoch 18/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 66ms/step - accuracy: 0.8593 - loss: 0.5622 - val_accuracy: 0.8141 - val_loss: 0.8352\n",
      "Epoch 19/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 68ms/step - accuracy: 0.8846 - loss: 0.4987 - val_accuracy: 0.8102 - val_loss: 0.8250\n",
      "Epoch 20/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 69ms/step - accuracy: 0.8751 - loss: 0.4998 - val_accuracy: 0.8164 - val_loss: 0.8120\n",
      "Epoch 21/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 72ms/step - accuracy: 0.8777 - loss: 0.4945 - val_accuracy: 0.8130 - val_loss: 0.8233\n",
      "Epoch 22/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 73ms/step - accuracy: 0.8871 - loss: 0.4601 - val_accuracy: 0.8119 - val_loss: 0.8130\n",
      "Epoch 23/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 76ms/step - accuracy: 0.8865 - loss: 0.4542 - val_accuracy: 0.8186 - val_loss: 0.8132\n",
      "Epoch 24/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 74ms/step - accuracy: 0.8961 - loss: 0.4344 - val_accuracy: 0.8108 - val_loss: 0.8125\n",
      "Epoch 25/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 71ms/step - accuracy: 0.8894 - loss: 0.4432 - val_accuracy: 0.8147 - val_loss: 0.8095\n",
      "Epoch 26/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 71ms/step - accuracy: 0.8915 - loss: 0.4335 - val_accuracy: 0.8186 - val_loss: 0.8151\n",
      "Epoch 27/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 71ms/step - accuracy: 0.9017 - loss: 0.3978 - val_accuracy: 0.8208 - val_loss: 0.8064\n",
      "Epoch 28/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 70ms/step - accuracy: 0.9041 - loss: 0.3994 - val_accuracy: 0.8225 - val_loss: 0.8110\n",
      "Epoch 29/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 75ms/step - accuracy: 0.9091 - loss: 0.3798 - val_accuracy: 0.8125 - val_loss: 0.8226\n",
      "Epoch 30/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 70ms/step - accuracy: 0.9053 - loss: 0.3778 - val_accuracy: 0.8214 - val_loss: 0.8211\n",
      "Epoch 31/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 69ms/step - accuracy: 0.9081 - loss: 0.3685 - val_accuracy: 0.8119 - val_loss: 0.8270\n",
      "Epoch 32/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 69ms/step - accuracy: 0.9095 - loss: 0.3618 - val_accuracy: 0.8214 - val_loss: 0.8196\n",
      "Epoch 33/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 69ms/step - accuracy: 0.9050 - loss: 0.3689 - val_accuracy: 0.8203 - val_loss: 0.8306\n",
      "Epoch 34/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 69ms/step - accuracy: 0.9097 - loss: 0.3502 - val_accuracy: 0.8147 - val_loss: 0.8360\n",
      "Epoch 35/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 67ms/step - accuracy: 0.9119 - loss: 0.3413 - val_accuracy: 0.8130 - val_loss: 0.8326\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_seq, y_oh_train, batch_size = 32, epochs = 100, validation_data = (val_seq, y_oh_val),\n",
    "                   callbacks = [early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a6aa81cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 76ms/step - accuracy: 0.3872 - loss: 2.5548 - val_accuracy: 0.4135 - val_loss: 2.7257\n",
      "Epoch 2/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 86ms/step - accuracy: 0.5230 - loss: 1.9098 - val_accuracy: 0.5097 - val_loss: 2.0753\n",
      "Epoch 3/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 88ms/step - accuracy: 0.5812 - loss: 1.6928 - val_accuracy: 0.6144 - val_loss: 1.7485\n",
      "Epoch 4/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 84ms/step - accuracy: 0.6266 - loss: 1.5239 - val_accuracy: 0.6539 - val_loss: 1.4691\n",
      "Epoch 5/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 89ms/step - accuracy: 0.6522 - loss: 1.3939 - val_accuracy: 0.6711 - val_loss: 1.3643\n",
      "Epoch 6/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 96ms/step - accuracy: 0.6846 - loss: 1.3040 - val_accuracy: 0.7045 - val_loss: 1.2784\n",
      "Epoch 7/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 85ms/step - accuracy: 0.6891 - loss: 1.2810 - val_accuracy: 0.7095 - val_loss: 1.2242\n",
      "Epoch 8/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 88ms/step - accuracy: 0.7049 - loss: 1.2203 - val_accuracy: 0.7262 - val_loss: 1.1680\n",
      "Epoch 9/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 93ms/step - accuracy: 0.7287 - loss: 1.1349 - val_accuracy: 0.7284 - val_loss: 1.1307\n",
      "Epoch 10/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 82ms/step - accuracy: 0.7287 - loss: 1.1265 - val_accuracy: 0.7351 - val_loss: 1.1145\n",
      "Epoch 11/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 81ms/step - accuracy: 0.7428 - loss: 1.0707 - val_accuracy: 0.7307 - val_loss: 1.1142\n",
      "Epoch 12/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 81ms/step - accuracy: 0.7546 - loss: 1.0379 - val_accuracy: 0.7468 - val_loss: 1.0930\n",
      "Epoch 13/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 83ms/step - accuracy: 0.7635 - loss: 1.0053 - val_accuracy: 0.7435 - val_loss: 1.0791\n",
      "Epoch 14/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 94ms/step - accuracy: 0.7663 - loss: 0.9977 - val_accuracy: 0.7618 - val_loss: 1.0452\n",
      "Epoch 15/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 91ms/step - accuracy: 0.7778 - loss: 0.9614 - val_accuracy: 0.7435 - val_loss: 1.0632\n",
      "Epoch 16/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 86ms/step - accuracy: 0.7683 - loss: 0.9788 - val_accuracy: 0.7524 - val_loss: 1.0507\n",
      "Epoch 17/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 87ms/step - accuracy: 0.7688 - loss: 0.9742 - val_accuracy: 0.7618 - val_loss: 1.0325\n",
      "Epoch 18/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 89ms/step - accuracy: 0.7739 - loss: 0.9633 - val_accuracy: 0.7724 - val_loss: 0.9989\n",
      "Epoch 19/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 89ms/step - accuracy: 0.7905 - loss: 0.9002 - val_accuracy: 0.7579 - val_loss: 1.0136\n",
      "Epoch 20/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 90ms/step - accuracy: 0.7893 - loss: 0.9166 - val_accuracy: 0.7668 - val_loss: 1.0018\n",
      "Epoch 21/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 89ms/step - accuracy: 0.7823 - loss: 0.9107 - val_accuracy: 0.7791 - val_loss: 0.9769\n",
      "Epoch 22/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 93ms/step - accuracy: 0.7862 - loss: 0.8989 - val_accuracy: 0.7730 - val_loss: 0.9901\n",
      "Epoch 23/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 93ms/step - accuracy: 0.7983 - loss: 0.8615 - val_accuracy: 0.7763 - val_loss: 0.9684\n",
      "Epoch 24/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 91ms/step - accuracy: 0.7985 - loss: 0.8822 - val_accuracy: 0.7613 - val_loss: 1.0134\n",
      "Epoch 25/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 88ms/step - accuracy: 0.7994 - loss: 0.8372 - val_accuracy: 0.7668 - val_loss: 1.0176\n",
      "Epoch 26/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 93ms/step - accuracy: 0.8106 - loss: 0.8336 - val_accuracy: 0.7774 - val_loss: 0.9613\n",
      "Epoch 27/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 99ms/step - accuracy: 0.8114 - loss: 0.8080 - val_accuracy: 0.7730 - val_loss: 0.9652\n",
      "Epoch 28/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 94ms/step - accuracy: 0.8184 - loss: 0.7862 - val_accuracy: 0.7657 - val_loss: 0.9814\n",
      "Epoch 29/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 92ms/step - accuracy: 0.8145 - loss: 0.7910 - val_accuracy: 0.7863 - val_loss: 0.9332\n",
      "Epoch 30/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 89ms/step - accuracy: 0.8185 - loss: 0.7848 - val_accuracy: 0.7813 - val_loss: 0.9394\n",
      "Epoch 31/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 84ms/step - accuracy: 0.8208 - loss: 0.7759 - val_accuracy: 0.7924 - val_loss: 0.9203\n",
      "Epoch 32/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 83ms/step - accuracy: 0.8279 - loss: 0.7492 - val_accuracy: 0.7891 - val_loss: 0.9246\n",
      "Epoch 33/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 84ms/step - accuracy: 0.8195 - loss: 0.7534 - val_accuracy: 0.7813 - val_loss: 0.9399\n",
      "Epoch 34/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 88ms/step - accuracy: 0.8250 - loss: 0.7543 - val_accuracy: 0.7846 - val_loss: 0.9281\n",
      "Epoch 35/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 92ms/step - accuracy: 0.8210 - loss: 0.7514 - val_accuracy: 0.7874 - val_loss: 0.9238\n",
      "Epoch 36/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 93ms/step - accuracy: 0.8245 - loss: 0.7543 - val_accuracy: 0.7858 - val_loss: 0.9346\n",
      "Epoch 37/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 91ms/step - accuracy: 0.8261 - loss: 0.7466 - val_accuracy: 0.7913 - val_loss: 0.9150\n",
      "Epoch 38/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 91ms/step - accuracy: 0.8320 - loss: 0.7227 - val_accuracy: 0.7980 - val_loss: 0.8996\n",
      "Epoch 39/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 93ms/step - accuracy: 0.8280 - loss: 0.7317 - val_accuracy: 0.7935 - val_loss: 0.9142\n",
      "Epoch 40/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 82ms/step - accuracy: 0.8359 - loss: 0.7184 - val_accuracy: 0.7930 - val_loss: 0.9232\n",
      "Epoch 41/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 93ms/step - accuracy: 0.8348 - loss: 0.7119 - val_accuracy: 0.7997 - val_loss: 0.8979\n",
      "Epoch 42/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 91ms/step - accuracy: 0.8374 - loss: 0.6994 - val_accuracy: 0.7980 - val_loss: 0.9105\n",
      "Epoch 43/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 88ms/step - accuracy: 0.8339 - loss: 0.7149 - val_accuracy: 0.7980 - val_loss: 0.8929\n",
      "Epoch 44/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 91ms/step - accuracy: 0.8382 - loss: 0.7127 - val_accuracy: 0.8013 - val_loss: 0.9034\n",
      "Epoch 45/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 87ms/step - accuracy: 0.8460 - loss: 0.6695 - val_accuracy: 0.8041 - val_loss: 0.8957\n",
      "Epoch 46/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 86ms/step - accuracy: 0.8390 - loss: 0.6934 - val_accuracy: 0.8024 - val_loss: 0.8956\n",
      "Epoch 47/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 89ms/step - accuracy: 0.8433 - loss: 0.6665 - val_accuracy: 0.7963 - val_loss: 0.8973\n",
      "Epoch 48/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 113ms/step - accuracy: 0.8379 - loss: 0.6728 - val_accuracy: 0.7969 - val_loss: 0.9120\n",
      "Epoch 49/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 90ms/step - accuracy: 0.8485 - loss: 0.6463 - val_accuracy: 0.8008 - val_loss: 0.8922\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 79ms/step - accuracy: 0.8502 - loss: 0.6434 - val_accuracy: 0.7991 - val_loss: 0.8944\n",
      "Epoch 51/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 82ms/step - accuracy: 0.8420 - loss: 0.6577 - val_accuracy: 0.8013 - val_loss: 0.8817\n",
      "Epoch 52/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 80ms/step - accuracy: 0.8489 - loss: 0.6463 - val_accuracy: 0.8114 - val_loss: 0.8850\n",
      "Epoch 53/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 79ms/step - accuracy: 0.8432 - loss: 0.6847 - val_accuracy: 0.8002 - val_loss: 0.9009\n",
      "Epoch 54/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 79ms/step - accuracy: 0.8540 - loss: 0.6343 - val_accuracy: 0.8036 - val_loss: 0.8983\n",
      "Epoch 55/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 80ms/step - accuracy: 0.8372 - loss: 0.6804 - val_accuracy: 0.8063 - val_loss: 0.8997\n",
      "Epoch 56/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 81ms/step - accuracy: 0.8444 - loss: 0.6509 - val_accuracy: 0.8058 - val_loss: 0.9052\n",
      "Epoch 57/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 81ms/step - accuracy: 0.8426 - loss: 0.6668 - val_accuracy: 0.8041 - val_loss: 0.9048\n",
      "Epoch 58/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 81ms/step - accuracy: 0.8571 - loss: 0.6088 - val_accuracy: 0.8108 - val_loss: 0.8876\n",
      "Epoch 59/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 81ms/step - accuracy: 0.8519 - loss: 0.6386 - val_accuracy: 0.8036 - val_loss: 0.9134\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(train_seq, y_oh_train, batch_size = 32, epochs = 100, validation_data = (val_seq, y_oh_val),\n",
    "                   callbacks = [early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c1d5d174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8198 - loss: 0.8184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8410524725914001, 0.812110424041748]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_seq, y_oh_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3ff98d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.8015 - loss: 0.9331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9597750306129456, 0.7920747995376587]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(test_seq, y_oh_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34942d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
