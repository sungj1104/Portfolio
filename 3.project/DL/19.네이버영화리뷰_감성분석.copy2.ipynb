{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8792896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b47c50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./data/ratings_train.txt\", sep = \"\\t\")\n",
    "test_df = pd.read_csv(\"./data/ratings_test.txt\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52ad1d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150000, 3), (50000, 3))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "655a0ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   id        150000 non-null  int64 \n",
      " 1   document  149995 non-null  object\n",
      " 2   label     150000 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1edc0002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "document    5\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 확인\n",
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "737d952a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "document    3\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4862a163",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.dropna(subset = [\"document\"])\n",
    "test_df = test_df.dropna(subset = [\"document\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc4d2a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((149995, 3), (49997, 3))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e303d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([75170, 74825], dtype=int64))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 종속변수 확인\n",
    "np.unique(train_df[\"label\"], return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34528251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6270596</td>\n",
       "      <td>굳 ㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9274899</td>\n",
       "      <td>GDNTOPCLASSINTHECLUB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8544678</td>\n",
       "      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6825595</td>\n",
       "      <td>지루하지는 않은데 완전 막장임... 돈주고 보기에는....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6723715</td>\n",
       "      <td>3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                           document  label\n",
       "0  6270596                                                굳 ㅋ      1\n",
       "1  9274899                               GDNTOPCLASSINTHECLUB      0\n",
       "2  8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
       "3  6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n",
       "4  6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2617349c",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94a692fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글 이외의 문자들 제거\n",
    "train_df[\"document\"] = train_df[\"document\"].map(lambda x: re.sub(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣 ]\", \"\", x))\n",
    "test_df[\"document\"] = test_df[\"document\"].map(lambda x: re.sub(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣 ]\", \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82e85490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 솔직히 재미는 없다평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                  아 더빙 진짜 짜증나네요 목소리      0\n",
       "1   3819312                         흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                          교도소 이야기구먼 솔직히 재미는 없다평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...      1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da7ceacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6270596</td>\n",
       "      <td>굳 ㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9274899</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8544678</td>\n",
       "      <td>뭐야 이 평점들은 나쁘진 않지만 점 짜리는 더더욱 아니잖아</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6825595</td>\n",
       "      <td>지루하지는 않은데 완전 막장임 돈주고 보기에는</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6723715</td>\n",
       "      <td>만 아니었어도 별 다섯 개 줬을텐데 왜 로 나와서 제 심기를 불편하게 하죠</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                   document  label\n",
       "0  6270596                                        굳 ㅋ      1\n",
       "1  9274899                                                 0\n",
       "2  8544678           뭐야 이 평점들은 나쁘진 않지만 점 짜리는 더더욱 아니잖아      0\n",
       "3  6825595                  지루하지는 않은데 완전 막장임 돈주고 보기에는      0\n",
       "4  6723715  만 아니었어도 별 다섯 개 줬을텐데 왜 로 나와서 제 심기를 불편하게 하죠      0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b096656d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df[\"document\"].map(lambda x: len(x.strip()) >= 1)]\n",
    "test_df = test_df[test_df[\"document\"].map(lambda x: len(x.strip()) >= 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "500f4465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((148740, 3), (49575, 3))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff108095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46599</th>\n",
       "      <td>9682597</td>\n",
       "      <td>그리고 내 감정을 불러 일으켰다</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43436</th>\n",
       "      <td>9582856</td>\n",
       "      <td>그리고 내 감정을 불러 일으켰다</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123713</th>\n",
       "      <td>9582855</td>\n",
       "      <td>그리고 내 감정을 불러 일으켰다</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93364</th>\n",
       "      <td>171409</td>\n",
       "      <td>가입  추천바람</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138373</th>\n",
       "      <td>171407</td>\n",
       "      <td>가입  추천바람</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57831</th>\n",
       "      <td>3906478</td>\n",
       "      <td>흥미진진</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8446</th>\n",
       "      <td>5158304</td>\n",
       "      <td>힐러리 더프의 매력에 빠지다</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72688</th>\n",
       "      <td>5153363</td>\n",
       "      <td>힐러리 더프의 매력에 빠지다</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26889</th>\n",
       "      <td>7971814</td>\n",
       "      <td>힘들다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122612</th>\n",
       "      <td>7415842</td>\n",
       "      <td>힘들다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6449 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id               document  label\n",
       "46599   9682597      그리고 내 감정을 불러 일으켰다      1\n",
       "43436   9582856      그리고 내 감정을 불러 일으켰다      1\n",
       "123713  9582855      그리고 내 감정을 불러 일으켰다      1\n",
       "93364    171409               가입  추천바람      1\n",
       "138373   171407               가입  추천바람      1\n",
       "...         ...                    ...    ...\n",
       "57831   3906478                   흥미진진      1\n",
       "8446    5158304        힐러리 더프의 매력에 빠지다      1\n",
       "72688   5153363        힐러리 더프의 매력에 빠지다      1\n",
       "26889   7971814                    힘들다      0\n",
       "122612  7415842                    힘들다      0\n",
       "\n",
       "[6449 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복 데이터 확인\n",
    "train_df[train_df[\"document\"].duplicated(keep = False)].sort_values(\"document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b3d7d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복제거\n",
    "train_df = train_df.drop_duplicates(subset = [\"document\"], keep =\"first\")\n",
    "test_df = test_df.drop_duplicates(subset = [\"document\"], keep =\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8362ff1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((143660, 3), (48403, 3))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f421946a",
   "metadata": {},
   "source": [
    "# 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "547184dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ebb66d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['아', '더빙', '진짜', '짜증나네요', '목소리']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt.morphs(\"아 더빙 진짜 짜증나네요 목소리\", stem = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd6d0467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['아', '더빙', '진짜', '짜증나다', '목소리']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt.morphs(\"아 더빙 진짜 짜증나네요 목소리\", stem = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd7e6c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['더빙', '진짜', '목소리']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt.nouns(\"아 더빙 진짜 짜증나네요 목소리\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84b8b133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('아', 'Exclamation'),\n",
       " ('더빙', 'Noun'),\n",
       " ('진짜', 'Noun'),\n",
       " ('짜증나네요', 'Adjective'),\n",
       " ('목소리', 'Noun')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt.pos(\"아 더빙 진짜 짜증나네요 목소리\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f1a76a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 22min 43s\n",
      "Wall time: 21min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df[\"token\"] = train_df[\"document\"].map(lambda x: okt.morphs(x, stem = True))\n",
    "test_df[\"token\"] = test_df[\"document\"].map(lambda x: okt.morphs(x, stem = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5682e9ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "      <td>[아, 더빙, 진짜, 짜증나다, 목소리]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "      <td>[흠, 포스터, 보고, 초딩, 영화, 줄, 오버, 연기, 조차, 가볍다, 않다]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "      <td>[너, 무재, 밓었, 다그, 래서, 보다, 추천, 한, 다]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 솔직히 재미는 없다평점 조정</td>\n",
       "      <td>0</td>\n",
       "      <td>[교도소, 이야기, 구먼, 솔직하다, 재미, 는, 없다, 평점, 조정]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...</td>\n",
       "      <td>1</td>\n",
       "      <td>[사이, 몬페, 그, 의, 익살스럽다, 연기, 가, 돋보이다, 영화, 스파이더맨, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5403919</td>\n",
       "      <td>막 걸음마 뗀 세부터 초등학교 학년생인 살용영화ㅋㅋㅋ별반개도 아까움</td>\n",
       "      <td>0</td>\n",
       "      <td>[막, 걸음, 마, 떼다, 세, 부터, 초등학교, 학년, 생인, 살다, 영화, ㅋㅋ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7797314</td>\n",
       "      <td>원작의 긴장감을 제대로 살려내지못했다</td>\n",
       "      <td>0</td>\n",
       "      <td>[원작, 의, 긴장감, 을, 제대로, 살리다, 하다]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9443947</td>\n",
       "      <td>별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지정말 발로해도 그것보단 낫...</td>\n",
       "      <td>0</td>\n",
       "      <td>[별, 반개, 도, 아깝다, 욕, 나오다, 이응경, 길용우, 연, 기, 생활, 이,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7156791</td>\n",
       "      <td>액션이 없는데도 재미 있는 몇안되는 영화</td>\n",
       "      <td>1</td>\n",
       "      <td>[액션, 이, 없다, 재미, 있다, 몇, 안되다, 영화]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5912145</td>\n",
       "      <td>왜케 평점이 낮은건데 꽤 볼만한데 헐리우드식 화려함에만 너무 길들여져 있나</td>\n",
       "      <td>1</td>\n",
       "      <td>[왜케, 평점, 이, 낮다, 꽤, 볼, 만, 한, 데, 헐리우드, 식, 화려하다, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9008700</td>\n",
       "      <td>걍인피니트가짱이다진짜짱이다</td>\n",
       "      <td>1</td>\n",
       "      <td>[걍, 인피니트, 가, 짱, 이다, 진짜, 짱, 이다]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10217543</td>\n",
       "      <td>볼때마다 눈물나서 죽겠다년대의 향수자극허진호는 감성절제멜로의 달인이다</td>\n",
       "      <td>1</td>\n",
       "      <td>[볼때, 마다, 눈물나다, 죽다, 년대, 의, 향수, 자, 극, 허진호, 는, 감성...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5957425</td>\n",
       "      <td>울면서 손들고 횡단보도 건널때 뛰쳐나올뻔 이범수 연기 드럽게못해</td>\n",
       "      <td>0</td>\n",
       "      <td>[울면, 서, 손, 들, 고, 횡단보도, 건너다, 때, 뛰다, 치다, 올, 뻔, 이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8628627</td>\n",
       "      <td>담백하고 깔끔해서 좋다 신문기사로만 보다 보면 자꾸 잊어버린다 그들도 사람이었다는 것을</td>\n",
       "      <td>1</td>\n",
       "      <td>[담백하다, 깔끔하다, 좋다, 신, 문, 기, 사, 로만, 보다, 보다, 자꾸, 잊...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9864035</td>\n",
       "      <td>취향은 존중한다지만 진짜 내생에 극장에서 본 영화중 가장 노잼 노감동임 스토리도 어...</td>\n",
       "      <td>0</td>\n",
       "      <td>[취향, 은, 존중, 한, 다지, 만, 진짜, 내생, 에, 극장, 에서, 보다, 영...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6852435</td>\n",
       "      <td>ㄱ냥 매번 긴장되고 재밋음ㅠㅠ</td>\n",
       "      <td>1</td>\n",
       "      <td>[ㄱ, 냥, 매번, 긴장, 되다, 재밋음, ㅠㅠ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9143163</td>\n",
       "      <td>참 사람들 웃긴게 바스코가 이기면 락스코라고 까고바비가 이기면 아이돌이라고 깐다그냥...</td>\n",
       "      <td>1</td>\n",
       "      <td>[차다, 사람, 들, 웃기다, 바스코, 가, 이기, 면, 락스, 코, 라고, 끄다,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4891476</td>\n",
       "      <td>굿바이 레닌 표절인것은 이해하는데 왜 뒤로 갈수록 재미없어지냐</td>\n",
       "      <td>0</td>\n",
       "      <td>[굿바이, 레닌, 표절, 인, 것, 은, 이해, 하다, 왜, 뒤, 로, 갈수록, 재...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7465483</td>\n",
       "      <td>이건 정말 깨알 캐스팅과 질퍽하지않은 산뜻한 내용구성이 잘 버무러진 깨알일드</td>\n",
       "      <td>1</td>\n",
       "      <td>[이건, 정말, 깨알, 캐스팅, 과, 질퍽, 하, 지, 않다, 산뜻하다, 내, 용구...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3989148</td>\n",
       "      <td>약탈자를 위한 변명 이라 저놈들은 착한놈들 절대 아닌걸요</td>\n",
       "      <td>1</td>\n",
       "      <td>[약탈, 자, 를, 위, 한, 변명, 이르다, 저, 놈, 들, 은, 착하다, 놈, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                           document  label  \\\n",
       "0    9976970                                  아 더빙 진짜 짜증나네요 목소리      0   \n",
       "1    3819312                         흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나      1   \n",
       "2   10265843                                  너무재밓었다그래서보는것을추천한다      0   \n",
       "3    9045019                          교도소 이야기구먼 솔직히 재미는 없다평점 조정      0   \n",
       "4    6483659  사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...      1   \n",
       "5    5403919              막 걸음마 뗀 세부터 초등학교 학년생인 살용영화ㅋㅋㅋ별반개도 아까움      0   \n",
       "6    7797314                               원작의 긴장감을 제대로 살려내지못했다      0   \n",
       "7    9443947  별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지정말 발로해도 그것보단 낫...      0   \n",
       "8    7156791                             액션이 없는데도 재미 있는 몇안되는 영화      1   \n",
       "9    5912145          왜케 평점이 낮은건데 꽤 볼만한데 헐리우드식 화려함에만 너무 길들여져 있나      1   \n",
       "10   9008700                                     걍인피니트가짱이다진짜짱이다      1   \n",
       "11  10217543             볼때마다 눈물나서 죽겠다년대의 향수자극허진호는 감성절제멜로의 달인이다      1   \n",
       "12   5957425                울면서 손들고 횡단보도 건널때 뛰쳐나올뻔 이범수 연기 드럽게못해      0   \n",
       "13   8628627   담백하고 깔끔해서 좋다 신문기사로만 보다 보면 자꾸 잊어버린다 그들도 사람이었다는 것을      1   \n",
       "14   9864035  취향은 존중한다지만 진짜 내생에 극장에서 본 영화중 가장 노잼 노감동임 스토리도 어...      0   \n",
       "15   6852435                                   ㄱ냥 매번 긴장되고 재밋음ㅠㅠ      1   \n",
       "16   9143163  참 사람들 웃긴게 바스코가 이기면 락스코라고 까고바비가 이기면 아이돌이라고 깐다그냥...      1   \n",
       "17   4891476                 굿바이 레닌 표절인것은 이해하는데 왜 뒤로 갈수록 재미없어지냐      0   \n",
       "18   7465483         이건 정말 깨알 캐스팅과 질퍽하지않은 산뜻한 내용구성이 잘 버무러진 깨알일드      1   \n",
       "19   3989148                    약탈자를 위한 변명 이라 저놈들은 착한놈들 절대 아닌걸요      1   \n",
       "\n",
       "                                                token  \n",
       "0                              [아, 더빙, 진짜, 짜증나다, 목소리]  \n",
       "1        [흠, 포스터, 보고, 초딩, 영화, 줄, 오버, 연기, 조차, 가볍다, 않다]  \n",
       "2                   [너, 무재, 밓었, 다그, 래서, 보다, 추천, 한, 다]  \n",
       "3             [교도소, 이야기, 구먼, 솔직하다, 재미, 는, 없다, 평점, 조정]  \n",
       "4   [사이, 몬페, 그, 의, 익살스럽다, 연기, 가, 돋보이다, 영화, 스파이더맨, ...  \n",
       "5   [막, 걸음, 마, 떼다, 세, 부터, 초등학교, 학년, 생인, 살다, 영화, ㅋㅋ...  \n",
       "6                       [원작, 의, 긴장감, 을, 제대로, 살리다, 하다]  \n",
       "7   [별, 반개, 도, 아깝다, 욕, 나오다, 이응경, 길용우, 연, 기, 생활, 이,...  \n",
       "8                     [액션, 이, 없다, 재미, 있다, 몇, 안되다, 영화]  \n",
       "9   [왜케, 평점, 이, 낮다, 꽤, 볼, 만, 한, 데, 헐리우드, 식, 화려하다, ...  \n",
       "10                     [걍, 인피니트, 가, 짱, 이다, 진짜, 짱, 이다]  \n",
       "11  [볼때, 마다, 눈물나다, 죽다, 년대, 의, 향수, 자, 극, 허진호, 는, 감성...  \n",
       "12  [울면, 서, 손, 들, 고, 횡단보도, 건너다, 때, 뛰다, 치다, 올, 뻔, 이...  \n",
       "13  [담백하다, 깔끔하다, 좋다, 신, 문, 기, 사, 로만, 보다, 보다, 자꾸, 잊...  \n",
       "14  [취향, 은, 존중, 한, 다지, 만, 진짜, 내생, 에, 극장, 에서, 보다, 영...  \n",
       "15                        [ㄱ, 냥, 매번, 긴장, 되다, 재밋음, ㅠㅠ]  \n",
       "16  [차다, 사람, 들, 웃기다, 바스코, 가, 이기, 면, 락스, 코, 라고, 끄다,...  \n",
       "17  [굿바이, 레닌, 표절, 인, 것, 은, 이해, 하다, 왜, 뒤, 로, 갈수록, 재...  \n",
       "18  [이건, 정말, 깨알, 캐스팅, 과, 질퍽, 하, 지, 않다, 산뜻하다, 내, 용구...  \n",
       "19  [약탈, 자, 를, 위, 한, 변명, 이르다, 저, 놈, 들, 은, 착하다, 놈, ...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76260b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"nsmc_ratings_train_pre.csv\", index = False)\n",
    "test_df.to_csv(\"nsmc_ratings_test_pre.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "692126cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./nsmc_ratings_train_pre.csv\")\n",
    "test_df = pd.read_csv(\"./nsmc_ratings_test_pre.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a9e42df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_df.loc[0, \"token\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74c19552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 타입이 문자열이라면 리스트로 바꾸는 법\n",
    "train_df[\"token\"] = train_df[\"token\"].map(lambda x: eval(x))\n",
    "test_df[\"token\"] = test_df[\"token\"].map(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f9eb603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((143660, 4), (48403, 4))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebb1291",
   "metadata": {},
   "source": [
    "train_df[\"token\"] = train_df[\"token\"].map(lambda x: [i for i in x if len(i) > 1])\n",
    "test_df[\"token\"] = test_df[\"token\"].map(lambda x: [i for i in x if len(i) > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92407d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((143660, 4), (48403, 4))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29e3537b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "      <td>[아, 더빙, 진짜, 짜증나다, 목소리]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "      <td>[흠, 포스터, 보고, 초딩, 영화, 줄, 오버, 연기, 조차, 가볍다, 않다]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "      <td>[너, 무재, 밓었, 다그, 래서, 보다, 추천, 한, 다]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 솔직히 재미는 없다평점 조정</td>\n",
       "      <td>0</td>\n",
       "      <td>[교도소, 이야기, 구먼, 솔직하다, 재미, 는, 없다, 평점, 조정]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...</td>\n",
       "      <td>1</td>\n",
       "      <td>[사이, 몬페, 그, 의, 익살스럽다, 연기, 가, 돋보이다, 영화, 스파이더맨, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label  \\\n",
       "0   9976970                                  아 더빙 진짜 짜증나네요 목소리      0   \n",
       "1   3819312                         흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나      1   \n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0   \n",
       "3   9045019                          교도소 이야기구먼 솔직히 재미는 없다평점 조정      0   \n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...      1   \n",
       "\n",
       "                                               token  \n",
       "0                             [아, 더빙, 진짜, 짜증나다, 목소리]  \n",
       "1       [흠, 포스터, 보고, 초딩, 영화, 줄, 오버, 연기, 조차, 가볍다, 않다]  \n",
       "2                  [너, 무재, 밓었, 다그, 래서, 보다, 추천, 한, 다]  \n",
       "3            [교도소, 이야기, 구먼, 솔직하다, 재미, 는, 없다, 평점, 조정]  \n",
       "4  [사이, 몬페, 그, 의, 익살스럽다, 연기, 가, 돋보이다, 영화, 스파이더맨, ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85a425ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df[\"token\"]. map(lambda x: len(x) > 0)]\n",
    "test_df = test_df[test_df[\"token\"]. map(lambda x: len(x) > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a78b054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((143660, 4), (48403, 4))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461f2403",
   "metadata": {},
   "source": [
    "# 정수인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f77f436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae317fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 집합 생성\n",
    "# 등장 빈도 수가 높은 순서대로 정수값 부여\n",
    "tokenizer.fit_on_texts(train_df[\"token\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11975c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'이': 1,\n",
       " '영화': 2,\n",
       " '보다': 3,\n",
       " '하다': 4,\n",
       " '의': 5,\n",
       " '에': 6,\n",
       " '가': 7,\n",
       " '을': 8,\n",
       " '도': 9,\n",
       " '들': 10,\n",
       " '는': 11,\n",
       " '를': 12,\n",
       " '은': 13,\n",
       " '없다': 14,\n",
       " '이다': 15,\n",
       " '있다': 16,\n",
       " '좋다': 17,\n",
       " '너무': 18,\n",
       " '다': 19,\n",
       " '정말': 20,\n",
       " '한': 21,\n",
       " '되다': 22,\n",
       " '적': 23,\n",
       " '만': 24,\n",
       " '재밌다': 25,\n",
       " '같다': 26,\n",
       " '진짜': 27,\n",
       " '으로': 28,\n",
       " '로': 29,\n",
       " '아니다': 30,\n",
       " '않다': 31,\n",
       " '점': 32,\n",
       " '에서': 33,\n",
       " '만들다': 34,\n",
       " '과': 35,\n",
       " '나오다': 36,\n",
       " '연기': 37,\n",
       " '것': 38,\n",
       " '평점': 39,\n",
       " '내': 40,\n",
       " '최고': 41,\n",
       " '그': 42,\n",
       " '나': 43,\n",
       " '안': 44,\n",
       " '인': 45,\n",
       " '스토리': 46,\n",
       " '생각': 47,\n",
       " '못': 48,\n",
       " '왜': 49,\n",
       " '드라마': 50,\n",
       " '게': 51,\n",
       " '사람': 52,\n",
       " '감동': 53,\n",
       " '보고': 54,\n",
       " '이렇다': 55,\n",
       " '고': 56,\n",
       " '말': 57,\n",
       " '아깝다': 58,\n",
       " '더': 59,\n",
       " '배우': 60,\n",
       " '때': 61,\n",
       " 'ㅋㅋ': 62,\n",
       " '와': 63,\n",
       " '아': 64,\n",
       " '감독': 65,\n",
       " '거': 66,\n",
       " '그냥': 67,\n",
       " '요': 68,\n",
       " '재미있다': 69,\n",
       " '재미': 70,\n",
       " '시간': 71,\n",
       " '내용': 72,\n",
       " '까지': 73,\n",
       " '뭐': 74,\n",
       " '중': 75,\n",
       " '주다': 76,\n",
       " '좀': 77,\n",
       " '자다': 78,\n",
       " '하고': 79,\n",
       " '지루하다': 80,\n",
       " '수': 81,\n",
       " '재미없다': 82,\n",
       " '네': 83,\n",
       " '쓰레기': 84,\n",
       " '모르다': 85,\n",
       " '가다': 86,\n",
       " '들다': 87,\n",
       " '그렇다': 88,\n",
       " '싶다': 89,\n",
       " '지': 90,\n",
       " '작품': 91,\n",
       " '사랑': 92,\n",
       " '알다': 93,\n",
       " '하나': 94,\n",
       " '다시': 95,\n",
       " '마지막': 96,\n",
       " '볼': 97,\n",
       " '잘': 98,\n",
       " '정도': 99,\n",
       " '저': 100,\n",
       " '이건': 101,\n",
       " '오다': 102,\n",
       " '완전': 103,\n",
       " 'ㅋ': 104,\n",
       " 'ㅠㅠ': 105,\n",
       " '많다': 106,\n",
       " '처음': 107,\n",
       " 'ㅋㅋㅋ': 108,\n",
       " '장면': 109,\n",
       " '액션': 110,\n",
       " '주인공': 111,\n",
       " '이렇게': 112,\n",
       " '안되다': 113,\n",
       " '걸': 114,\n",
       " '차다': 115,\n",
       " '나다': 116,\n",
       " '개': 117,\n",
       " '하': 118,\n",
       " '돈': 119,\n",
       " '이야기': 120,\n",
       " '지금': 121,\n",
       " '최악': 122,\n",
       " '넘다': 123,\n",
       " '느낌': 124,\n",
       " '연출': 125,\n",
       " '임': 126,\n",
       " '라': 127,\n",
       " 'ㅡㅡ': 128,\n",
       " '인데': 129,\n",
       " '듯': 130,\n",
       " '끝': 131,\n",
       " '좋아하다': 132,\n",
       " '명작': 133,\n",
       " '그리고': 134,\n",
       " '년': 135,\n",
       " '받다': 136,\n",
       " '역시': 137,\n",
       " '기': 138,\n",
       " '별로': 139,\n",
       " '많이': 140,\n",
       " '남다': 141,\n",
       " '별': 142,\n",
       " '이해': 143,\n",
       " '면': 144,\n",
       " '난': 145,\n",
       " '이런': 146,\n",
       " '이영화': 147,\n",
       " '분': 148,\n",
       " '느끼다': 149,\n",
       " '괜찮다': 150,\n",
       " '라고': 151,\n",
       " '또': 152,\n",
       " '버리다': 153,\n",
       " '이나': 154,\n",
       " '때문': 155,\n",
       " '성': 156,\n",
       " '여자': 157,\n",
       " '서': 158,\n",
       " '부터': 159,\n",
       " '일': 160,\n",
       " '먹다': 161,\n",
       " '아름답다': 162,\n",
       " '해주다': 163,\n",
       " '꼭': 164,\n",
       " '보기': 165,\n",
       " '엔': 166,\n",
       " '이고': 167,\n",
       " '두': 168,\n",
       " '무슨': 169,\n",
       " '여': 170,\n",
       " '에게': 171,\n",
       " '기억': 172,\n",
       " '결말': 173,\n",
       " '편': 174,\n",
       " '대': 175,\n",
       " 'ㅎㅎ': 176,\n",
       " '랑': 177,\n",
       " '야': 178,\n",
       " '아쉽다': 179,\n",
       " '마음': 180,\n",
       " '소재': 181,\n",
       " '영': 182,\n",
       " '짱': 183,\n",
       " '뻔하다': 184,\n",
       " '인생': 185,\n",
       " '끄다': 186,\n",
       " '애': 187,\n",
       " '보여주다': 188,\n",
       " '님': 189,\n",
       " '어떻다': 190,\n",
       " '전': 191,\n",
       " '없이': 192,\n",
       " '수준': 193,\n",
       " '어리다': 194,\n",
       " '무섭다': 195,\n",
       " '현실': 196,\n",
       " '맞다': 197,\n",
       " '한번': 198,\n",
       " '속': 199,\n",
       " '씨': 200,\n",
       " '가장': 201,\n",
       " '급': 202,\n",
       " '본': 203,\n",
       " '웃기다': 204,\n",
       " '반전': 205,\n",
       " '매력': 206,\n",
       " '재다': 207,\n",
       " '되어다': 208,\n",
       " '전개': 209,\n",
       " '제': 210,\n",
       " '라는': 211,\n",
       " '한국': 212,\n",
       " '남자': 213,\n",
       " '끝나다': 214,\n",
       " '가슴': 215,\n",
       " '뿐': 216,\n",
       " '낮다': 217,\n",
       " '말다': 218,\n",
       " '아이': 219,\n",
       " '죽다': 220,\n",
       " '슬프다': 221,\n",
       " '음악': 222,\n",
       " '유치하다': 223,\n",
       " '높다': 224,\n",
       " '알': 225,\n",
       " '니': 226,\n",
       " '다른': 227,\n",
       " '멋지다': 228,\n",
       " '원작': 229,\n",
       " '줄': 230,\n",
       " '늘다': 231,\n",
       " '인간': 232,\n",
       " '화': 233,\n",
       " '솔직하다': 234,\n",
       " '크다': 235,\n",
       " '우리': 236,\n",
       " '추천': 237,\n",
       " '눈물': 238,\n",
       " '냐': 239,\n",
       " '쓰다': 240,\n",
       " '살다': 241,\n",
       " '인지': 242,\n",
       " '모든': 243,\n",
       " '지만': 244,\n",
       " '내다': 245,\n",
       " '함': 246,\n",
       " '자체': 247,\n",
       " '번': 248,\n",
       " '야하다': 249,\n",
       " '눈': 250,\n",
       " '허다': 251,\n",
       " '찍다': 252,\n",
       " '하지만': 253,\n",
       " '인가': 254,\n",
       " '캐릭터': 255,\n",
       " '보이다': 256,\n",
       " '코미디': 257,\n",
       " '처럼': 258,\n",
       " '대한': 259,\n",
       " 'ㅋㅋㅋㅋ': 260,\n",
       " '움': 261,\n",
       " '모두': 262,\n",
       " '이상': 263,\n",
       " '뭔가': 264,\n",
       " 'ㅠ': 265,\n",
       " '돼다': 266,\n",
       " '이네': 267,\n",
       " '전혀': 268,\n",
       " '대박': 269,\n",
       " '이쁘다': 270,\n",
       " '연기력': 271,\n",
       " '건지다': 272,\n",
       " '여운': 273,\n",
       " '미치다': 274,\n",
       " '그래도': 275,\n",
       " '개봉': 276,\n",
       " '공감': 277,\n",
       " '짜증나다': 278,\n",
       " '일본': 279,\n",
       " '기대': 280,\n",
       " '기대하다': 281,\n",
       " '근데': 282,\n",
       " '시리즈': 283,\n",
       " '중간': 284,\n",
       " '지다': 285,\n",
       " '표현': 286,\n",
       " '영상': 287,\n",
       " '부분': 288,\n",
       " '아주': 289,\n",
       " '모습': 290,\n",
       " '에는': 291,\n",
       " '작': 292,\n",
       " '제목': 293,\n",
       " '계속': 294,\n",
       " '이랑': 295,\n",
       " '치다': 296,\n",
       " '이라': 297,\n",
       " '귀엽다': 298,\n",
       " '시키다': 299,\n",
       " 'ㅜㅜ': 300,\n",
       " '가족': 301,\n",
       " '내내': 302,\n",
       " '뭔': 303,\n",
       " '믿다': 304,\n",
       " '보지': 305,\n",
       " '자': 306,\n",
       " '진심': 307,\n",
       " '몰입': 308,\n",
       " '밖에': 309,\n",
       " '실망': 310,\n",
       " '후': 311,\n",
       " '짜다': 312,\n",
       " '기분': 313,\n",
       " '대단하다': 314,\n",
       " '연': 315,\n",
       " '작가': 316,\n",
       " '건': 317,\n",
       " '떨어지다': 318,\n",
       " 'ㅎ': 319,\n",
       " '잔잔하다': 320,\n",
       " '이제': 321,\n",
       " '위': 322,\n",
       " '웃다': 323,\n",
       " '요즘': 324,\n",
       " '공포': 325,\n",
       " '빠지다': 326,\n",
       " '스릴러': 327,\n",
       " '이라는': 328,\n",
       " '시': 329,\n",
       " '감': 330,\n",
       " '긴장감': 331,\n",
       " '개인': 332,\n",
       " '용': 333,\n",
       " '잼': 334,\n",
       " '조금': 335,\n",
       " '애니': 336,\n",
       " '대사': 337,\n",
       " '이유': 338,\n",
       " '알바': 339,\n",
       " '특히': 340,\n",
       " '제대로': 341,\n",
       " '삶': 342,\n",
       " '극장': 343,\n",
       " '울다': 344,\n",
       " '노래': 345,\n",
       " '한테': 346,\n",
       " '딱': 347,\n",
       " '점도': 348,\n",
       " '욕': 349,\n",
       " '잇다': 350,\n",
       " '점수': 351,\n",
       " '시작': 352,\n",
       " '막장': 353,\n",
       " '이란': 354,\n",
       " '나름': 355,\n",
       " '오랜': 356,\n",
       " '극': 357,\n",
       " '이상하다': 358,\n",
       " '이지': 359,\n",
       " '예쁘다': 360,\n",
       " '깊다': 361,\n",
       " '굿': 362,\n",
       " '에도': 363,\n",
       " '차라리': 364,\n",
       " '제일': 365,\n",
       " '놈': 366,\n",
       " '노잼': 367,\n",
       " '느껴지다': 368,\n",
       " '친구': 369,\n",
       " '해보다': 370,\n",
       " '영화로': 371,\n",
       " '당시': 372,\n",
       " '같이': 373,\n",
       " '어설프다': 374,\n",
       " '의미': 375,\n",
       " '빼다': 376,\n",
       " '절대': 377,\n",
       " '식': 378,\n",
       " '력': 379,\n",
       " '위해': 380,\n",
       " '세상': 381,\n",
       " '류': 382,\n",
       " '따뜻하다': 383,\n",
       " '찾다': 384,\n",
       " '몇': 385,\n",
       " '아직도': 386,\n",
       " '훌륭하다': 387,\n",
       " '이라고': 388,\n",
       " '년대': 389,\n",
       " '공포영화': 390,\n",
       " '명': 391,\n",
       " '미국': 392,\n",
       " '웃음': 393,\n",
       " '도대체': 394,\n",
       " '생각나다': 395,\n",
       " '설정': 396,\n",
       " '아무': 397,\n",
       " '앞': 398,\n",
       " '걍': 399,\n",
       " '무엇': 400,\n",
       " '마다': 401,\n",
       " '그리다': 402,\n",
       " '너': 403,\n",
       " '오': 404,\n",
       " '어': 405,\n",
       " '죽이다': 406,\n",
       " '초반': 407,\n",
       " '써다': 408,\n",
       " '다르다': 409,\n",
       " '데': 410,\n",
       " '물': 411,\n",
       " '뭘': 412,\n",
       " '우리나라': 413,\n",
       " '출연': 414,\n",
       " '따다': 415,\n",
       " '수작': 416,\n",
       " '힘들다': 417,\n",
       " '사실': 418,\n",
       " '싫다': 419,\n",
       " '답답하다': 420,\n",
       " '엄청': 421,\n",
       " '추억': 422,\n",
       " '가지': 423,\n",
       " '반': 424,\n",
       " '한국영': 425,\n",
       " '남': 426,\n",
       " '놓다': 427,\n",
       " '멋있다': 428,\n",
       " '신선하다': 429,\n",
       " '시나리오': 430,\n",
       " '관객': 431,\n",
       " '분위기': 432,\n",
       " '아프다': 433,\n",
       " '이야': 434,\n",
       " '대다': 435,\n",
       " '기다': 436,\n",
       " '팬': 437,\n",
       " '시대': 438,\n",
       " '해': 439,\n",
       " '어이없다': 440,\n",
       " '지루함': 441,\n",
       " '필요없다': 442,\n",
       " '세': 443,\n",
       " '장난': 444,\n",
       " '잊다': 445,\n",
       " '살': 446,\n",
       " '자신': 447,\n",
       " '나쁘다': 448,\n",
       " '소리': 449,\n",
       " '이딴': 450,\n",
       " '감정': 451,\n",
       " '졸작': 452,\n",
       " '엔딩': 453,\n",
       " '이지만': 454,\n",
       " '영화관': 455,\n",
       " '엄마': 456,\n",
       " '안타깝다': 457,\n",
       " '오늘': 458,\n",
       " '준': 459,\n",
       " '멀다': 460,\n",
       " '구': 461,\n",
       " '결국': 462,\n",
       " '접': 463,\n",
       " '정신': 464,\n",
       " '제발': 465,\n",
       " '주': 466,\n",
       " '봄': 467,\n",
       " '인상': 468,\n",
       " '부족하다': 469,\n",
       " '배우다': 470,\n",
       " '스럽다': 471,\n",
       " '원': 472,\n",
       " '더빙': 473,\n",
       " '포스터': 474,\n",
       " '캐스팅': 475,\n",
       " '라면': 476,\n",
       " '평가': 477,\n",
       " '더럽다': 478,\n",
       " '코믹': 479,\n",
       " '문제': 480,\n",
       " '니까': 481,\n",
       " '얼마나': 482,\n",
       " '아무리': 483,\n",
       " '엉': 484,\n",
       " '최고다': 485,\n",
       " '애니메이션': 486,\n",
       " '함께': 487,\n",
       " '어색하다': 488,\n",
       " '그저': 489,\n",
       " '몰입도': 490,\n",
       " '신': 491,\n",
       " '서다': 492,\n",
       " '낫다': 493,\n",
       " '티비': 494,\n",
       " '기도': 495,\n",
       " '든': 496,\n",
       " '배경': 497,\n",
       " '첨': 498,\n",
       " '두다': 499,\n",
       " '대해': 500,\n",
       " '유쾌하다': 501,\n",
       " '쓸다': 502,\n",
       " '살리다': 503,\n",
       " '뒤': 504,\n",
       " '맘': 505,\n",
       " '비다': 506,\n",
       " '망하다': 507,\n",
       " '킬링타임': 508,\n",
       " '나가다': 509,\n",
       " '스릴': 510,\n",
       " '충격': 511,\n",
       " '음': 512,\n",
       " '전쟁': 513,\n",
       " '만화': 514,\n",
       " '얘기': 515,\n",
       " '진부하다': 516,\n",
       " '완벽하다': 517,\n",
       " '존나': 518,\n",
       " '적다': 519,\n",
       " '책': 520,\n",
       " '건가': 521,\n",
       " '등': 522,\n",
       " '예술': 523,\n",
       " '개연': 524,\n",
       " '그렇게': 525,\n",
       " '간': 526,\n",
       " '머리': 527,\n",
       " '갈수록': 528,\n",
       " '매우': 529,\n",
       " '머': 530,\n",
       " '놀라다': 531,\n",
       " '조': 532,\n",
       " '질': 533,\n",
       " '즐겁다': 534,\n",
       " '얼굴': 535,\n",
       " '보단': 536,\n",
       " '후회': 537,\n",
       " '웃기': 538,\n",
       " '이름': 539,\n",
       " '읽다': 540,\n",
       " '영화인': 541,\n",
       " '옛날': 542,\n",
       " '구성': 543,\n",
       " '어디': 544,\n",
       " '너무나': 545,\n",
       " '어울리다': 546,\n",
       " '행복하다': 547,\n",
       " '집중': 548,\n",
       " '이후': 549,\n",
       " '들이다': 550,\n",
       " '울': 551,\n",
       " '총': 552,\n",
       " '장르': 553,\n",
       " '꽤': 554,\n",
       " '집': 555,\n",
       " '새롭다': 556,\n",
       " '주연': 557,\n",
       " '날': 558,\n",
       " '다큐': 559,\n",
       " '시즌': 560,\n",
       " '상황': 561,\n",
       " '누구': 562,\n",
       " '그래서': 563,\n",
       " '이리': 564,\n",
       " '상': 565,\n",
       " '억지': 566,\n",
       " '언제': 567,\n",
       " '씬': 568,\n",
       " '짜증': 569,\n",
       " '생기다': 570,\n",
       " '예전': 571,\n",
       " '충분하다': 572,\n",
       " '글': 573,\n",
       " '아직': 574,\n",
       " '후반': 575,\n",
       " '비': 576,\n",
       " '다운': 577,\n",
       " '역사': 578,\n",
       " '어느': 579,\n",
       " '강추': 580,\n",
       " '궁금하다': 581,\n",
       " '걸작': 582,\n",
       " '여기': 583,\n",
       " '불쌍하다': 584,\n",
       " '누가': 585,\n",
       " '밉다': 586,\n",
       " '진': 587,\n",
       " '약간': 588,\n",
       " '훨씬': 589,\n",
       " '자기': 590,\n",
       " '소름': 591,\n",
       " '그것': 592,\n",
       " '인물': 593,\n",
       " '발연기': 594,\n",
       " '그나마': 595,\n",
       " '실화': 596,\n",
       " '해도': 597,\n",
       " '그대로': 598,\n",
       " '방송': 599,\n",
       " '심하다': 600,\n",
       " '분들': 601,\n",
       " '시절': 602,\n",
       " '잔인하다': 603,\n",
       " '회': 604,\n",
       " '비디오': 605,\n",
       " '대체': 606,\n",
       " '순수하다': 607,\n",
       " '비슷하다': 608,\n",
       " '만점': 609,\n",
       " '그런': 610,\n",
       " '소설': 611,\n",
       " '한마디': 612,\n",
       " '사회': 613,\n",
       " '아들': 614,\n",
       " '어렵다': 615,\n",
       " '부': 616,\n",
       " '로맨스': 617,\n",
       " '드리다': 618,\n",
       " '비교': 619,\n",
       " '초딩': 620,\n",
       " '감성': 621,\n",
       " '판': 622,\n",
       " '네이버': 623,\n",
       " '필요하다': 624,\n",
       " '쉬다': 625,\n",
       " '따르다': 626,\n",
       " '보': 627,\n",
       " '남기다': 628,\n",
       " '다음': 629,\n",
       " '만나다': 630,\n",
       " '여주': 631,\n",
       " '여배우': 632,\n",
       " '전체': 633,\n",
       " '간만': 634,\n",
       " '타다': 635,\n",
       " '죠': 636,\n",
       " '떠나다': 637,\n",
       " '상당하다': 638,\n",
       " '라도': 639,\n",
       " '휴': 640,\n",
       " '장': 641,\n",
       " '편이': 642,\n",
       " '나이': 643,\n",
       " '만큼': 644,\n",
       " '이라도': 645,\n",
       " '당하다': 646,\n",
       " '사랑스럽다': 647,\n",
       " '꿈': 648,\n",
       " '나라': 649,\n",
       " '코': 650,\n",
       " '재': 651,\n",
       " '굉장하다': 652,\n",
       " '성룡': 653,\n",
       " '동안': 654,\n",
       " '이르다': 655,\n",
       " '혼자': 656,\n",
       " '열': 657,\n",
       " '터지다': 658,\n",
       " '순간': 659,\n",
       " '돌리다': 660,\n",
       " '교훈': 661,\n",
       " '쯤': 662,\n",
       " '삼류': 663,\n",
       " '보다는': 664,\n",
       " '빨리': 665,\n",
       " '재밋': 666,\n",
       " '감사하다': 667,\n",
       " '그만': 668,\n",
       " '존재': 669,\n",
       " '힘': 670,\n",
       " 'ㅉㅉ': 671,\n",
       " '바로': 672,\n",
       " '풀다': 673,\n",
       " '주제': 674,\n",
       " '바라다': 675,\n",
       " '진정하다': 676,\n",
       " '목소리': 677,\n",
       " '년도': 678,\n",
       " '억': 679,\n",
       " '에요': 680,\n",
       " '잡다': 681,\n",
       " '망치다': 682,\n",
       " '화려하다': 683,\n",
       " '죽': 684,\n",
       " '당신': 685,\n",
       " '돋다': 686,\n",
       " '거의': 687,\n",
       " '지나다': 688,\n",
       " '안보': 689,\n",
       " '몇번': 690,\n",
       " '낭비': 691,\n",
       " '질질': 692,\n",
       " '년전': 693,\n",
       " '가볍다': 694,\n",
       " '라니': 695,\n",
       " '독특하다': 696,\n",
       " '말고': 697,\n",
       " '엄청나다': 698,\n",
       " '줄거리': 699,\n",
       " '맞추다': 700,\n",
       " '성하다': 701,\n",
       " '뜨다': 702,\n",
       " 'ㅜ': 703,\n",
       " '의도': 704,\n",
       " '에선': 705,\n",
       " '딸': 706,\n",
       " '아버지': 707,\n",
       " '좀비': 708,\n",
       " '판타지': 709,\n",
       " '이번': 710,\n",
       " '담다': 711,\n",
       " '갑자기': 712,\n",
       " '그러나': 713,\n",
       " '어른': 714,\n",
       " '넣다': 715,\n",
       " '피': 716,\n",
       " '전부': 717,\n",
       " '당': 718,\n",
       " '상영': 719,\n",
       " '점주': 720,\n",
       " '모': 721,\n",
       " '시청률': 722,\n",
       " '흥미롭다': 723,\n",
       " '실제': 724,\n",
       " '소': 725,\n",
       " 'ㅎㅎㅎ': 726,\n",
       " '넘치다': 727,\n",
       " 'ㅡ': 728,\n",
       " '힘드다': 729,\n",
       " '평론가': 730,\n",
       " '곳': 731,\n",
       " '맛': 732,\n",
       " '점점': 733,\n",
       " '으로도': 734,\n",
       " '땜': 735,\n",
       " '만하': 736,\n",
       " '단': 737,\n",
       " '기다리다': 738,\n",
       " '막': 739,\n",
       " '한편': 740,\n",
       " '그녀': 741,\n",
       " '히': 742,\n",
       " '필요': 743,\n",
       " '제작': 744,\n",
       " '화면': 745,\n",
       " '사': 746,\n",
       " '바': 747,\n",
       " '대로': 748,\n",
       " '극장판': 749,\n",
       " '만들어지다': 750,\n",
       " '초': 751,\n",
       " '이기다': 752,\n",
       " '중국': 753,\n",
       " '형': 754,\n",
       " '온': 755,\n",
       " '답': 756,\n",
       " '각본': 757,\n",
       " '에서도': 758,\n",
       " '볼때': 759,\n",
       " '간다': 760,\n",
       " '억지스럽다': 761,\n",
       " '래': 762,\n",
       " '밑': 763,\n",
       " '평': 764,\n",
       " '달다': 765,\n",
       " '바꾸다': 766,\n",
       " '관람': 767,\n",
       " '란': 768,\n",
       " '오글거리다': 769,\n",
       " '저런': 770,\n",
       " '스타일': 771,\n",
       " '세계': 772,\n",
       " '이하': 773,\n",
       " '선택': 774,\n",
       " '선': 775,\n",
       " '성우': 776,\n",
       " '요소': 777,\n",
       " '터': 778,\n",
       " '둘': 779,\n",
       " '복수': 780,\n",
       " '항상': 781,\n",
       " '일단': 782,\n",
       " '가치': 783,\n",
       " '똥': 784,\n",
       " '햇': 785,\n",
       " '어디서': 786,\n",
       " '굳다': 787,\n",
       " '에서는': 788,\n",
       " '첫': 789,\n",
       " '갖다': 790,\n",
       " '뻔': 791,\n",
       " '올리다': 792,\n",
       " '흥행': 793,\n",
       " '부르다': 794,\n",
       " '참고': 795,\n",
       " '그때': 796,\n",
       " '가보다': 797,\n",
       " '드': 798,\n",
       " '여러': 799,\n",
       " '보내다': 800,\n",
       " '더욱': 801,\n",
       " '걸리다': 802,\n",
       " '치고': 803,\n",
       " '확실하다': 804,\n",
       " '너무하다': 805,\n",
       " '라서': 806,\n",
       " '들어가다': 807,\n",
       " '또한': 808,\n",
       " '아빠': 809,\n",
       " '씩': 810,\n",
       " '물론': 811,\n",
       " '역대': 812,\n",
       " '평범하다': 813,\n",
       " '거기': 814,\n",
       " '수가': 815,\n",
       " '불편하다': 816,\n",
       " '발': 817,\n",
       " 'ㅋㅋㅋㅋㅋ': 818,\n",
       " '인거': 819,\n",
       " '완성': 820,\n",
       " '편집': 821,\n",
       " '단순하다': 822,\n",
       " '이냐': 823,\n",
       " '상미': 824,\n",
       " '멜로': 825,\n",
       " '듣다': 826,\n",
       " '끼다': 827,\n",
       " '흐르다': 828,\n",
       " '잃다': 829,\n",
       " '전형': 830,\n",
       " '짧다': 831,\n",
       " '새끼': 832,\n",
       " '허무하다': 833,\n",
       " '짓': 834,\n",
       " 'ㅠㅠㅠ': 835,\n",
       " '때리다': 836,\n",
       " '역': 837,\n",
       " '걸다': 838,\n",
       " '어이': 839,\n",
       " '술': 840,\n",
       " '탄탄하다': 841,\n",
       " '군': 842,\n",
       " '귀': 843,\n",
       " '가지다': 844,\n",
       " '화이팅': 845,\n",
       " '진행': 846,\n",
       " '개그': 847,\n",
       " '에겐': 848,\n",
       " '돋보이다': 849,\n",
       " '엉망': 850,\n",
       " '불륜': 851,\n",
       " '거지': 852,\n",
       " '예상': 853,\n",
       " '이에요': 854,\n",
       " '잠': 855,\n",
       " '사건': 856,\n",
       " '즐기다': 857,\n",
       " '병맛': 858,\n",
       " '중반': 859,\n",
       " '미화': 860,\n",
       " '지겹다': 861,\n",
       " '그게': 862,\n",
       " '똑같다': 863,\n",
       " '소중하다': 864,\n",
       " '어쩔': 865,\n",
       " '설명': 866,\n",
       " '과거': 867,\n",
       " '메다': 868,\n",
       " '찾아보다': 869,\n",
       " '적당하다': 870,\n",
       " '프랑스': 871,\n",
       " '중요하다': 872,\n",
       " '화보': 873,\n",
       " '키': 874,\n",
       " '불다': 875,\n",
       " '도저히': 876,\n",
       " '손': 877,\n",
       " '노력': 878,\n",
       " '훈훈하다': 879,\n",
       " '댓글': 880,\n",
       " '그래픽': 881,\n",
       " '흥미': 882,\n",
       " '닿다': 883,\n",
       " '갈다': 884,\n",
       " '흥미진진': 885,\n",
       " '거리': 886,\n",
       " '여서': 887,\n",
       " '죽음': 888,\n",
       " '꿀잼': 889,\n",
       " '싸우다': 890,\n",
       " '티': 891,\n",
       " '무조건': 892,\n",
       " '원래': 893,\n",
       " '몸': 894,\n",
       " '취향': 895,\n",
       " '식상하다': 896,\n",
       " '척': 897,\n",
       " '리': 898,\n",
       " '화가': 899,\n",
       " '새': 900,\n",
       " '뛰어나다': 901,\n",
       " '마르다': 902,\n",
       " '현': 903,\n",
       " '자극': 904,\n",
       " '일이': 905,\n",
       " '비추다': 906,\n",
       " '배': 907,\n",
       " '감상': 908,\n",
       " '며': 909,\n",
       " '역겹다': 910,\n",
       " '만으로도': 911,\n",
       " '만이': 912,\n",
       " '한심하다': 913,\n",
       " '예': 914,\n",
       " '학교': 915,\n",
       " '길다': 916,\n",
       " '자꾸': 917,\n",
       " '무': 918,\n",
       " '액션영화': 919,\n",
       " '관': 920,\n",
       " '뭐라다': 921,\n",
       " '예고편': 922,\n",
       " '오히려': 923,\n",
       " '괜히': 924,\n",
       " '결혼': 925,\n",
       " '암': 926,\n",
       " '다가': 927,\n",
       " '바보': 928,\n",
       " '심리': 929,\n",
       " '다루다': 930,\n",
       " '이라니': 931,\n",
       " '게임': 932,\n",
       " '아저씨': 933,\n",
       " '속편': 934,\n",
       " '용도': 935,\n",
       " '연기자': 936,\n",
       " '보이': 937,\n",
       " '잘만': 938,\n",
       " '마무리': 939,\n",
       " '나서다': 940,\n",
       " '올': 941,\n",
       " '강하다': 942,\n",
       " '관계': 943,\n",
       " '양': 944,\n",
       " '나르다': 945,\n",
       " '왠만하다': 946,\n",
       " '천재': 947,\n",
       " '법': 948,\n",
       " '미안하다': 949,\n",
       " '맨': 950,\n",
       " 'ㄷㄷ': 951,\n",
       " '억지로': 952,\n",
       " '표정': 953,\n",
       " '땐': 954,\n",
       " '참신하다': 955,\n",
       " '영환': 956,\n",
       " '귀신': 957,\n",
       " '최근': 958,\n",
       " '한다는': 959,\n",
       " '순': 960,\n",
       " '기억나다': 961,\n",
       " '현재': 962,\n",
       " '상상': 963,\n",
       " '동': 964,\n",
       " '흠': 965,\n",
       " '유치': 966,\n",
       " '전설': 967,\n",
       " '젠': 968,\n",
       " '타임': 969,\n",
       " '촬영': 970,\n",
       " '오빠': 971,\n",
       " '헐다': 972,\n",
       " '아쉬움': 973,\n",
       " '봣': 974,\n",
       " '오래': 975,\n",
       " '다니다': 976,\n",
       " '산': 977,\n",
       " '대한민국': 978,\n",
       " '조차': 979,\n",
       " '빠져들다': 980,\n",
       " '우연히': 981,\n",
       " '엇': 982,\n",
       " '흘리다': 983,\n",
       " '짐': 984,\n",
       " '전편': 985,\n",
       " '길': 986,\n",
       " '스타': 987,\n",
       " '잊혀지다': 988,\n",
       " '묘사': 989,\n",
       " '메세지': 990,\n",
       " '진지하다': 991,\n",
       " '만의': 992,\n",
       " '대작': 993,\n",
       " '철학': 994,\n",
       " '겁나다': 995,\n",
       " '타': 996,\n",
       " '프로그램': 997,\n",
       " '마': 998,\n",
       " '동화': 999,\n",
       " '프로': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 집합\n",
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4743707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('아', 4121),\n",
       "             ('더빙', 572),\n",
       "             ('진짜', 8288),\n",
       "             ('짜증나다', 1002),\n",
       "             ('목소리', 374),\n",
       "             ('흠', 246),\n",
       "             ('포스터', 572),\n",
       "             ('보고', 4653),\n",
       "             ('초딩', 422),\n",
       "             ('영화', 50172),\n",
       "             ('줄', 1240),\n",
       "             ('오버', 142),\n",
       "             ('연기', 6326),\n",
       "             ('조차', 242),\n",
       "             ('가볍다', 360),\n",
       "             ('않다', 7718),\n",
       "             ('너', 670),\n",
       "             ('무재', 69),\n",
       "             ('밓었', 1),\n",
       "             ('다그', 75),\n",
       "             ('래서', 20),\n",
       "             ('보다', 40991),\n",
       "             ('추천', 1180),\n",
       "             ('한', 9615),\n",
       "             ('다', 10077),\n",
       "             ('교도소', 16),\n",
       "             ('이야기', 2171),\n",
       "             ('구먼', 11),\n",
       "             ('솔직하다', 1199),\n",
       "             ('재미', 3854),\n",
       "             ('는', 16911),\n",
       "             ('없다', 15519),\n",
       "             ('평점', 6245),\n",
       "             ('조정', 40),\n",
       "             ('사이', 222),\n",
       "             ('몬페', 2),\n",
       "             ('그', 5667),\n",
       "             ('의', 30737),\n",
       "             ('익살스럽다', 9),\n",
       "             ('가', 26578),\n",
       "             ('돋보이다', 288),\n",
       "             ('스파이더맨', 64),\n",
       "             ('에서', 6979),\n",
       "             ('늙다', 198),\n",
       "             ('보이다', 1073),\n",
       "             ('하다', 40759),\n",
       "             ('커스틴', 4),\n",
       "             ('던스트', 2),\n",
       "             ('너무나도', 206),\n",
       "             ('이쁘다', 1033),\n",
       "             ('막', 333),\n",
       "             ('걸음', 20),\n",
       "             ('마', 236),\n",
       "             ('떼다', 151),\n",
       "             ('세', 599),\n",
       "             ('부터', 1717),\n",
       "             ('초등학교', 116),\n",
       "             ('학년', 121),\n",
       "             ('생인', 6),\n",
       "             ('살다', 1173),\n",
       "             ('ㅋㅋㅋ', 2448),\n",
       "             ('별', 1918),\n",
       "             ('반개', 202),\n",
       "             ('도', 21058),\n",
       "             ('아깝다', 4373),\n",
       "             ('움', 1049),\n",
       "             ('원작', 1253),\n",
       "             ('긴장감', 832),\n",
       "             ('을', 23197),\n",
       "             ('제대로', 796),\n",
       "             ('살리다', 532),\n",
       "             ('욕', 778),\n",
       "             ('나오다', 6394),\n",
       "             ('이응경', 8),\n",
       "             ('길용우', 4),\n",
       "             ('연', 882),\n",
       "             ('기', 1967),\n",
       "             ('생활', 126),\n",
       "             ('이', 55570),\n",
       "             ('몇', 697),\n",
       "             ('년', 1989),\n",
       "             ('인지', 1170),\n",
       "             ('정말', 9662),\n",
       "             ('발', 299),\n",
       "             ('로', 7830),\n",
       "             ('해도', 440),\n",
       "             ('그것', 444),\n",
       "             ('보단', 508),\n",
       "             ('낫다', 543),\n",
       "             ('납치', 49),\n",
       "             ('감금', 11),\n",
       "             ('만', 8653),\n",
       "             ('반복', 151),\n",
       "             ('드라마', 5024),\n",
       "             ('가족', 937),\n",
       "             ('못', 5294),\n",
       "             ('사람', 4836),\n",
       "             ('모', 344),\n",
       "             ('엿', 207),\n",
       "             ('네', 3411),\n",
       "             ('액션', 2394),\n",
       "             ('있다', 12424),\n",
       "             ('안되다', 2320),\n",
       "             ('왜케', 131),\n",
       "             ('낮다', 1309),\n",
       "             ('꽤', 490),\n",
       "             ('볼', 2728),\n",
       "             ('데', 652),\n",
       "             ('헐리우드', 143),\n",
       "             ('식', 713),\n",
       "             ('화려하다', 368),\n",
       "             ('너무', 11069),\n",
       "             ('길들이다', 20),\n",
       "             ('걍', 678),\n",
       "             ('인피니트', 27),\n",
       "             ('짱', 1503),\n",
       "             ('이다', 13140),\n",
       "             ('볼때', 324),\n",
       "             ('마다', 675),\n",
       "             ('눈물나다', 174),\n",
       "             ('죽다', 1295),\n",
       "             ('년대', 687),\n",
       "             ('향수', 66),\n",
       "             ('자', 921),\n",
       "             ('극', 754),\n",
       "             ('허진호', 6),\n",
       "             ('감성', 420),\n",
       "             ('절제', 67),\n",
       "             ('멜로', 297),\n",
       "             ('달인', 21),\n",
       "             ('울면', 78),\n",
       "             ('서', 1723),\n",
       "             ('손', 277),\n",
       "             ('들', 18140),\n",
       "             ('고', 4500),\n",
       "             ('횡단보도', 1),\n",
       "             ('건너다', 8),\n",
       "             ('때', 4277),\n",
       "             ('뛰다', 171),\n",
       "             ('치다', 948),\n",
       "             ('올', 253),\n",
       "             ('뻔', 311),\n",
       "             ('이범수', 39),\n",
       "             ('드럽다', 233),\n",
       "             ('담백하다', 68),\n",
       "             ('깔끔하다', 174),\n",
       "             ('좋다', 11911),\n",
       "             ('신', 547),\n",
       "             ('문', 181),\n",
       "             ('사', 332),\n",
       "             ('로만', 139),\n",
       "             ('자꾸', 263),\n",
       "             ('잊어버리다', 15),\n",
       "             ('것', 6276),\n",
       "             ('취향', 273),\n",
       "             ('은', 15991),\n",
       "             ('존중', 36),\n",
       "             ('다지', 18),\n",
       "             ('내생', 106),\n",
       "             ('에', 27021),\n",
       "             ('극장', 794),\n",
       "             ('중', 3724),\n",
       "             ('가장', 1385),\n",
       "             ('노잼', 737),\n",
       "             ('노', 216),\n",
       "             ('감동', 4803),\n",
       "             ('임', 2070),\n",
       "             ('스토리', 5329),\n",
       "             ('어거지', 76),\n",
       "             ('ㄱ', 115),\n",
       "             ('냥', 178),\n",
       "             ('매번', 65),\n",
       "             ('긴장', 153),\n",
       "             ('되다', 8843),\n",
       "             ('재밋음', 81),\n",
       "             ('ㅠㅠ', 2473),\n",
       "             ('차다', 2301),\n",
       "             ('웃기다', 1368),\n",
       "             ('바스코', 15),\n",
       "             ('이기', 168),\n",
       "             ('면', 1873),\n",
       "             ('락스', 13),\n",
       "             ('코', 397),\n",
       "             ('라고', 1778),\n",
       "             ('끄다', 1490),\n",
       "             ('바비', 24),\n",
       "             ('아이돌', 148),\n",
       "             ('이라고', 689),\n",
       "             ('깔다', 211),\n",
       "             ('안달', 22),\n",
       "             ('난', 1868),\n",
       "             ('처럼', 1065),\n",
       "             ('굿바이', 21),\n",
       "             ('레닌', 6),\n",
       "             ('표절', 182),\n",
       "             ('인', 5461),\n",
       "             ('이해', 1893),\n",
       "             ('왜', 5110),\n",
       "             ('뒤', 530),\n",
       "             ('갈수록', 512),\n",
       "             ('없어지다', 135),\n",
       "             ('이건', 2566),\n",
       "             ('깨알', 68),\n",
       "             ('캐스팅', 572),\n",
       "             ('과', 6418),\n",
       "             ('질퍽', 3),\n",
       "             ('하', 2198),\n",
       "             ('지', 3015),\n",
       "             ('산뜻하다', 14),\n",
       "             ('내', 5884),\n",
       "             ('용구성', 6),\n",
       "             ('자다', 3609),\n",
       "             ('버무러진', 2),\n",
       "             ('일드', 37),\n",
       "             ('약탈', 4),\n",
       "             ('를', 16149),\n",
       "             ('위', 859),\n",
       "             ('변명', 29),\n",
       "             ('이르다', 392),\n",
       "             ('저', 2574),\n",
       "             ('놈', 739),\n",
       "             ('착하다', 217),\n",
       "             ('절대', 714),\n",
       "             ('아니다', 7738),\n",
       "             ('걸', 2315),\n",
       "             ('요', 4011),\n",
       "             ('나름', 760),\n",
       "             ('심오하다', 100),\n",
       "             ('뜻', 174),\n",
       "             ('듯', 2039),\n",
       "             ('그냥', 4049),\n",
       "             ('학생', 133),\n",
       "             ('선생', 64),\n",
       "             ('놀다', 106),\n",
       "             ('웃다', 854),\n",
       "             ('건', 878),\n",
       "             ('불가능하다', 48),\n",
       "             ('재미없다', 3416),\n",
       "             ('지루하다', 3479),\n",
       "             ('같다', 8341),\n",
       "             ('음식', 82),\n",
       "             ('인데', 2060),\n",
       "             ('바베트', 1),\n",
       "             ('만찬', 9),\n",
       "             ('하고', 3563),\n",
       "             ('넘다', 2108),\n",
       "             ('차이', 161),\n",
       "             ('남바', 1),\n",
       "             ('베트', 3),\n",
       "             ('게', 4907),\n",
       "             ('별로', 1947),\n",
       "             ('안', 5492),\n",
       "             ('핀란드', 8),\n",
       "             ('풍경', 120),\n",
       "             ('이라도', 400),\n",
       "             ('구', 582),\n",
       "             ('경', 132),\n",
       "             ('할랫', 1),\n",
       "             ('늘다', 1222),\n",
       "             ('ㅡㅡ', 2061),\n",
       "             ('평범하다', 300),\n",
       "             ('수작', 639),\n",
       "             ('이라', 947),\n",
       "             ('는걸', 176),\n",
       "             ('말씀드리다', 6),\n",
       "             ('주제', 378),\n",
       "             ('중반', 285),\n",
       "             ('짤랐을꺼', 1),\n",
       "             ('야', 1525),\n",
       "             ('그래서', 473),\n",
       "             ('납득', 55),\n",
       "             ('수', 3430),\n",
       "             ('그렇다', 3093),\n",
       "             ('꼭', 1621),\n",
       "             ('고추', 15),\n",
       "             ('털다', 27),\n",
       "             ('버리다', 1770),\n",
       "             ('카밀라', 10),\n",
       "             ('벨', 50),\n",
       "             ('발연기', 441),\n",
       "             ('재밋는뎅', 1),\n",
       "             ('센스', 81),\n",
       "             ('연출', 2075),\n",
       "             ('력', 708),\n",
       "             ('탁월하다', 66),\n",
       "             ('점', 7480),\n",
       "             ('엄포스', 3),\n",
       "             ('위력', 12),\n",
       "             ('다시', 2806),\n",
       "             ('한번', 1405),\n",
       "             ('깨닫다', 148),\n",
       "             ('해주다', 1644),\n",
       "             ('적남', 1),\n",
       "             ('꽃', 92),\n",
       "             ('검사', 55),\n",
       "             ('님', 1464),\n",
       "             ('완전', 2507),\n",
       "             ('명품', 136),\n",
       "             ('졸', 79),\n",
       "             ('쓰레기', 3391),\n",
       "             ('진부하다', 518),\n",
       "             ('도안', 131),\n",
       "             ('돼다', 1041),\n",
       "             ('ㅋㅋ', 4272),\n",
       "             ('아시', 42),\n",
       "             ('간', 513),\n",
       "             ('재밌다', 8652),\n",
       "             ('이리', 469),\n",
       "             ('라도', 406),\n",
       "             ('기대하다', 996),\n",
       "             ('죄인', 13),\n",
       "             ('아직도', 695),\n",
       "             ('인생', 1496),\n",
       "             ('최고', 5681),\n",
       "             ('패션', 38),\n",
       "             ('대한', 1055),\n",
       "             ('열정', 159),\n",
       "             ('안나', 216),\n",
       "             ('윈', 10),\n",
       "             ('투어', 7),\n",
       "             ('키이라', 16),\n",
       "             ('나이틀리', 8),\n",
       "             ('대체', 431),\n",
       "             ('정신장애', 2),\n",
       "             ('틱장애', 3),\n",
       "             ('허허', 85),\n",
       "             ('원', 573),\n",
       "             ('작가', 879),\n",
       "             ('정신', 579),\n",
       "             ('나가다', 524),\n",
       "             ('유령', 49),\n",
       "             ('재미있다', 3951),\n",
       "             ('관객', 617),\n",
       "             ('명', 686),\n",
       "             ('이네', 1039),\n",
       "             ('이렇게', 2325),\n",
       "             ('평가', 569),\n",
       "             ('받다', 1983),\n",
       "             ('모르다', 3208),\n",
       "             ('단순하다', 298),\n",
       "             ('은은하다', 35),\n",
       "             ('매력', 1364),\n",
       "             ('알바생', 53),\n",
       "             ('인가', 1081),\n",
       "             ('내용', 3811),\n",
       "             ('무섭다', 1416),\n",
       "             ('하나', 2810),\n",
       "             ('싱겁다', 55),\n",
       "             ('ㅇㅇ', 181),\n",
       "             ('ㅇ', 202),\n",
       "             ('시간', 3852),\n",
       "             ('낚임', 26),\n",
       "             ('오다', 2508),\n",
       "             ('두다', 534),\n",
       "             ('서리', 11),\n",
       "             ('굶주리다', 4),\n",
       "             ('맘', 530),\n",
       "             ('들다', 3196),\n",
       "             ('또', 1774),\n",
       "             ('방법', 141),\n",
       "             ('ㅜㅡ', 17),\n",
       "             ('윤제문', 13),\n",
       "             ('이라는', 843),\n",
       "             ('멋지다', 1254),\n",
       "             ('배우', 4282),\n",
       "             ('발견', 181),\n",
       "             ('소소하다', 144),\n",
       "             ('일', 1686),\n",
       "             ('탈', 96),\n",
       "             ('잔잔하다', 874),\n",
       "             ('미소', 202),\n",
       "             ('머금', 8),\n",
       "             ('음악', 1276),\n",
       "             ('조금', 806),\n",
       "             ('아쉽다', 1523),\n",
       "             ('주다', 3720),\n",
       "             ('싶다', 3051),\n",
       "             ('올리다', 311),\n",
       "             ('속지', 66),\n",
       "             ('말다', 1309),\n",
       "             ('낭비', 362),\n",
       "             ('돈', 2186),\n",
       "             ('리얼리티', 72),\n",
       "             ('뛰어나다', 271),\n",
       "             ('한데', 123),\n",
       "             ('크다', 1193),\n",
       "             ('공감', 1003),\n",
       "             ('간다', 324),\n",
       "             ('이민기', 44),\n",
       "             ('캐릭터', 1075),\n",
       "             ('정신의학', 1),\n",
       "             ('상', 469),\n",
       "             ('분노조절', 5),\n",
       "             ('장애', 54),\n",
       "             ('초기', 42),\n",
       "             ('증상', 3),\n",
       "             ('툭하면', 13),\n",
       "             ('패', 102),\n",
       "             ('물건', 38),\n",
       "             ('파손', 2),\n",
       "             ('오', 669),\n",
       "             ('바', 332),\n",
       "             ('초반', 663),\n",
       "             ('엔', 1605),\n",
       "             ('신선하다', 619),\n",
       "             ('가면', 155),\n",
       "             ('상태', 105),\n",
       "             ('불가', 163),\n",
       "             ('마이너스', 122),\n",
       "             ('ㅋ', 2494),\n",
       "             ('뮤비', 18),\n",
       "             ('수준', 1445),\n",
       "             ('딱', 783),\n",
       "             ('알', 1272),\n",
       "             ('ㅉㅉ', 381),\n",
       "             ('북한', 166),\n",
       "             ('이렇다', 4583),\n",
       "             ('만들다', 6500),\n",
       "             ('대다', 612),\n",
       "             ('우리', 1187),\n",
       "             ('사랑', 2939),\n",
       "             ('리스', 34),\n",
       "             ('타르', 8),\n",
       "             ('가르다', 39),\n",
       "             ('엔나', 1),\n",
       "             ('용의', 24),\n",
       "             ('주인', 46),\n",
       "             ('누', 46),\n",
       "             ('이랑', 952),\n",
       "             ('근친상간', 10),\n",
       "             ('이나', 1762),\n",
       "             ('다니다', 243),\n",
       "             ('소설', 426),\n",
       "             ('속', 1405),\n",
       "             ('에선', 353),\n",
       "             ('제일', 743),\n",
       "             ('메', 90),\n",
       "             ('라', 2064),\n",
       "             ('니스', 14),\n",
       "             ('터', 317),\n",
       "             ('드래곤', 24),\n",
       "             ('용이', 206),\n",
       "             ('웃음', 683),\n",
       "             ('감독', 4113),\n",
       "             ('토르', 27),\n",
       "             ('다크', 39),\n",
       "             ('월드', 41),\n",
       "             ('말', 4500),\n",
       "             ('잡수다', 6),\n",
       "             ('기본', 158),\n",
       "             ('선방', 4),\n",
       "             ('영혼', 122),\n",
       "             ('어루만지다', 12),\n",
       "             ('수도', 180),\n",
       "             ('거치다', 76),\n",
       "             ('상사', 18),\n",
       "             ('잠시', 88),\n",
       "             ('잊다', 598),\n",
       "             ('동화', 236),\n",
       "             ('행복하다', 500),\n",
       "             ('세르게이', 6),\n",
       "             ('작다', 235),\n",
       "             ('맵다', 7),\n",
       "             ('맛', 338),\n",
       "             ('보여주다', 1467),\n",
       "             ('포퐁', 1),\n",
       "             ('저그', 20),\n",
       "             ('콩', 63),\n",
       "             ('진호', 9),\n",
       "             ('가슴', 1325),\n",
       "             ('시리', 14),\n",
       "             ('자체', 1146),\n",
       "             ('난또', 6),\n",
       "             ('꼬마', 103),\n",
       "             ('애가', 96),\n",
       "             ('무슨', 1596),\n",
       "             ('원한', 22),\n",
       "             ('깊다', 749),\n",
       "             ('혼자', 392),\n",
       "             ('나대다', 24),\n",
       "             ('어쩌라고', 34),\n",
       "             ('전', 1456),\n",
       "             ('충격', 523),\n",
       "             ('적다', 516),\n",
       "             ('기분', 887),\n",
       "             ('완전하다', 149),\n",
       "             ('푹', 137),\n",
       "             ('꺼지다', 71),\n",
       "             ('느낌', 2093),\n",
       "             ('활', 34),\n",
       "             ('이라고는', 31),\n",
       "             ('무겁다', 163),\n",
       "             ('지독하다', 51),\n",
       "             ('차갑다', 72),\n",
       "             ('무자비하다', 12),\n",
       "             ('그저', 549),\n",
       "             ('일본인', 80),\n",
       "             ('상상력', 201),\n",
       "             ('대단하다', 886),\n",
       "             ('생각', 5312),\n",
       "             ('심심하다', 181),\n",
       "             ('백봉기', 1),\n",
       "             ('언제', 465),\n",
       "             ('그대로', 439),\n",
       "             ('들어맞다', 15),\n",
       "             ('예측', 62),\n",
       "             ('카리스마', 122),\n",
       "             ('악역', 180),\n",
       "             ('불알', 3),\n",
       "             ('당황', 90),\n",
       "             ('아무튼', 80),\n",
       "             ('중간', 992),\n",
       "             ('끝나다', 1331),\n",
       "             ('녹다', 78),\n",
       "             ('일상', 178),\n",
       "             ('밋밋하다', 128),\n",
       "             ('계속', 954),\n",
       "             ('전개도', 137),\n",
       "             ('느리다', 154),\n",
       "             ('주인공', 2375),\n",
       "             ('은희', 26),\n",
       "             ('한두', 33),\n",
       "             ('컷', 71),\n",
       "             ('소', 343),\n",
       "             ('극적', 60),\n",
       "             ('모습', 973),\n",
       "             ('짜증', 464),\n",
       "             ('ㅜㅜ', 945),\n",
       "             ('맨날', 146),\n",
       "             ('대만', 34),\n",
       "             ('전개', 1359),\n",
       "             ('좀', 3630),\n",
       "             ('빨리', 385),\n",
       "             ('가슴속', 34),\n",
       "             ('온', 326),\n",
       "             ('감정', 594),\n",
       "             ('헤집다', 5),\n",
       "             ('예요', 231),\n",
       "             ('많다', 2460),\n",
       "             ('다큐', 475),\n",
       "             ('우리나라', 647),\n",
       "             ('슬프다', 1290),\n",
       "             ('현대', 86),\n",
       "             ('사의', 29),\n",
       "             ('단면', 14),\n",
       "             ('대해', 534),\n",
       "             ('깊이', 215),\n",
       "             ('사죄', 7),\n",
       "             ('바로', 379),\n",
       "             ('잡기', 18),\n",
       "             ('위해', 706),\n",
       "             ('노력', 277),\n",
       "             ('말로', 169),\n",
       "             ('듣다', 297),\n",
       "             ('보도', 11),\n",
       "             ('연맹', 1),\n",
       "             ('민간인', 22),\n",
       "             ('학살', 46),\n",
       "             ('이정', 128),\n",
       "             ('이야', 613),\n",
       "             ('명백하다', 20),\n",
       "             ('살인', 227),\n",
       "             ('살인자', 51),\n",
       "             ('어디', 503),\n",
       "             ('예전', 463),\n",
       "             ('작품', 2975),\n",
       "             ('에피소드', 131),\n",
       "             ('재탕', 36),\n",
       "             ('삼', 162),\n",
       "             ('탕', 26),\n",
       "             ('사골', 21),\n",
       "             ('우려', 105),\n",
       "             ('먹듯', 10),\n",
       "             ('산', 243),\n",
       "             ('으로', 7930),\n",
       "             ('가다', 3208),\n",
       "             ('시청률', 344),\n",
       "             ('아예', 107),\n",
       "             ('이제', 866),\n",
       "             ('회', 433),\n",
       "             ('부작', 81),\n",
       "             ('이라니', 258),\n",
       "             ('김남길', 30),\n",
       "             ('백', 148),\n",
       "             ('짜다', 892),\n",
       "             ('연기력', 1030),\n",
       "             ('몰입도', 548),\n",
       "             ('에도', 747),\n",
       "             ('불구', 156),\n",
       "             ('손예진', 50),\n",
       "             ('ㅈㅈ', 3),\n",
       "             ('비슷하다', 429),\n",
       "             ('분', 1807),\n",
       "             ('한테', 788),\n",
       "             ('노래실력', 5),\n",
       "             ('뽑다', 135),\n",
       "             ('맞다', 1413),\n",
       "             ('박시환', 17),\n",
       "             ('망신', 26),\n",
       "             ('일본', 999),\n",
       "             ('이런', 1848),\n",
       "             ('건가', 515),\n",
       "             ('유치하다', 1275),\n",
       "             ('이틀', 25),\n",
       "             ('만에', 234),\n",
       "             ('근데', 993),\n",
       "             ('차', 186),\n",
       "             ('넣다', 349),\n",
       "             ('조작', 107),\n",
       "             ('안이', 17),\n",
       "             ('열리다', 48),\n",
       "             ('집', 486),\n",
       "             ('활짝', 9),\n",
       "             ('아무나', 56),\n",
       "             ('들어가다', 302),\n",
       "             ('문자', 16),\n",
       "             ('비번', 3),\n",
       "             ('걸리다', 308),\n",
       "             ('억지스럽다', 324),\n",
       "             ('그래도', 1015),\n",
       "             ('졸작', 590),\n",
       "             ('재밋네', 38),\n",
       "             ('달팽이', 8),\n",
       "             ('빨', 181),\n",
       "             ('라서', 304),\n",
       "             ('더', 4352),\n",
       "             ('어설프다', 722),\n",
       "             ('어이없다', 600),\n",
       "             ('결말', 1577),\n",
       "             ('부패하다', 7),\n",
       "             ('로마노프', 2),\n",
       "             ('왕조', 2),\n",
       "             ('기리', 34),\n",
       "             ('뭣같', 6),\n",
       "             ('온몸', 36),\n",
       "             ('항거', 3),\n",
       "             ('러시아', 72),\n",
       "             ('민중', 13),\n",
       "             ('폭도', 8),\n",
       "             ('냐', 1178),\n",
       "             ('무난', 69),\n",
       "             ('펴다', 81),\n",
       "             ('매우', 512),\n",
       "             ('실망', 901),\n",
       "             ('한국영', 624),\n",
       "             ('화', 1205),\n",
       "             ('흥행', 311),\n",
       "             ('코드', 171),\n",
       "             ('갈등', 138),\n",
       "             ('계', 197),\n",
       "             ('화해', 34),\n",
       "             ('남발', 40),\n",
       "             ('뻔하다', 1498),\n",
       "             ('뭐', 3732),\n",
       "             ('아햏햏', 4),\n",
       "             ('시작', 771),\n",
       "             ('분만', 99),\n",
       "             ('리플릿', 1),\n",
       "             ('사진', 110),\n",
       "             ('불안하다', 45),\n",
       "             ('단연', 129),\n",
       "             ('럼', 16),\n",
       "             ('먹다', 1684),\n",
       "             ('에게', 1592),\n",
       "             ('뭘', 649),\n",
       "             ('엉망', 288),\n",
       "             ('진창', 50),\n",
       "             ('개', 2234),\n",
       "             ('우뢰매', 82),\n",
       "             ('진정', 181),\n",
       "             ('위대하다', 211),\n",
       "             ('별루', 104),\n",
       "             ('내일', 76),\n",
       "             ('기대', 999),\n",
       "             ('조미', 11),\n",
       "             ('막문위', 2),\n",
       "             ('좋아하다', 2010),\n",
       "             ('가요', 134),\n",
       "             ('골깜', 1),\n",
       "             ('눈', 1130),\n",
       "             ('부라리다', 2),\n",
       "             ('쓰러지다', 40),\n",
       "             ('성룡', 394),\n",
       "             ('최악', 2166),\n",
       "             ('골', 93),\n",
       "             ('때리다', 293),\n",
       "             ('ㅋㅋㅋㅋ', 1055),\n",
       "             ('걸스데이', 3),\n",
       "             ('이혜리', 1),\n",
       "             ('서기', 34),\n",
       "             ('ㅋㅋㅋㅋㅋ', 299),\n",
       "             ('인공', 30),\n",
       "             ('주귀', 1),\n",
       "             ('여', 1596),\n",
       "             ('ㅋㅋㅋㅋㅋㅋ', 140),\n",
       "             ('인상', 577),\n",
       "             ('적', 8726),\n",
       "             ('어내스트', 1),\n",
       "             ('와', 4237),\n",
       "             ('셀레스틴', 2),\n",
       "             ('강추', 456),\n",
       "             ('에요', 372),\n",
       "             ('클라라', 54),\n",
       "             ('볼라', 52),\n",
       "             ('화신', 24),\n",
       "             ('설정', 679),\n",
       "             ('새롭다', 481),\n",
       "             ('메인', 41),\n",
       "             ('차차', 4),\n",
       "             ('신카이', 4),\n",
       "             ('마코토', 5),\n",
       "             ('작화', 57),\n",
       "             ('밉다', 452),\n",
       "             ('유', 186),\n",
       "             ('카나', 3),\n",
       "             ('잘', 2703),\n",
       "             ('대박', 1034),\n",
       "             ('진심', 909),\n",
       "             ('이훨', 1),\n",
       "             ('나', 5554),\n",
       "             ('두', 1603),\n",
       "             ('인거', 299),\n",
       "             ('고은님', 1),\n",
       "             ('쓰다', 1175),\n",
       "             ('노골', 42),\n",
       "             ('술', 291),\n",
       "             ('광고', 198),\n",
       "             ('어떻다', 1463),\n",
       "             ('킬링타임', 526),\n",
       "             ('크리스마스', 114),\n",
       "             ('떠오르다', 179),\n",
       "             ('행복', 159),\n",
       "             ('ㅎㅎㅎ', 343),\n",
       "             ('빠지다', 847),\n",
       "             ('쫌', 157),\n",
       "             ('산만하다', 189),\n",
       "             ('태어나다', 202),\n",
       "             ('처음', 2451),\n",
       "             ('불륜', 288),\n",
       "             ('로맨스', 423),\n",
       "             ('왕', 218),\n",
       "             ('아주', 979),\n",
       "             ('짬뽕', 64),\n",
       "             ('믹스', 15),\n",
       "             ('음향', 48),\n",
       "             ('별루더', 1),\n",
       "             ('기준', 118),\n",
       "             ('패널', 8),\n",
       "             ('가구', 7),\n",
       "             ('머', 512),\n",
       "             ('명작', 2007),\n",
       "             ('망치', 56),\n",
       "             ('서운하다', 7),\n",
       "             ('이상하다', 754),\n",
       "             ('몬스터', 31),\n",
       "             ('주식회사', 7),\n",
       "             ('너무나', 503),\n",
       "             ('소재', 1508),\n",
       "             ('흥미', 275),\n",
       "             ('끌', 164),\n",
       "             ('지만', 1160),\n",
       "             ('투', 114),\n",
       "             ('박하다', 56),\n",
       "             ('몰입', 907),\n",
       "             ('중국인', 38),\n",
       "             ('특유', 222),\n",
       "             ('과장', 138),\n",
       "             ('허풍', 8),\n",
       "             ('안간힘', 4),\n",
       "             ('쓸다', 533),\n",
       "             ('가상하다', 24),\n",
       "             ('고증', 59),\n",
       "             ('현', 270),\n",
       "             ('실감', 159),\n",
       "             ('떨어지다', 877),\n",
       "             ('거북', 17),\n",
       "             ('스럽다', 574),\n",
       "             ('도대체', 682),\n",
       "             ('까지', 3777),\n",
       "             ('스스로', 138),\n",
       "             ('과대', 65),\n",
       "             ('포장', 182),\n",
       "             ('불법체류자', 14),\n",
       "             ('잡다', 370),\n",
       "             ('우상화', 4),\n",
       "             ('미국', 686),\n",
       "             ('따뜻하다', 700),\n",
       "             ('뭥미', 87),\n",
       "             ('삶속', 7),\n",
       "             ('생애', 199),\n",
       "             ('전부', 347),\n",
       "             ('드러나다', 84),\n",
       "             ('점점', 338),\n",
       "             ('지난', 221),\n",
       "             ('후', 895),\n",
       "             ('남다', 1923),\n",
       "             ('대', 1561),\n",
       "             ('지나', 67),\n",
       "             ('순수하다', 430),\n",
       "             ('숀펜', 21),\n",
       "             ('또한', 302),\n",
       "             ('올레', 62),\n",
       "             ('공짜', 114),\n",
       "             ('헐다', 244),\n",
       "             ('문제', 567),\n",
       "             ('연기자', 255),\n",
       "             ('전혀', 1038),\n",
       "             ('배역', 111),\n",
       "             ('어울리다', 503),\n",
       "             ('그리고', 2004),\n",
       "             ('상대', 63),\n",
       "             ('따로', 114),\n",
       "             ('놓다', 620),\n",
       "             ('보아', 166),\n",
       "             ('라미란', 5),\n",
       "             ('아들', 424),\n",
       "             ('젤', 174),\n",
       "             ('욕심', 94),\n",
       "             ('어느', 458),\n",
       "             ('쪽', 122),\n",
       "             ('만이라도', 16),\n",
       "             ('빵점', 106),\n",
       "             ('베댓', 14),\n",
       "             ('잘쓰다', 30),\n",
       "             ('모자라다', 108),\n",
       "             ('도둑', 64),\n",
       "             ('뫼비우스', 5),\n",
       "             ('나라', 398),\n",
       "             ('만들어지다', 330),\n",
       "             ('믿어지다', 16),\n",
       "             ('찌릿짜릿', 1),\n",
       "             ('용기', 103),\n",
       "             ('교훈', 388),\n",
       "             ('영', 1506),\n",
       "             ('화이', 24),\n",
       "             ('당시', 729),\n",
       "             ('상황', 474),\n",
       "             ('주입', 13),\n",
       "             ('식이', 57),\n",
       "             ('전하', 71),\n",
       "             ('케이블', 206),\n",
       "             ('그만', 383),\n",
       "             ('다르다', 655),\n",
       "             ('덴', 10),\n",
       "             ('이냐', 298),\n",
       "             ('리투', 1),\n",
       "             ('차이밍량', 1),\n",
       "             ('섞이다', 70),\n",
       "             ('채', 104),\n",
       "             ('그릇', 22),\n",
       "             ('담기다', 154),\n",
       "             ('여군', 25),\n",
       "             ('잼', 813),\n",
       "             ('건지다', 1028),\n",
       "             ('엠비씨', 26),\n",
       "             ('질린다', 30),\n",
       "             ('한석규', 57),\n",
       "             ('김혜수', 57),\n",
       "             ('어딘', 6),\n",
       "             ('많이', 1929),\n",
       "             ('에볼라', 4),\n",
       "             ('바이러스', 30),\n",
       "             ('떠들다', 53),\n",
       "             ('석', 54),\n",
       "             ('해', 606),\n",
       "             ('성', 1730),\n",
       "             ('어떤', 178),\n",
       "             ('에서도', 325),\n",
       "             ('년전', 361),\n",
       "             ('보기', 1611),\n",
       "             ('믿다', 922),\n",
       "             ('힘들다', 636),\n",
       "             ('정도', 2585),\n",
       "             ('마지막', 2756),\n",
       "             ('후반', 460),\n",
       "             ('부가', 37),\n",
       "             ('살짝', 184),\n",
       "             ('하지만', 1105),\n",
       "             ('만해', 119),\n",
       "             ('떨다', 85),\n",
       "             ('용가리', 35),\n",
       "             ('짱짱맨', 55),\n",
       "             ('서다', 547),\n",
       "             ('감히', 119),\n",
       "             ('하나로', 116),\n",
       "             ('꼽', 44),\n",
       "             ('살', 597),\n",
       "             ('야하다', 1140),\n",
       "             ('나르다', 252),\n",
       "             ('고민', 194),\n",
       "             ('모건', 24),\n",
       "             ('프리', 43),\n",
       "             ('멀다', 583),\n",
       "             ('나이', 401),\n",
       "             ('여전하다', 234),\n",
       "             ('섹시하다', 129),\n",
       "             ('재방송', 46),\n",
       "             ('혹', 49),\n",
       "             ('시나', 13),\n",
       "             ('답', 326),\n",
       "             ('여운', 1022),\n",
       "             ('왠만하다', 252),\n",
       "             ('상업', 124),\n",
       "             ('퀄리티', 174),\n",
       "             ('쩔다', 219),\n",
       "             ('질', 510),\n",
       "             ('충분하다', 462),\n",
       "             ('개인', 828),\n",
       "             ('잔인하다', 435),\n",
       "             ('자극', 270),\n",
       "             ('노출씬', 11),\n",
       "             ('화끈하다', 107),\n",
       "             ('국산', 58),\n",
       "             ('아끼다', 84),\n",
       "             ('보임', 66),\n",
       "             ('끝내', 72),\n",
       "             ('지겹다', 284),\n",
       "             ('역시', 1979),\n",
       "             ('드니', 66),\n",
       "             ('일품', 116),\n",
       "             ('나다', 2242),\n",
       "             ('맥스', 41),\n",
       "             ('샘', 70),\n",
       "             ('죽이다', 666),\n",
       "             ('바랬다', 6),\n",
       "             ('괜찮다', 1780),\n",
       "             ('스러웟음', 1),\n",
       "             ('지네', 43),\n",
       "             ('뜨다', 354),\n",
       "             ('찍을껀데', 1),\n",
       "             ('면상', 16),\n",
       "             ('알다', 2938),\n",
       "             ('자신', 597),\n",
       "             ('어린이', 186),\n",
       "             ('어리다', 1442),\n",
       "             ('동심', 74),\n",
       "             ('멀리', 45),\n",
       "             ('무술', 113),\n",
       "             ('총을드', 1),\n",
       "             ('크리스토퍼', 31),\n",
       "             ('왈츠', 11),\n",
       "             ('타란티노', 67),\n",
       "             ('조합', 131),\n",
       "             ('이란', 761),\n",
       "             ('한국', 1333),\n",
       "             ('유명', 33),\n",
       "             ('한편', 333),\n",
       "             ('외국', 145),\n",
       "             ('상상', 247),\n",
       "             ('초월', 61),\n",
       "             ('유명하다', 205),\n",
       "             ('오랜', 759),\n",
       "             ('재밋', 384),\n",
       "             ('종방', 6),\n",
       "             ('되어다', 1363),\n",
       "             ('오늘', 584),\n",
       "             ('방도', 13),\n",
       "             ('방송', 439),\n",
       "             ('대본', 98),\n",
       "             ('완성', 299),\n",
       "             ('요즘', 852),\n",
       "             ('막장', 766),\n",
       "             ('지치다', 86),\n",
       "             ('수백향', 8),\n",
       "             ('바른', 6),\n",
       "             ('그리다', 675),\n",
       "             ('심하다', 438),\n",
       "             ('화이팅', 289),\n",
       "             ('조절', 113),\n",
       "             ('위원회', 29),\n",
       "             ('김혜선', 12),\n",
       "             ('김', 95),\n",
       "             ('순정', 23),\n",
       "             ('순', 248),\n",
       "             ('정이', 87),\n",
       "             ('역할', 231),\n",
       "             ('팜므파탈', 7),\n",
       "             ('로써', 125),\n",
       "             ('해내다', 152),\n",
       "             ('의외', 60),\n",
       "             ('사극', 177),\n",
       "             ('벌어지다', 59),\n",
       "             ('그녀', 333),\n",
       "             ('논란', 26),\n",
       "             ('왠지', 209),\n",
       "             ('코미디', 1069),\n",
       "             ('장면', 2425),\n",
       "             ('끝', 2039),\n",
       "             ('쯤', 388),\n",
       "             ('멍하다', 37),\n",
       "             ('한마디', 425),\n",
       "             ('ㅈ', 79),\n",
       "             ('공유', 64),\n",
       "             ('존잘', 20),\n",
       "             ('상쾌', 18),\n",
       "             ('발랄하다', 52),\n",
       "             ('껄끄런', 1),\n",
       "             ('유쾌하다', 534),\n",
       "             ('해설', 26),\n",
       "             ('소파', 7),\n",
       "             ...])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 등장 수\n",
    "tokenizer.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fd97ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43770"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_cnt = len(tokenizer.word_index)\n",
    "total_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0351ff4c",
   "metadata": {},
   "source": [
    "- 사용 단어 수를 지정하여 토큰화\n",
    "    - tokenizer = Tokenizer(num_words = 원하는 단어 수)\n",
    "    - tokenizer.fit_on_texts(train_df[\"token\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5890625",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tokenizer.texts_to_sequences(train_df[\"token\"])\n",
    "x_test = tokenizer.texts_to_sequences(test_df[\"token\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5745220",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df[\"label\"]\n",
    "y_test = test_df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "238120a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13.234950577753027, 10.0, 78, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = []\n",
    "for i in range(len(x_train)):\n",
    "    a.append(len(x_train[i]))\n",
    "np.mean(a), np.median(a), np.max(a), np.min(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "267c33f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, stratify = y_train, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9e1f0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = pad_sequences(x_train, maxlen = 60)\n",
    "val_seq = pad_sequences(x_val, maxlen = 60)\n",
    "test_seq = pad_sequences(x_test, maxlen = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f21b759e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 26ms/step - accuracy: 0.6801 - loss: 0.5742 - val_accuracy: 0.8027 - val_loss: 0.4225\n",
      "Epoch 2/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 24ms/step - accuracy: 0.7964 - loss: 0.4344 - val_accuracy: 0.8120 - val_loss: 0.4048\n",
      "Epoch 3/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 25ms/step - accuracy: 0.8111 - loss: 0.4102 - val_accuracy: 0.8180 - val_loss: 0.3990\n",
      "Epoch 4/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 25ms/step - accuracy: 0.8155 - loss: 0.4011 - val_accuracy: 0.8159 - val_loss: 0.3982\n",
      "Epoch 5/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 24ms/step - accuracy: 0.8208 - loss: 0.3903 - val_accuracy: 0.8206 - val_loss: 0.3930\n",
      "Epoch 6/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 25ms/step - accuracy: 0.8246 - loss: 0.3868 - val_accuracy: 0.8238 - val_loss: 0.3896\n",
      "Epoch 7/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 24ms/step - accuracy: 0.8268 - loss: 0.3815 - val_accuracy: 0.8197 - val_loss: 0.3920\n",
      "Epoch 8/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 28ms/step - accuracy: 0.8272 - loss: 0.3812 - val_accuracy: 0.8238 - val_loss: 0.3872\n",
      "Epoch 9/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 27ms/step - accuracy: 0.8294 - loss: 0.3777 - val_accuracy: 0.8253 - val_loss: 0.3845\n",
      "Epoch 10/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 31ms/step - accuracy: 0.8322 - loss: 0.3730 - val_accuracy: 0.8246 - val_loss: 0.3844\n",
      "Epoch 11/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 30ms/step - accuracy: 0.8351 - loss: 0.3668 - val_accuracy: 0.8269 - val_loss: 0.3820\n",
      "Epoch 12/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 28ms/step - accuracy: 0.8365 - loss: 0.3660 - val_accuracy: 0.8275 - val_loss: 0.3811\n",
      "Epoch 13/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 27ms/step - accuracy: 0.8359 - loss: 0.3654 - val_accuracy: 0.8276 - val_loss: 0.3831\n",
      "Epoch 14/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 26ms/step - accuracy: 0.8411 - loss: 0.3613 - val_accuracy: 0.8279 - val_loss: 0.3799\n",
      "Epoch 15/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 26ms/step - accuracy: 0.8391 - loss: 0.3610 - val_accuracy: 0.8298 - val_loss: 0.3776\n",
      "Epoch 16/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 28ms/step - accuracy: 0.8448 - loss: 0.3539 - val_accuracy: 0.8299 - val_loss: 0.3762\n",
      "Epoch 17/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 25ms/step - accuracy: 0.8438 - loss: 0.3550 - val_accuracy: 0.8313 - val_loss: 0.3752\n",
      "Epoch 18/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 25ms/step - accuracy: 0.8462 - loss: 0.3494 - val_accuracy: 0.8318 - val_loss: 0.3733\n",
      "Epoch 19/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 25ms/step - accuracy: 0.8480 - loss: 0.3472 - val_accuracy: 0.8294 - val_loss: 0.3766\n",
      "Epoch 20/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 25ms/step - accuracy: 0.8502 - loss: 0.3455 - val_accuracy: 0.8307 - val_loss: 0.3720\n",
      "Epoch 21/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 25ms/step - accuracy: 0.8531 - loss: 0.3403 - val_accuracy: 0.8311 - val_loss: 0.3731\n",
      "Epoch 22/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 27ms/step - accuracy: 0.8505 - loss: 0.3425 - val_accuracy: 0.8320 - val_loss: 0.3716\n",
      "Epoch 23/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 25ms/step - accuracy: 0.8537 - loss: 0.3388 - val_accuracy: 0.8340 - val_loss: 0.3706\n",
      "Epoch 24/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 25ms/step - accuracy: 0.8536 - loss: 0.3386 - val_accuracy: 0.8318 - val_loss: 0.3704\n",
      "Epoch 25/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 27ms/step - accuracy: 0.8560 - loss: 0.3352 - val_accuracy: 0.8327 - val_loss: 0.3690\n",
      "Epoch 26/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 25ms/step - accuracy: 0.8565 - loss: 0.3338 - val_accuracy: 0.8328 - val_loss: 0.3680\n",
      "Epoch 27/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 25ms/step - accuracy: 0.8556 - loss: 0.3345 - val_accuracy: 0.8332 - val_loss: 0.3675\n",
      "Epoch 28/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 25ms/step - accuracy: 0.8570 - loss: 0.3320 - val_accuracy: 0.8326 - val_loss: 0.3726\n",
      "Epoch 29/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 30ms/step - accuracy: 0.8588 - loss: 0.3288 - val_accuracy: 0.8317 - val_loss: 0.3691\n",
      "Epoch 30/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 28ms/step - accuracy: 0.8608 - loss: 0.3260 - val_accuracy: 0.8318 - val_loss: 0.3692\n",
      "Epoch 31/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 25ms/step - accuracy: 0.8629 - loss: 0.3215 - val_accuracy: 0.8343 - val_loss: 0.3694\n",
      "Epoch 32/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 28ms/step - accuracy: 0.8605 - loss: 0.3250 - val_accuracy: 0.8322 - val_loss: 0.3748\n",
      "Epoch 33/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 25ms/step - accuracy: 0.8630 - loss: 0.3209 - val_accuracy: 0.8344 - val_loss: 0.3686\n",
      "Epoch 34/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 28ms/step - accuracy: 0.8639 - loss: 0.3224 - val_accuracy: 0.8327 - val_loss: 0.3680\n",
      "Epoch 35/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 27ms/step - accuracy: 0.8640 - loss: 0.3196 - val_accuracy: 0.8342 - val_loss: 0.3725\n",
      "Epoch 36/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 26ms/step - accuracy: 0.8668 - loss: 0.3172 - val_accuracy: 0.8323 - val_loss: 0.3724\n",
      "Epoch 37/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 26ms/step - accuracy: 0.8663 - loss: 0.3157 - val_accuracy: 0.8304 - val_loss: 0.3746\n"
     ]
    }
   ],
   "source": [
    "model7 = keras.Sequential()\n",
    "model7.add(keras.layers.Embedding(4377, 256, input_shape = (60,)))\n",
    "model7.add(keras.layers.Dropout(0.3))\n",
    "\n",
    "model7.add(keras.layers.GRU(256, dropout = 0.3))\n",
    "\n",
    "model7.add(keras.layers.Dense(10, activation = \"relu\"))\n",
    "model7.add(keras.layers.BatchNormalization())\n",
    "model7.add(keras.layers.Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "rmsprop = keras.optimizers.RMSprop(learning_rate = 0.0001)\n",
    "model7.compile(optimizer = rmsprop, loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "\n",
    "history7 = model7.fit(train_seq, y_train, batch_size = 64, epochs = 1000,\n",
    "                    validation_data = (val_seq, y_val), callbacks = [early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34f8500a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1513/1513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.8382 - loss: 0.3655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.368745356798172, 0.8358779549598694]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7.evaluate(test_seq, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aff11d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = pad_sequences(x_train, maxlen = 65)\n",
    "val_seq = pad_sequences(x_val, maxlen = 65)\n",
    "test_seq = pad_sequences(x_test, maxlen = 65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11e5282f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 59ms/step - accuracy: 0.6552 - loss: 0.6001 - val_accuracy: 0.7666 - val_loss: 0.4687\n",
      "Epoch 2/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 59ms/step - accuracy: 0.7936 - loss: 0.4400 - val_accuracy: 0.8005 - val_loss: 0.4203\n",
      "Epoch 3/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 64ms/step - accuracy: 0.8101 - loss: 0.4134 - val_accuracy: 0.8222 - val_loss: 0.3901\n",
      "Epoch 4/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 51ms/step - accuracy: 0.8186 - loss: 0.3998 - val_accuracy: 0.8197 - val_loss: 0.3912\n",
      "Epoch 5/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 51ms/step - accuracy: 0.8250 - loss: 0.3916 - val_accuracy: 0.8281 - val_loss: 0.3815\n",
      "Epoch 6/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 52ms/step - accuracy: 0.8286 - loss: 0.3850 - val_accuracy: 0.8303 - val_loss: 0.3757\n",
      "Epoch 7/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 54ms/step - accuracy: 0.8284 - loss: 0.3799 - val_accuracy: 0.8322 - val_loss: 0.3717\n",
      "Epoch 8/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 59ms/step - accuracy: 0.8340 - loss: 0.3703 - val_accuracy: 0.8303 - val_loss: 0.3732\n",
      "Epoch 9/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 63ms/step - accuracy: 0.8352 - loss: 0.3700 - val_accuracy: 0.8349 - val_loss: 0.3646\n",
      "Epoch 10/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 63ms/step - accuracy: 0.8387 - loss: 0.3666 - val_accuracy: 0.8354 - val_loss: 0.3638\n",
      "Epoch 11/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 64ms/step - accuracy: 0.8408 - loss: 0.3601 - val_accuracy: 0.8385 - val_loss: 0.3618\n",
      "Epoch 12/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 61ms/step - accuracy: 0.8453 - loss: 0.3565 - val_accuracy: 0.8392 - val_loss: 0.3589\n",
      "Epoch 13/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 62ms/step - accuracy: 0.8448 - loss: 0.3566 - val_accuracy: 0.8409 - val_loss: 0.3559\n",
      "Epoch 14/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 61ms/step - accuracy: 0.8451 - loss: 0.3540 - val_accuracy: 0.8418 - val_loss: 0.3552\n",
      "Epoch 15/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 62ms/step - accuracy: 0.8493 - loss: 0.3493 - val_accuracy: 0.8390 - val_loss: 0.3597\n",
      "Epoch 16/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 61ms/step - accuracy: 0.8473 - loss: 0.3464 - val_accuracy: 0.8429 - val_loss: 0.3522\n",
      "Epoch 17/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 60ms/step - accuracy: 0.8509 - loss: 0.3434 - val_accuracy: 0.8415 - val_loss: 0.3504\n",
      "Epoch 18/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 65ms/step - accuracy: 0.8505 - loss: 0.3434 - val_accuracy: 0.8417 - val_loss: 0.3535\n",
      "Epoch 19/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 61ms/step - accuracy: 0.8539 - loss: 0.3356 - val_accuracy: 0.8456 - val_loss: 0.3474\n",
      "Epoch 20/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 64ms/step - accuracy: 0.8526 - loss: 0.3380 - val_accuracy: 0.8446 - val_loss: 0.3486\n",
      "Epoch 21/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 57ms/step - accuracy: 0.8532 - loss: 0.3374 - val_accuracy: 0.8441 - val_loss: 0.3480\n",
      "Epoch 22/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 58ms/step - accuracy: 0.8550 - loss: 0.3351 - val_accuracy: 0.8461 - val_loss: 0.3491\n",
      "Epoch 23/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 59ms/step - accuracy: 0.8573 - loss: 0.3312 - val_accuracy: 0.8449 - val_loss: 0.3470\n",
      "Epoch 24/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 64ms/step - accuracy: 0.8594 - loss: 0.3281 - val_accuracy: 0.8463 - val_loss: 0.3459\n",
      "Epoch 25/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 62ms/step - accuracy: 0.8589 - loss: 0.3266 - val_accuracy: 0.8451 - val_loss: 0.3444\n",
      "Epoch 26/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 64ms/step - accuracy: 0.8606 - loss: 0.3291 - val_accuracy: 0.8480 - val_loss: 0.3441\n",
      "Epoch 27/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 66ms/step - accuracy: 0.8627 - loss: 0.3207 - val_accuracy: 0.8471 - val_loss: 0.3447\n",
      "Epoch 28/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 66ms/step - accuracy: 0.8617 - loss: 0.3198 - val_accuracy: 0.8468 - val_loss: 0.3457\n",
      "Epoch 29/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 64ms/step - accuracy: 0.8634 - loss: 0.3198 - val_accuracy: 0.8476 - val_loss: 0.3413\n",
      "Epoch 30/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 67ms/step - accuracy: 0.8635 - loss: 0.3209 - val_accuracy: 0.8471 - val_loss: 0.3432\n",
      "Epoch 31/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 65ms/step - accuracy: 0.8628 - loss: 0.3208 - val_accuracy: 0.8476 - val_loss: 0.3438\n",
      "Epoch 32/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 63ms/step - accuracy: 0.8668 - loss: 0.3152 - val_accuracy: 0.8475 - val_loss: 0.3556\n",
      "Epoch 33/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 65ms/step - accuracy: 0.8664 - loss: 0.3113 - val_accuracy: 0.8491 - val_loss: 0.3441\n",
      "Epoch 34/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 64ms/step - accuracy: 0.8660 - loss: 0.3149 - val_accuracy: 0.8492 - val_loss: 0.3423\n",
      "Epoch 35/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 60ms/step - accuracy: 0.8677 - loss: 0.3106 - val_accuracy: 0.8506 - val_loss: 0.3404\n",
      "Epoch 36/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 59ms/step - accuracy: 0.8678 - loss: 0.3097 - val_accuracy: 0.8483 - val_loss: 0.3425\n",
      "Epoch 37/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 60ms/step - accuracy: 0.8681 - loss: 0.3117 - val_accuracy: 0.8498 - val_loss: 0.3390\n",
      "Epoch 38/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 61ms/step - accuracy: 0.8703 - loss: 0.3090 - val_accuracy: 0.8487 - val_loss: 0.3426\n",
      "Epoch 39/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 60ms/step - accuracy: 0.8725 - loss: 0.3046 - val_accuracy: 0.8498 - val_loss: 0.3387\n",
      "Epoch 40/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 60ms/step - accuracy: 0.8704 - loss: 0.3059 - val_accuracy: 0.8492 - val_loss: 0.3390\n",
      "Epoch 41/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 61ms/step - accuracy: 0.8701 - loss: 0.3052 - val_accuracy: 0.8503 - val_loss: 0.3442\n",
      "Epoch 42/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 60ms/step - accuracy: 0.8724 - loss: 0.3022 - val_accuracy: 0.8509 - val_loss: 0.3438\n",
      "Epoch 43/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 60ms/step - accuracy: 0.8725 - loss: 0.3007 - val_accuracy: 0.8496 - val_loss: 0.3444\n",
      "Epoch 44/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 60ms/step - accuracy: 0.8750 - loss: 0.2971 - val_accuracy: 0.8494 - val_loss: 0.3416\n",
      "Epoch 45/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 61ms/step - accuracy: 0.8706 - loss: 0.3036 - val_accuracy: 0.8510 - val_loss: 0.3388\n",
      "Epoch 46/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 61ms/step - accuracy: 0.8750 - loss: 0.2981 - val_accuracy: 0.8511 - val_loss: 0.3389\n",
      "Epoch 47/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 61ms/step - accuracy: 0.8779 - loss: 0.2946 - val_accuracy: 0.8523 - val_loss: 0.3421\n",
      "Epoch 48/1000\n",
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 61ms/step - accuracy: 0.8757 - loss: 0.2979 - val_accuracy: 0.8507 - val_loss: 0.3413\n",
      "Epoch 49/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3592/3592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 60ms/step - accuracy: 0.8767 - loss: 0.2957 - val_accuracy: 0.8505 - val_loss: 0.3460\n"
     ]
    }
   ],
   "source": [
    "model8 = keras.Sequential()\n",
    "model8.add(keras.layers.Embedding(4377, 256, input_shape = (65,)))\n",
    "model8.add(keras.layers.Dropout(0.4))\n",
    "\n",
    "model8.add(keras.layers.GRU(256, dropout = 0.4))\n",
    "\n",
    "model8.add(keras.layers.Dense(10, activation = \"relu\"))\n",
    "model8.add(keras.layers.BatchNormalization())\n",
    "model8.add(keras.layers.Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "rmsprop = keras.optimizers.RMSprop(learning_rate = 0.0001)\n",
    "model8.compile(optimizer = rmsprop, loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "\n",
    "history8 = model8.fit(train_seq, y_train, batch_size = 32, epochs = 1000,\n",
    "                    validation_data = (val_seq, y_val), callbacks = [early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2d172c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1513/1513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 17ms/step - accuracy: 0.8520 - loss: 0.3404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3422556221485138, 0.8503398299217224]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model8.evaluate(test_seq, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5539d4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m762s\u001b[0m 423ms/step - accuracy: 0.6944 - loss: 0.5640 - val_accuracy: 0.7999 - val_loss: 0.4217\n",
      "Epoch 2/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m741s\u001b[0m 413ms/step - accuracy: 0.7992 - loss: 0.4246 - val_accuracy: 0.8203 - val_loss: 0.3915\n",
      "Epoch 3/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m753s\u001b[0m 419ms/step - accuracy: 0.8207 - loss: 0.3920 - val_accuracy: 0.8255 - val_loss: 0.3818\n",
      "Epoch 4/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m727s\u001b[0m 405ms/step - accuracy: 0.8249 - loss: 0.3863 - val_accuracy: 0.8288 - val_loss: 0.3756\n",
      "Epoch 5/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m777s\u001b[0m 432ms/step - accuracy: 0.8314 - loss: 0.3757 - val_accuracy: 0.8303 - val_loss: 0.3741\n",
      "Epoch 6/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m779s\u001b[0m 434ms/step - accuracy: 0.8361 - loss: 0.3677 - val_accuracy: 0.8363 - val_loss: 0.3660\n",
      "Epoch 7/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m771s\u001b[0m 429ms/step - accuracy: 0.8389 - loss: 0.3635 - val_accuracy: 0.8326 - val_loss: 0.3671\n",
      "Epoch 8/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m760s\u001b[0m 423ms/step - accuracy: 0.8392 - loss: 0.3609 - val_accuracy: 0.8353 - val_loss: 0.3659\n",
      "Epoch 9/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m724s\u001b[0m 403ms/step - accuracy: 0.8447 - loss: 0.3536 - val_accuracy: 0.8404 - val_loss: 0.3616\n",
      "Epoch 10/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m667s\u001b[0m 371ms/step - accuracy: 0.8473 - loss: 0.3498 - val_accuracy: 0.8402 - val_loss: 0.3571\n",
      "Epoch 11/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m779s\u001b[0m 434ms/step - accuracy: 0.8458 - loss: 0.3504 - val_accuracy: 0.8423 - val_loss: 0.3551\n",
      "Epoch 12/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m728s\u001b[0m 406ms/step - accuracy: 0.8493 - loss: 0.3455 - val_accuracy: 0.8421 - val_loss: 0.3573\n",
      "Epoch 13/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m667s\u001b[0m 371ms/step - accuracy: 0.8520 - loss: 0.3400 - val_accuracy: 0.8404 - val_loss: 0.3542\n",
      "Epoch 14/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m724s\u001b[0m 403ms/step - accuracy: 0.8523 - loss: 0.3375 - val_accuracy: 0.8424 - val_loss: 0.3496\n",
      "Epoch 15/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m608s\u001b[0m 338ms/step - accuracy: 0.8562 - loss: 0.3294 - val_accuracy: 0.8444 - val_loss: 0.3501\n",
      "Epoch 16/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m578s\u001b[0m 322ms/step - accuracy: 0.8572 - loss: 0.3302 - val_accuracy: 0.8446 - val_loss: 0.3488\n",
      "Epoch 17/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m571s\u001b[0m 318ms/step - accuracy: 0.8583 - loss: 0.3283 - val_accuracy: 0.8472 - val_loss: 0.3494\n",
      "Epoch 18/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m576s\u001b[0m 321ms/step - accuracy: 0.8604 - loss: 0.3247 - val_accuracy: 0.8460 - val_loss: 0.3429\n",
      "Epoch 19/1000\n",
      "\u001b[1m1796/1796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m580s\u001b[0m 323ms/step - accuracy: 0.8607 - loss: 0.3242 - val_accuracy: 0.8462 - val_loss: 0.3453\n",
      "Epoch 20/1000\n",
      "\u001b[1m 989/1796\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4:11\u001b[0m 311ms/step - accuracy: 0.8614 - loss: 0.3211"
     ]
    }
   ],
   "source": [
    "model9 = keras.Sequential()\n",
    "model9.add(keras.layers.Embedding(4377, 512, input_shape = (65,)))\n",
    "model9.add(keras.layers.Dropout(0.4))\n",
    "\n",
    "model9.add(keras.layers.GRU(512, dropout = 0.4))\n",
    "\n",
    "model9.add(keras.layers.Dense(10, activation = \"relu\"))\n",
    "model9.add(keras.layers.BatchNormalization())\n",
    "model9.add(keras.layers.Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "rmsprop = keras.optimizers.RMSprop(learning_rate = 0.0001)\n",
    "model9.compile(optimizer = rmsprop, loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "\n",
    "history9 = model9.fit(train_seq, y_train, batch_size = 64, epochs = 1000,\n",
    "                    validation_data = (val_seq, y_val), callbacks = [early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6e3e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model9.evaluate(test_seq, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72b7e76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ce1b02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c36f56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26406c36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d102760e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb26fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00d0f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1b842c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49283601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edad4d03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36691c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28248011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadd5560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ca7e01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02068709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbde12a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b34ee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8d077d65",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.7525 - loss: 0.4932 - val_accuracy: 0.8086 - val_loss: 0.4161\n",
      "Epoch 2/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8154 - loss: 0.4068 - val_accuracy: 0.8191 - val_loss: 0.3961\n",
      "Epoch 3/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8244 - loss: 0.3899 - val_accuracy: 0.8216 - val_loss: 0.3879\n",
      "Epoch 4/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8339 - loss: 0.3732 - val_accuracy: 0.8253 - val_loss: 0.3834\n",
      "Epoch 5/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8368 - loss: 0.3697 - val_accuracy: 0.8270 - val_loss: 0.3816\n",
      "Epoch 6/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8415 - loss: 0.3614 - val_accuracy: 0.8276 - val_loss: 0.3779\n",
      "Epoch 7/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8430 - loss: 0.3613 - val_accuracy: 0.8270 - val_loss: 0.3779\n",
      "Epoch 8/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8461 - loss: 0.3526 - val_accuracy: 0.8285 - val_loss: 0.3815\n",
      "Epoch 9/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8497 - loss: 0.3484 - val_accuracy: 0.8309 - val_loss: 0.3749\n",
      "Epoch 10/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8526 - loss: 0.3449 - val_accuracy: 0.8271 - val_loss: 0.3821\n",
      "Epoch 11/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8514 - loss: 0.3430 - val_accuracy: 0.8283 - val_loss: 0.3826\n",
      "Epoch 12/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8562 - loss: 0.3369 - val_accuracy: 0.8277 - val_loss: 0.3815\n",
      "Epoch 13/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8562 - loss: 0.3362 - val_accuracy: 0.8283 - val_loss: 0.3836\n",
      "Epoch 14/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8594 - loss: 0.3303 - val_accuracy: 0.8293 - val_loss: 0.3817\n",
      "Epoch 15/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8600 - loss: 0.3268 - val_accuracy: 0.8284 - val_loss: 0.3842\n",
      "Epoch 16/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8633 - loss: 0.3229 - val_accuracy: 0.8273 - val_loss: 0.3848\n",
      "Epoch 17/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8628 - loss: 0.3249 - val_accuracy: 0.8274 - val_loss: 0.3879\n",
      "Epoch 18/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8652 - loss: 0.3172 - val_accuracy: 0.8263 - val_loss: 0.3901\n",
      "Epoch 19/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8687 - loss: 0.3157 - val_accuracy: 0.8262 - val_loss: 0.3960\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(4377, 128, input_shape = (13,)))\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "\n",
    "model.add(keras.layers.GRU(128, dropout = 0.4))\n",
    "\n",
    "model.add(keras.layers.Dense(10, activation = \"relu\"))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "rmsprop = keras.optimizers.RMSprop(learning_rate = 0.001)\n",
    "model.compile(optimizer = rmsprop, loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "\n",
    "history = model.fit(train_seq, y_train, batch_size = 32, epochs = 1000,\n",
    "                    validation_data = (val_seq, y_val), callbacks = [early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7d0e5fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8309 - loss: 0.3697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3741733729839325, 0.8292374610900879]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_seq, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5c9943d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m1792/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 13ms/step - accuracy: 0.6504 - loss: 0.6024 - val_accuracy: 0.8064 - val_loss: 0.4250\n",
      "Epoch 2/1000\n",
      "\u001b[1m1792/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - accuracy: 0.7832 - loss: 0.4471 - val_accuracy: 0.8166 - val_loss: 0.4034\n",
      "Epoch 3/1000\n",
      "\u001b[1m1792/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - accuracy: 0.8043 - loss: 0.4173 - val_accuracy: 0.8188 - val_loss: 0.3952\n",
      "Epoch 4/1000\n",
      "\u001b[1m1792/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - accuracy: 0.8165 - loss: 0.3993 - val_accuracy: 0.8205 - val_loss: 0.3920\n",
      "Epoch 5/1000\n",
      "\u001b[1m1792/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - accuracy: 0.8252 - loss: 0.3901 - val_accuracy: 0.8191 - val_loss: 0.3913\n",
      "Epoch 6/1000\n",
      "\u001b[1m1792/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - accuracy: 0.8263 - loss: 0.3826 - val_accuracy: 0.8216 - val_loss: 0.3882\n",
      "Epoch 7/1000\n",
      "\u001b[1m1792/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - accuracy: 0.8290 - loss: 0.3756 - val_accuracy: 0.8226 - val_loss: 0.3868\n",
      "Epoch 8/1000\n",
      "\u001b[1m1792/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - accuracy: 0.8296 - loss: 0.3735 - val_accuracy: 0.8218 - val_loss: 0.3870\n",
      "Epoch 9/1000\n",
      "\u001b[1m1792/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - accuracy: 0.8328 - loss: 0.3681 - val_accuracy: 0.8228 - val_loss: 0.3853\n",
      "Epoch 10/1000\n",
      "\u001b[1m1792/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - accuracy: 0.8344 - loss: 0.3639 - val_accuracy: 0.8236 - val_loss: 0.3854\n",
      "Epoch 11/1000\n",
      "\u001b[1m1792/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 13ms/step - accuracy: 0.8393 - loss: 0.3553 - val_accuracy: 0.8234 - val_loss: 0.3862\n",
      "Epoch 12/1000\n",
      "\u001b[1m1792/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - accuracy: 0.8386 - loss: 0.3555 - val_accuracy: 0.8246 - val_loss: 0.3866\n",
      "Epoch 13/1000\n",
      "\u001b[1m1792/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - accuracy: 0.8436 - loss: 0.3508 - val_accuracy: 0.8242 - val_loss: 0.3872\n",
      "Epoch 14/1000\n",
      "\u001b[1m1792/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - accuracy: 0.8417 - loss: 0.3494 - val_accuracy: 0.8240 - val_loss: 0.3873\n",
      "Epoch 15/1000\n",
      "\u001b[1m1792/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - accuracy: 0.8435 - loss: 0.3462 - val_accuracy: 0.8244 - val_loss: 0.3901\n",
      "Epoch 16/1000\n",
      "\u001b[1m1792/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - accuracy: 0.8474 - loss: 0.3405 - val_accuracy: 0.8236 - val_loss: 0.3871\n",
      "Epoch 17/1000\n",
      "\u001b[1m1792/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - accuracy: 0.8460 - loss: 0.3410 - val_accuracy: 0.8243 - val_loss: 0.3890\n",
      "Epoch 18/1000\n",
      "\u001b[1m1792/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - accuracy: 0.8480 - loss: 0.3395 - val_accuracy: 0.8242 - val_loss: 0.3895\n",
      "Epoch 19/1000\n",
      "\u001b[1m1792/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - accuracy: 0.8534 - loss: 0.3289 - val_accuracy: 0.8249 - val_loss: 0.3928\n",
      "Epoch 20/1000\n",
      "\u001b[1m1792/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 13ms/step - accuracy: 0.8513 - loss: 0.3301 - val_accuracy: 0.8242 - val_loss: 0.3933\n",
      "Epoch 21/1000\n",
      "\u001b[1m1792/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 13ms/step - accuracy: 0.8544 - loss: 0.3247 - val_accuracy: 0.8236 - val_loss: 0.3949\n",
      "Epoch 22/1000\n",
      "\u001b[1m1792/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 13ms/step - accuracy: 0.8568 - loss: 0.3207 - val_accuracy: 0.8238 - val_loss: 0.3966\n",
      "Epoch 23/1000\n",
      "\u001b[1m1792/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 13ms/step - accuracy: 0.8569 - loss: 0.3209 - val_accuracy: 0.8241 - val_loss: 0.3974\n",
      "Epoch 24/1000\n",
      "\u001b[1m1792/1792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 13ms/step - accuracy: 0.8594 - loss: 0.3182 - val_accuracy: 0.8238 - val_loss: 0.3934\n"
     ]
    }
   ],
   "source": [
    "model3 = keras.Sequential()\n",
    "model3.add(keras.layers.Embedding(4212, 256, input_shape = (13,)))\n",
    "model3.add(keras.layers.Dropout(0.4))\n",
    "\n",
    "model3.add(keras.layers.LSTM(256, dropout = 0.4))\n",
    "\n",
    "model3.add(keras.layers.Dense(10, activation = \"relu\"))\n",
    "model3.add(keras.layers.BatchNormalization())\n",
    "model3.add(keras.layers.Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "adam = keras.optimizers.Adam(learning_rate =0.00005)\n",
    "model3.compile(loss = \"binary_crossentropy\", optimizer = adam, metrics = [\"accuracy\"])\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 15, restore_best_weights = True)\n",
    "\n",
    "history = model3.fit(train_seq, y_train, batch_size = 64, epochs = 1000, validation_data = (val_seq, y_val), callbacks = [early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6fe6456c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8246 - loss: 0.3806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3834826648235321, 0.8235806226730347]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(test_seq, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a5074231",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m7166/7166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 6ms/step - accuracy: 0.6685 - loss: 0.5888 - val_accuracy: 0.8085 - val_loss: 0.4177\n",
      "Epoch 2/1000\n",
      "\u001b[1m7166/7166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 6ms/step - accuracy: 0.7915 - loss: 0.4444 - val_accuracy: 0.8194 - val_loss: 0.3941\n",
      "Epoch 3/1000\n",
      "\u001b[1m7166/7166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 6ms/step - accuracy: 0.8126 - loss: 0.4137 - val_accuracy: 0.8173 - val_loss: 0.3947\n",
      "Epoch 4/1000\n",
      "\u001b[1m7166/7166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 6ms/step - accuracy: 0.8222 - loss: 0.3983 - val_accuracy: 0.8260 - val_loss: 0.3842\n",
      "Epoch 5/1000\n",
      "\u001b[1m7166/7166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 6ms/step - accuracy: 0.8243 - loss: 0.3928 - val_accuracy: 0.8264 - val_loss: 0.3829\n",
      "Epoch 6/1000\n",
      "\u001b[1m7166/7166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 6ms/step - accuracy: 0.8311 - loss: 0.3812 - val_accuracy: 0.8280 - val_loss: 0.3829\n",
      "Epoch 7/1000\n",
      "\u001b[1m7166/7166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 6ms/step - accuracy: 0.8391 - loss: 0.3705 - val_accuracy: 0.8282 - val_loss: 0.3807\n",
      "Epoch 8/1000\n",
      "\u001b[1m7166/7166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 6ms/step - accuracy: 0.8391 - loss: 0.3667 - val_accuracy: 0.8289 - val_loss: 0.3818\n",
      "Epoch 9/1000\n",
      "\u001b[1m7166/7166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 6ms/step - accuracy: 0.8428 - loss: 0.3643 - val_accuracy: 0.8294 - val_loss: 0.3802\n",
      "Epoch 10/1000\n",
      "\u001b[1m7166/7166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 6ms/step - accuracy: 0.8454 - loss: 0.3555 - val_accuracy: 0.8302 - val_loss: 0.3797\n",
      "Epoch 11/1000\n",
      "\u001b[1m7166/7166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 6ms/step - accuracy: 0.8467 - loss: 0.3540 - val_accuracy: 0.8282 - val_loss: 0.3840\n",
      "Epoch 12/1000\n",
      "\u001b[1m7166/7166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 6ms/step - accuracy: 0.8469 - loss: 0.3529 - val_accuracy: 0.8273 - val_loss: 0.3858\n",
      "Epoch 13/1000\n",
      "\u001b[1m7166/7166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 6ms/step - accuracy: 0.8510 - loss: 0.3455 - val_accuracy: 0.8275 - val_loss: 0.3818\n",
      "Epoch 14/1000\n",
      "\u001b[1m7166/7166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 6ms/step - accuracy: 0.8529 - loss: 0.3398 - val_accuracy: 0.8279 - val_loss: 0.3876\n",
      "Epoch 15/1000\n",
      "\u001b[1m7166/7166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 6ms/step - accuracy: 0.8547 - loss: 0.3413 - val_accuracy: 0.8273 - val_loss: 0.3873\n",
      "Epoch 16/1000\n",
      "\u001b[1m7166/7166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 6ms/step - accuracy: 0.8582 - loss: 0.3314 - val_accuracy: 0.8279 - val_loss: 0.3897\n",
      "Epoch 17/1000\n",
      "\u001b[1m7166/7166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 6ms/step - accuracy: 0.8606 - loss: 0.3295 - val_accuracy: 0.8287 - val_loss: 0.3911\n",
      "Epoch 18/1000\n",
      "\u001b[1m7166/7166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 6ms/step - accuracy: 0.8640 - loss: 0.3253 - val_accuracy: 0.8302 - val_loss: 0.3862\n",
      "Epoch 19/1000\n",
      "\u001b[1m7166/7166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 6ms/step - accuracy: 0.8628 - loss: 0.3253 - val_accuracy: 0.8294 - val_loss: 0.3875\n",
      "Epoch 20/1000\n",
      "\u001b[1m7166/7166\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 6ms/step - accuracy: 0.8660 - loss: 0.3195 - val_accuracy: 0.8284 - val_loss: 0.3903\n"
     ]
    }
   ],
   "source": [
    "model4 = keras.Sequential()\n",
    "model4.add(keras.layers.Embedding(8424, 128, input_shape = (13,)))\n",
    "model4.add(keras.layers.Dropout(0.4))\n",
    "\n",
    "model4.add(keras.layers.LSTM(256, dropout = 0.4))\n",
    "\n",
    "model4.add(keras.layers.Dense(10, activation = \"relu\"))\n",
    "model4.add(keras.layers.BatchNormalization())\n",
    "model4.add(keras.layers.Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "adam = keras.optimizers.Adam(learning_rate =0.00005)\n",
    "model4.compile(loss = \"binary_crossentropy\", optimizer = adam, metrics = [\"accuracy\"])\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "\n",
    "history = model4.fit(train_seq, y_train, batch_size = 16, epochs = 1000, validation_data = (val_seq, y_val), callbacks = [early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bce19e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8313 - loss: 0.3734\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.37741202116012573, 0.8287401795387268]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.evaluate(test_seq, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "30660071",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.5280 - loss: 0.7040 - val_accuracy: 0.6075 - val_loss: 0.6598\n",
      "Epoch 2/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.6039 - loss: 0.6580 - val_accuracy: 0.6879 - val_loss: 0.5971\n",
      "Epoch 3/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 8ms/step - accuracy: 0.6470 - loss: 0.6199 - val_accuracy: 0.7244 - val_loss: 0.5493\n",
      "Epoch 4/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 8ms/step - accuracy: 0.6821 - loss: 0.5865 - val_accuracy: 0.7511 - val_loss: 0.5145\n",
      "Epoch 5/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 8ms/step - accuracy: 0.7081 - loss: 0.5560 - val_accuracy: 0.7685 - val_loss: 0.4888\n",
      "Epoch 6/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 8ms/step - accuracy: 0.7267 - loss: 0.5327 - val_accuracy: 0.7804 - val_loss: 0.4691\n",
      "Epoch 7/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 8ms/step - accuracy: 0.7404 - loss: 0.5139 - val_accuracy: 0.7894 - val_loss: 0.4547\n",
      "Epoch 8/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 8ms/step - accuracy: 0.7501 - loss: 0.5008 - val_accuracy: 0.7949 - val_loss: 0.4439\n",
      "Epoch 9/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.7607 - loss: 0.4866 - val_accuracy: 0.8000 - val_loss: 0.4364\n",
      "Epoch 10/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.7717 - loss: 0.4733 - val_accuracy: 0.8026 - val_loss: 0.4273\n",
      "Epoch 11/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.7770 - loss: 0.4650 - val_accuracy: 0.8064 - val_loss: 0.4221\n",
      "Epoch 12/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.7805 - loss: 0.4573 - val_accuracy: 0.8089 - val_loss: 0.4175\n",
      "Epoch 13/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.7859 - loss: 0.4521 - val_accuracy: 0.8120 - val_loss: 0.4142\n",
      "Epoch 14/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.7868 - loss: 0.4491 - val_accuracy: 0.8132 - val_loss: 0.4100\n",
      "Epoch 15/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.7938 - loss: 0.4383 - val_accuracy: 0.8155 - val_loss: 0.4073\n",
      "Epoch 16/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.7964 - loss: 0.4317 - val_accuracy: 0.8165 - val_loss: 0.4046\n",
      "Epoch 17/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.7978 - loss: 0.4318 - val_accuracy: 0.8180 - val_loss: 0.4031\n",
      "Epoch 18/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8014 - loss: 0.4265 - val_accuracy: 0.8181 - val_loss: 0.4000\n",
      "Epoch 19/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8050 - loss: 0.4215 - val_accuracy: 0.8185 - val_loss: 0.3996\n",
      "Epoch 20/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8063 - loss: 0.4176 - val_accuracy: 0.8203 - val_loss: 0.3970\n",
      "Epoch 21/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8073 - loss: 0.4186 - val_accuracy: 0.8208 - val_loss: 0.3957\n",
      "Epoch 22/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8085 - loss: 0.4142 - val_accuracy: 0.8218 - val_loss: 0.3948\n",
      "Epoch 23/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8121 - loss: 0.4099 - val_accuracy: 0.8218 - val_loss: 0.3933\n",
      "Epoch 24/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8151 - loss: 0.4085 - val_accuracy: 0.8225 - val_loss: 0.3927\n",
      "Epoch 25/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8168 - loss: 0.4012 - val_accuracy: 0.8224 - val_loss: 0.3918\n",
      "Epoch 26/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8163 - loss: 0.4045 - val_accuracy: 0.8224 - val_loss: 0.3906\n",
      "Epoch 27/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8147 - loss: 0.4027 - val_accuracy: 0.8223 - val_loss: 0.3902\n",
      "Epoch 28/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8175 - loss: 0.4015 - val_accuracy: 0.8226 - val_loss: 0.3893\n",
      "Epoch 29/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8181 - loss: 0.3992 - val_accuracy: 0.8237 - val_loss: 0.3884\n",
      "Epoch 30/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8199 - loss: 0.3985 - val_accuracy: 0.8232 - val_loss: 0.3881\n",
      "Epoch 31/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8212 - loss: 0.3960 - val_accuracy: 0.8242 - val_loss: 0.3873\n",
      "Epoch 32/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8247 - loss: 0.3941 - val_accuracy: 0.8245 - val_loss: 0.3868\n",
      "Epoch 33/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8237 - loss: 0.3921 - val_accuracy: 0.8242 - val_loss: 0.3864\n",
      "Epoch 34/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8228 - loss: 0.3936 - val_accuracy: 0.8265 - val_loss: 0.3871\n",
      "Epoch 35/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8248 - loss: 0.3899 - val_accuracy: 0.8250 - val_loss: 0.3858\n",
      "Epoch 36/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8246 - loss: 0.3869 - val_accuracy: 0.8249 - val_loss: 0.3854\n",
      "Epoch 37/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8237 - loss: 0.3896 - val_accuracy: 0.8236 - val_loss: 0.3853\n",
      "Epoch 38/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8270 - loss: 0.3846 - val_accuracy: 0.8258 - val_loss: 0.3853\n",
      "Epoch 39/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8262 - loss: 0.3861 - val_accuracy: 0.8269 - val_loss: 0.3856\n",
      "Epoch 40/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8266 - loss: 0.3861 - val_accuracy: 0.8255 - val_loss: 0.3843\n",
      "Epoch 41/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8265 - loss: 0.3869 - val_accuracy: 0.8233 - val_loss: 0.3848\n",
      "Epoch 42/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8300 - loss: 0.3791 - val_accuracy: 0.8245 - val_loss: 0.3840\n",
      "Epoch 43/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8291 - loss: 0.3789 - val_accuracy: 0.8257 - val_loss: 0.3836\n",
      "Epoch 44/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8287 - loss: 0.3817 - val_accuracy: 0.8244 - val_loss: 0.3835\n",
      "Epoch 45/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8331 - loss: 0.3760 - val_accuracy: 0.8245 - val_loss: 0.3841\n",
      "Epoch 46/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8304 - loss: 0.3782 - val_accuracy: 0.8253 - val_loss: 0.3833\n",
      "Epoch 47/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8330 - loss: 0.3744 - val_accuracy: 0.8251 - val_loss: 0.3831\n",
      "Epoch 48/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8317 - loss: 0.3777 - val_accuracy: 0.8262 - val_loss: 0.3829\n",
      "Epoch 49/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 9ms/step - accuracy: 0.8321 - loss: 0.3770 - val_accuracy: 0.8252 - val_loss: 0.3830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 8ms/step - accuracy: 0.8348 - loss: 0.3724 - val_accuracy: 0.8259 - val_loss: 0.3824\n",
      "Epoch 51/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8333 - loss: 0.3738 - val_accuracy: 0.8264 - val_loss: 0.3834\n",
      "Epoch 52/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8356 - loss: 0.3707 - val_accuracy: 0.8259 - val_loss: 0.3822\n",
      "Epoch 53/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8349 - loss: 0.3737 - val_accuracy: 0.8268 - val_loss: 0.3825\n",
      "Epoch 54/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8350 - loss: 0.3705 - val_accuracy: 0.8264 - val_loss: 0.3820\n",
      "Epoch 55/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 8ms/step - accuracy: 0.8355 - loss: 0.3700 - val_accuracy: 0.8268 - val_loss: 0.3820\n",
      "Epoch 56/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8371 - loss: 0.3672 - val_accuracy: 0.8249 - val_loss: 0.3822\n",
      "Epoch 57/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8350 - loss: 0.3689 - val_accuracy: 0.8267 - val_loss: 0.3819\n",
      "Epoch 58/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8371 - loss: 0.3686 - val_accuracy: 0.8251 - val_loss: 0.3824\n",
      "Epoch 59/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 8ms/step - accuracy: 0.8395 - loss: 0.3645 - val_accuracy: 0.8263 - val_loss: 0.3820\n",
      "Epoch 60/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8382 - loss: 0.3669 - val_accuracy: 0.8261 - val_loss: 0.3820\n",
      "Epoch 61/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8376 - loss: 0.3661 - val_accuracy: 0.8273 - val_loss: 0.3813\n",
      "Epoch 62/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8382 - loss: 0.3656 - val_accuracy: 0.8267 - val_loss: 0.3816\n",
      "Epoch 63/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8388 - loss: 0.3640 - val_accuracy: 0.8272 - val_loss: 0.3816\n",
      "Epoch 64/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8411 - loss: 0.3624 - val_accuracy: 0.8270 - val_loss: 0.3813\n",
      "Epoch 65/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8395 - loss: 0.3646 - val_accuracy: 0.8263 - val_loss: 0.3814\n",
      "Epoch 66/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8407 - loss: 0.3622 - val_accuracy: 0.8269 - val_loss: 0.3814\n",
      "Epoch 67/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8394 - loss: 0.3610 - val_accuracy: 0.8241 - val_loss: 0.3834\n",
      "Epoch 68/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8411 - loss: 0.3619 - val_accuracy: 0.8269 - val_loss: 0.3815\n",
      "Epoch 69/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8404 - loss: 0.3600 - val_accuracy: 0.8255 - val_loss: 0.3825\n",
      "Epoch 70/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8414 - loss: 0.3608 - val_accuracy: 0.8272 - val_loss: 0.3817\n",
      "Epoch 71/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8433 - loss: 0.3571 - val_accuracy: 0.8270 - val_loss: 0.3818\n"
     ]
    }
   ],
   "source": [
    "model5 = keras.Sequential()\n",
    "model5.add(keras.layers.Embedding(8424, 128, input_shape = (13,)))\n",
    "model5.add(keras.layers.Dropout(0.4))\n",
    "\n",
    "model5.add(keras.layers.GRU(256, dropout = 0.4))\n",
    "\n",
    "model5.add(keras.layers.Dense(10, activation = \"relu\"))\n",
    "model5.add(keras.layers.BatchNormalization())\n",
    "model5.add(keras.layers.Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "adam = keras.optimizers.Adam(learning_rate =0.000005)\n",
    "model5.compile(loss = \"binary_crossentropy\", optimizer = adam, metrics = [\"accuracy\"])\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "\n",
    "history = model5.fit(train_seq, y_train, batch_size = 32, epochs = 1000, validation_data = (val_seq, y_val), callbacks = [early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "81f92009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8301 - loss: 0.3756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.37970301508903503, 0.827704131603241]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.evaluate(test_seq, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3c7dc5de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.5089 - loss: 0.7168 - val_accuracy: 0.6144 - val_loss: 0.6561\n",
      "Epoch 2/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.6077 - loss: 0.6507 - val_accuracy: 0.7080 - val_loss: 0.5693\n",
      "Epoch 3/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.6752 - loss: 0.5910 - val_accuracy: 0.7567 - val_loss: 0.5109\n",
      "Epoch 4/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.7178 - loss: 0.5463 - val_accuracy: 0.7789 - val_loss: 0.4736\n",
      "Epoch 5/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.7439 - loss: 0.5113 - val_accuracy: 0.7935 - val_loss: 0.4494\n",
      "Epoch 6/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.4863 - val_accuracy: 0.8004 - val_loss: 0.4325\n",
      "Epoch 7/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.7716 - loss: 0.4692 - val_accuracy: 0.8071 - val_loss: 0.4219\n",
      "Epoch 8/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.7824 - loss: 0.4564 - val_accuracy: 0.8118 - val_loss: 0.4152\n",
      "Epoch 9/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.7879 - loss: 0.4491 - val_accuracy: 0.8138 - val_loss: 0.4100\n",
      "Epoch 10/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.7948 - loss: 0.4360 - val_accuracy: 0.8158 - val_loss: 0.4063\n",
      "Epoch 11/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.7969 - loss: 0.4339 - val_accuracy: 0.8169 - val_loss: 0.4030\n",
      "Epoch 12/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.8051 - loss: 0.4204 - val_accuracy: 0.8175 - val_loss: 0.4009\n",
      "Epoch 13/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.8057 - loss: 0.4189 - val_accuracy: 0.8192 - val_loss: 0.3994\n",
      "Epoch 14/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.8089 - loss: 0.4153 - val_accuracy: 0.8196 - val_loss: 0.3979\n",
      "Epoch 15/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.8122 - loss: 0.4109 - val_accuracy: 0.8207 - val_loss: 0.3965\n",
      "Epoch 16/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8097 - loss: 0.4109 - val_accuracy: 0.8188 - val_loss: 0.3966\n",
      "Epoch 17/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.8135 - loss: 0.4102 - val_accuracy: 0.8196 - val_loss: 0.3954\n",
      "Epoch 18/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8141 - loss: 0.4099 - val_accuracy: 0.8167 - val_loss: 0.3969\n",
      "Epoch 19/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.8148 - loss: 0.4037 - val_accuracy: 0.8208 - val_loss: 0.3929\n",
      "Epoch 20/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8172 - loss: 0.4001 - val_accuracy: 0.8209 - val_loss: 0.3925\n",
      "Epoch 21/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8201 - loss: 0.3972 - val_accuracy: 0.8207 - val_loss: 0.3918\n",
      "Epoch 22/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8179 - loss: 0.3995 - val_accuracy: 0.8214 - val_loss: 0.3916\n",
      "Epoch 23/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8204 - loss: 0.3976 - val_accuracy: 0.8216 - val_loss: 0.3914\n",
      "Epoch 24/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8228 - loss: 0.3919 - val_accuracy: 0.8206 - val_loss: 0.3910\n",
      "Epoch 25/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8221 - loss: 0.3946 - val_accuracy: 0.8196 - val_loss: 0.3909\n",
      "Epoch 26/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8218 - loss: 0.3916 - val_accuracy: 0.8216 - val_loss: 0.3898\n",
      "Epoch 27/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8230 - loss: 0.3909 - val_accuracy: 0.8217 - val_loss: 0.3895\n",
      "Epoch 28/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8250 - loss: 0.3866 - val_accuracy: 0.8217 - val_loss: 0.3892\n",
      "Epoch 29/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8256 - loss: 0.3848 - val_accuracy: 0.8218 - val_loss: 0.3893\n",
      "Epoch 30/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8236 - loss: 0.3883 - val_accuracy: 0.8217 - val_loss: 0.3889\n",
      "Epoch 31/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8265 - loss: 0.3855 - val_accuracy: 0.8223 - val_loss: 0.3884\n",
      "Epoch 32/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8286 - loss: 0.3837 - val_accuracy: 0.8223 - val_loss: 0.3884\n",
      "Epoch 33/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8261 - loss: 0.3845 - val_accuracy: 0.8222 - val_loss: 0.3883\n",
      "Epoch 34/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8277 - loss: 0.3807 - val_accuracy: 0.8221 - val_loss: 0.3887\n",
      "Epoch 35/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8281 - loss: 0.3825 - val_accuracy: 0.8227 - val_loss: 0.3879\n",
      "Epoch 36/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8269 - loss: 0.3795 - val_accuracy: 0.8223 - val_loss: 0.3876\n",
      "Epoch 37/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8287 - loss: 0.3808 - val_accuracy: 0.8229 - val_loss: 0.3875\n",
      "Epoch 38/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8279 - loss: 0.3812 - val_accuracy: 0.8221 - val_loss: 0.3878\n",
      "Epoch 39/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8309 - loss: 0.3766 - val_accuracy: 0.8214 - val_loss: 0.3886\n",
      "Epoch 40/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8317 - loss: 0.3746 - val_accuracy: 0.8228 - val_loss: 0.3869\n",
      "Epoch 41/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8303 - loss: 0.3780 - val_accuracy: 0.8226 - val_loss: 0.3869\n",
      "Epoch 42/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8315 - loss: 0.3753 - val_accuracy: 0.8227 - val_loss: 0.3874\n",
      "Epoch 43/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8306 - loss: 0.3765 - val_accuracy: 0.8224 - val_loss: 0.3867\n",
      "Epoch 44/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8337 - loss: 0.3703 - val_accuracy: 0.8232 - val_loss: 0.3867\n",
      "Epoch 45/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8304 - loss: 0.3758 - val_accuracy: 0.8226 - val_loss: 0.3867\n",
      "Epoch 46/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8357 - loss: 0.3709 - val_accuracy: 0.8223 - val_loss: 0.3866\n",
      "Epoch 47/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8345 - loss: 0.3720 - val_accuracy: 0.8234 - val_loss: 0.3863\n",
      "Epoch 48/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8332 - loss: 0.3707 - val_accuracy: 0.8224 - val_loss: 0.3862\n",
      "Epoch 49/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8358 - loss: 0.3695 - val_accuracy: 0.8213 - val_loss: 0.3875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.8356 - loss: 0.3666 - val_accuracy: 0.8229 - val_loss: 0.3864\n",
      "Epoch 51/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.8339 - loss: 0.3693 - val_accuracy: 0.8223 - val_loss: 0.3867\n",
      "Epoch 52/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.8351 - loss: 0.3678 - val_accuracy: 0.8231 - val_loss: 0.3865\n",
      "Epoch 53/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.8362 - loss: 0.3657 - val_accuracy: 0.8231 - val_loss: 0.3869\n",
      "Epoch 54/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.8348 - loss: 0.3670 - val_accuracy: 0.8235 - val_loss: 0.3867\n",
      "Epoch 55/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.8355 - loss: 0.3672 - val_accuracy: 0.8238 - val_loss: 0.3866\n",
      "Epoch 56/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.8365 - loss: 0.3654 - val_accuracy: 0.8232 - val_loss: 0.3871\n",
      "Epoch 57/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8362 - loss: 0.3666 - val_accuracy: 0.8234 - val_loss: 0.3870\n",
      "Epoch 58/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.8370 - loss: 0.3625 - val_accuracy: 0.8228 - val_loss: 0.3873\n"
     ]
    }
   ],
   "source": [
    "model6 = keras.Sequential()\n",
    "model6.add(keras.layers.Embedding(4212, 128, input_shape = (13,)))\n",
    "model6.add(keras.layers.Dropout(0.4))\n",
    "\n",
    "model6.add(keras.layers.GRU(128, dropout = 0.4))\n",
    "\n",
    "model6.add(keras.layers.Dense(10, activation = \"relu\"))\n",
    "model6.add(keras.layers.BatchNormalization())\n",
    "model6.add(keras.layers.Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "adam = keras.optimizers.Adam(learning_rate =0.00001)\n",
    "model6.compile(loss = \"binary_crossentropy\", optimizer = adam, metrics = [\"accuracy\"])\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "\n",
    "history = model6.fit(train_seq, y_train, batch_size = 32, epochs = 1000, validation_data = (val_seq, y_val), callbacks = [early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6c37cbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8251 - loss: 0.3787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3823125660419464, 0.8238707184791565]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6.evaluate(test_seq, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2a8b7659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.6509 - loss: 0.6038 - val_accuracy: 0.7919 - val_loss: 0.4399\n",
      "Epoch 2/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.7839 - loss: 0.4530 - val_accuracy: 0.8033 - val_loss: 0.4220\n",
      "Epoch 3/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.7979 - loss: 0.4325 - val_accuracy: 0.8070 - val_loss: 0.4156\n",
      "Epoch 4/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8077 - loss: 0.4232 - val_accuracy: 0.8059 - val_loss: 0.4168\n",
      "Epoch 5/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8071 - loss: 0.4198 - val_accuracy: 0.8083 - val_loss: 0.4120\n",
      "Epoch 6/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8114 - loss: 0.4130 - val_accuracy: 0.8122 - val_loss: 0.4078\n",
      "Epoch 7/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8130 - loss: 0.4110 - val_accuracy: 0.8120 - val_loss: 0.4069\n",
      "Epoch 8/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8142 - loss: 0.4071 - val_accuracy: 0.8136 - val_loss: 0.4060\n",
      "Epoch 9/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8163 - loss: 0.4046 - val_accuracy: 0.8152 - val_loss: 0.4026\n",
      "Epoch 10/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8193 - loss: 0.4016 - val_accuracy: 0.8150 - val_loss: 0.4022\n",
      "Epoch 11/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8181 - loss: 0.3995 - val_accuracy: 0.8153 - val_loss: 0.4000\n",
      "Epoch 12/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8192 - loss: 0.4002 - val_accuracy: 0.8124 - val_loss: 0.4054\n",
      "Epoch 13/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8191 - loss: 0.4010 - val_accuracy: 0.8174 - val_loss: 0.3969\n",
      "Epoch 14/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8212 - loss: 0.3955 - val_accuracy: 0.8183 - val_loss: 0.3950\n",
      "Epoch 15/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8227 - loss: 0.3903 - val_accuracy: 0.8180 - val_loss: 0.3947\n",
      "Epoch 16/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8228 - loss: 0.3923 - val_accuracy: 0.8187 - val_loss: 0.3936\n",
      "Epoch 17/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.8245 - loss: 0.3904 - val_accuracy: 0.8194 - val_loss: 0.3920\n",
      "Epoch 18/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8266 - loss: 0.3853 - val_accuracy: 0.8205 - val_loss: 0.3907\n",
      "Epoch 19/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8278 - loss: 0.3848 - val_accuracy: 0.8194 - val_loss: 0.3915\n",
      "Epoch 20/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8253 - loss: 0.3878 - val_accuracy: 0.8228 - val_loss: 0.3879\n",
      "Epoch 21/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8280 - loss: 0.3844 - val_accuracy: 0.8231 - val_loss: 0.3887\n",
      "Epoch 22/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8283 - loss: 0.3820 - val_accuracy: 0.8235 - val_loss: 0.3869\n",
      "Epoch 23/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8298 - loss: 0.3824 - val_accuracy: 0.8240 - val_loss: 0.3871\n",
      "Epoch 24/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8313 - loss: 0.3780 - val_accuracy: 0.8225 - val_loss: 0.3872\n",
      "Epoch 25/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8312 - loss: 0.3770 - val_accuracy: 0.8236 - val_loss: 0.3857\n",
      "Epoch 26/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8331 - loss: 0.3762 - val_accuracy: 0.8246 - val_loss: 0.3848\n",
      "Epoch 27/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8316 - loss: 0.3767 - val_accuracy: 0.8255 - val_loss: 0.3834\n",
      "Epoch 28/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8328 - loss: 0.3760 - val_accuracy: 0.8252 - val_loss: 0.3830\n",
      "Epoch 29/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8330 - loss: 0.3727 - val_accuracy: 0.8253 - val_loss: 0.3821\n",
      "Epoch 30/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8310 - loss: 0.3767 - val_accuracy: 0.8257 - val_loss: 0.3822\n",
      "Epoch 31/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8353 - loss: 0.3710 - val_accuracy: 0.8249 - val_loss: 0.3820\n",
      "Epoch 32/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8355 - loss: 0.3720 - val_accuracy: 0.8256 - val_loss: 0.3806\n",
      "Epoch 33/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8377 - loss: 0.3692 - val_accuracy: 0.8265 - val_loss: 0.3812\n",
      "Epoch 34/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8348 - loss: 0.3702 - val_accuracy: 0.8267 - val_loss: 0.3809\n",
      "Epoch 35/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8378 - loss: 0.3658 - val_accuracy: 0.8271 - val_loss: 0.3807\n",
      "Epoch 36/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8359 - loss: 0.3695 - val_accuracy: 0.8254 - val_loss: 0.3834\n",
      "Epoch 37/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8393 - loss: 0.3647 - val_accuracy: 0.8268 - val_loss: 0.3800\n",
      "Epoch 38/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8363 - loss: 0.3694 - val_accuracy: 0.8260 - val_loss: 0.3781\n",
      "Epoch 39/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8402 - loss: 0.3649 - val_accuracy: 0.8265 - val_loss: 0.3783\n",
      "Epoch 40/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8397 - loss: 0.3653 - val_accuracy: 0.8262 - val_loss: 0.3781\n",
      "Epoch 41/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8387 - loss: 0.3666 - val_accuracy: 0.8270 - val_loss: 0.3790\n",
      "Epoch 42/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8409 - loss: 0.3637 - val_accuracy: 0.8266 - val_loss: 0.3773\n",
      "Epoch 43/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8425 - loss: 0.3617 - val_accuracy: 0.8274 - val_loss: 0.3764\n",
      "Epoch 44/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8378 - loss: 0.3628 - val_accuracy: 0.8272 - val_loss: 0.3765\n",
      "Epoch 45/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8402 - loss: 0.3649 - val_accuracy: 0.8280 - val_loss: 0.3769\n",
      "Epoch 46/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8426 - loss: 0.3605 - val_accuracy: 0.8257 - val_loss: 0.3781\n",
      "Epoch 47/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8421 - loss: 0.3577 - val_accuracy: 0.8273 - val_loss: 0.3772\n",
      "Epoch 48/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8422 - loss: 0.3584 - val_accuracy: 0.8271 - val_loss: 0.3767\n",
      "Epoch 49/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8427 - loss: 0.3597 - val_accuracy: 0.8278 - val_loss: 0.3774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8417 - loss: 0.3580 - val_accuracy: 0.8280 - val_loss: 0.3778\n",
      "Epoch 51/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8434 - loss: 0.3566 - val_accuracy: 0.8271 - val_loss: 0.3785\n",
      "Epoch 52/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8424 - loss: 0.3592 - val_accuracy: 0.8279 - val_loss: 0.3756\n",
      "Epoch 53/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8434 - loss: 0.3577 - val_accuracy: 0.8280 - val_loss: 0.3748\n",
      "Epoch 54/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8436 - loss: 0.3577 - val_accuracy: 0.8286 - val_loss: 0.3745\n",
      "Epoch 55/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8439 - loss: 0.3574 - val_accuracy: 0.8277 - val_loss: 0.3775\n",
      "Epoch 56/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8455 - loss: 0.3539 - val_accuracy: 0.8281 - val_loss: 0.3736\n",
      "Epoch 57/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8448 - loss: 0.3556 - val_accuracy: 0.8296 - val_loss: 0.3758\n",
      "Epoch 58/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8433 - loss: 0.3564 - val_accuracy: 0.8296 - val_loss: 0.3765\n",
      "Epoch 59/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8453 - loss: 0.3563 - val_accuracy: 0.8295 - val_loss: 0.3740\n",
      "Epoch 60/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8456 - loss: 0.3532 - val_accuracy: 0.8303 - val_loss: 0.3745\n",
      "Epoch 61/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8472 - loss: 0.3525 - val_accuracy: 0.8290 - val_loss: 0.3788\n",
      "Epoch 62/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3489 - val_accuracy: 0.8293 - val_loss: 0.3747\n",
      "Epoch 63/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8496 - loss: 0.3502 - val_accuracy: 0.8290 - val_loss: 0.3750\n",
      "Epoch 64/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8456 - loss: 0.3546 - val_accuracy: 0.8300 - val_loss: 0.3764\n",
      "Epoch 65/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8464 - loss: 0.3512 - val_accuracy: 0.8279 - val_loss: 0.3766\n",
      "Epoch 66/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8433 - loss: 0.3565 - val_accuracy: 0.8295 - val_loss: 0.3744\n"
     ]
    }
   ],
   "source": [
    "model7 = keras.Sequential()\n",
    "model7.add(keras.layers.Embedding(4212, 64, input_shape = (13,)))\n",
    "model7.add(keras.layers.Dropout(0.3))\n",
    "\n",
    "model7.add(keras.layers.GRU(64, dropout = 0.3))\n",
    "\n",
    "model7.add(keras.layers.Dense(10, activation = \"relu\"))\n",
    "model7.add(keras.layers.BatchNormalization())\n",
    "model7.add(keras.layers.Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "rmsprop = keras.optimizers.RMSprop(learning_rate = 0.0001)\n",
    "model7.compile(optimizer = rmsprop, loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "\n",
    "history7 = model7.fit(train_seq, y_train, batch_size = 32, epochs = 1000,\n",
    "                    validation_data = (val_seq, y_val), callbacks = [early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cf3c5bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829us/step - accuracy: 0.8335 - loss: 0.3695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.37350139021873474, 0.8318275809288025]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7.evaluate(test_seq, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e4060c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e915eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb9622e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0c4cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3335e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ec92afe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.7642 - loss: 0.4716 - val_accuracy: 0.8210 - val_loss: 0.3902\n",
      "Epoch 2/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.8306 - loss: 0.3734 - val_accuracy: 0.8297 - val_loss: 0.3735\n",
      "Epoch 3/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.8393 - loss: 0.3573 - val_accuracy: 0.8298 - val_loss: 0.3737\n",
      "Epoch 4/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.8472 - loss: 0.3434 - val_accuracy: 0.8347 - val_loss: 0.3636\n",
      "Epoch 5/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.8546 - loss: 0.3312 - val_accuracy: 0.8360 - val_loss: 0.3619\n",
      "Epoch 6/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.8572 - loss: 0.3269 - val_accuracy: 0.8380 - val_loss: 0.3626\n",
      "Epoch 7/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.8600 - loss: 0.3183 - val_accuracy: 0.8373 - val_loss: 0.3630\n",
      "Epoch 8/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.8658 - loss: 0.3106 - val_accuracy: 0.8359 - val_loss: 0.3606\n",
      "Epoch 9/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.8716 - loss: 0.3005 - val_accuracy: 0.8347 - val_loss: 0.3682\n",
      "Epoch 10/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.8734 - loss: 0.2962 - val_accuracy: 0.8374 - val_loss: 0.3655\n",
      "Epoch 11/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.8776 - loss: 0.2866 - val_accuracy: 0.8327 - val_loss: 0.3760\n",
      "Epoch 12/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.8824 - loss: 0.2777 - val_accuracy: 0.8336 - val_loss: 0.3786\n",
      "Epoch 13/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.8869 - loss: 0.2725 - val_accuracy: 0.8337 - val_loss: 0.3810\n",
      "Epoch 14/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.8905 - loss: 0.2609 - val_accuracy: 0.8334 - val_loss: 0.3864\n",
      "Epoch 15/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.8942 - loss: 0.2547 - val_accuracy: 0.8295 - val_loss: 0.3967\n",
      "Epoch 16/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.8969 - loss: 0.2488 - val_accuracy: 0.8300 - val_loss: 0.4063\n",
      "Epoch 17/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.9029 - loss: 0.2379 - val_accuracy: 0.8276 - val_loss: 0.4152\n",
      "Epoch 18/1000\n",
      "\u001b[1m3583/3583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.9061 - loss: 0.2276 - val_accuracy: 0.8260 - val_loss: 0.4229\n"
     ]
    }
   ],
   "source": [
    "train_seq = pad_sequences(x_train, maxlen = 33)\n",
    "val_seq = pad_sequences(x_val, maxlen = 33)\n",
    "test_seq = pad_sequences(x_test, maxlen = 33)\n",
    "\n",
    "model2 = keras.Sequential()\n",
    "model2.add(keras.layers.Embedding(5000, 32, input_shape = (33,)))\n",
    "\n",
    "model2.add(keras.layers.GRU(64))\n",
    "\n",
    "model2.add(keras.layers.Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "rmsprop = keras.optimizers.RMSprop(learning_rate = 0.001)\n",
    "model2.compile(optimizer = rmsprop, loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "\n",
    "history2 = model2.fit(train_seq, y_train, batch_size = 32, epochs = 1000,\n",
    "                    validation_data = (val_seq, y_val), callbacks = [early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "df4e05f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1509/1509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8406 - loss: 0.3578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3619956970214844, 0.8389349579811096]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(test_seq, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
