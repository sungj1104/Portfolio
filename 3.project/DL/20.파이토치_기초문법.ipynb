{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0de70cf0",
   "metadata": {},
   "source": [
    "# 텐서\n",
    "\n",
    "- 파이토치는 텐서로 시작해서 텐서로 끝남\n",
    "- 텐서를 잘 다룰 수 있어야 신경망에서 데이터 입력과 출력을 제어할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2192b187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60abaab6",
   "metadata": {},
   "source": [
    "## 텐서 생성 및 변환\n",
    "\n",
    "- 텐서는 파이토치의 가장 기본이 되는 데이터 구조\n",
    "- numpy의 다차원 배열과 비슷하며 GPU에서도 연산 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea6aa5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2차원 텐서 생성\n",
    "torch.tensor([[1, 2],\n",
    "             [3, 4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c792f1e",
   "metadata": {},
   "source": [
    "- gpu가 있다면\n",
    "    - torch.tensor([[1, 2], [3, 4]], device = \"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9764a717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dtype을 이용하여 텐서 생성\n",
    "torch.tensor([[1, 2],\n",
    "             [3, 4]], dtype = torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb117ee6",
   "metadata": {},
   "source": [
    "### 텐서를 ndarray로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1862861",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = torch.tensor([[1, 2], [3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc38eb20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ndarray로 변환\n",
    "temp.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e150d767",
   "metadata": {},
   "source": [
    "- gpu가 있다면 gpu상의 텐서를 cpu의 텐서로 변환한 후 ndarrya로 변환\n",
    "    - temp = torch.tensor([[1, 2], [3, 4], device = \"cuda:0\"])\n",
    "    - temp.to(\"cpu\").numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9eb3c71",
   "metadata": {},
   "source": [
    "## 텐서의 인덱스 조작\n",
    "\n",
    "- 텐서는 넘파이의 다차원배열과 유사하게 동작하기 때문에 배열처럼 인덱스를 바로 지정하거나 슬라이스 등을 사용할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64548330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5., 6., 7.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파이토치로 1차원 벡터 생성\n",
    "temp = torch.FloatTensor([1, 2, 3, 4, 5, 6, 7])\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af0054e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.), tensor(2.), tensor(7.))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인덱스로 접근\n",
    "temp[0], temp[1], temp[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cb7ec9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3., 4., 5.]), tensor([5., 6.]), tensor([2.]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 슬라이스로 접근\n",
    "temp[2:5], temp[4:-1], temp[1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88645b84",
   "metadata": {},
   "source": [
    "## 텐서 연산\n",
    "\n",
    "- 텐서는 넘파이의 다차원배열처럼 다양한 수학 연산이 가능하며, gpu를 사용하면 더 빠르게 연산할 수 있음\n",
    "- 단, 텐서 간의 타입이 다르면 연산이 불가\n",
    "    - 예) FloatTensor(32비트의 부동 소수점)와 DoubleTensor(64비트의 부동 소수점) 간에 사칙 연산을 수행하면 오류 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61439f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 길이가 3인 벡터 생성\n",
    "v = torch.tensor([1, 2, 3])\n",
    "w = torch.tensor([3, 4, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7aaf9d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# 길이가 같은 벡터 간 뺄셈 연산\n",
    "print(w - v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facf8cd6",
   "metadata": {},
   "source": [
    "## 텐서의 차원 조작\n",
    "\n",
    "- 텐서의 차원을 변경하는 명령어\n",
    "    - view : 넘파이의 reshape와 유사\n",
    "    - cat : 다른 길이의 텐서를 하나로 병합\n",
    "    - transpose : 행렬의 전치 또는 차원의 순서 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a25ed597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2x2 행렬 생성\n",
    "temp = torch.tensor([\n",
    "    [1, 2], [3, 4]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97e72c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "433fa14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2x2 행렬을 4x1로 변경\n",
    "temp.view(4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10906689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2x2 행렬을 1차원 벡터로 변형\n",
    "temp.view(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d1203c",
   "metadata": {},
   "source": [
    "- -1은 다른 차원으로부터 해당 값을 유추하겠다는 뜻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aab31601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1643529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3fb6e7",
   "metadata": {},
   "source": [
    "# 데이터로더\n",
    "\n",
    "- torch.utils.data.DataLoader는 학습에 사용될 데이터 전체를 보관했다가 모델 학습을 할 때 배치 크기만큼 데이터를 꺼내서 사용\n",
    "\n",
    "- 주의할 점은 미리 데이터를 잘라 놓는 것이 아니라 내부적으로 이터레이터에 포함된 인덱스를 이용하여 배치 크기만큼 데이터를 반환\n",
    "\n",
    "<img src = \"./image/dataloader.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51508523",
   "metadata": {},
   "source": [
    "# 파이토치 데이터셋 사용\n",
    "\n",
    "- torchvision은 파이토치에서 제공하는 데이터셋이 모여있는 패키지\n",
    "- 파이토치 데이터셋을 다운로드 받으려면 requests 라이브러리 설치가 필요\n",
    "    - HTTP 요청을 하기 위함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d341e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06484356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균이 0.5, 표준편차가 1.0이 되도록 데이터의 분포를 정규화\n",
    "mnist_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (1.0,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "515d0e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST_DATASET\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 9912422/9912422 [00:01<00:00, 8690495.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST_DATASET\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data/MNIST_DATASET\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST_DATASET\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 28881/28881 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST_DATASET\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data/MNIST_DATASET\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST_DATASET\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 1648877/1648877 [00:00<00:00, 5569377.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST_DATASET\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data/MNIST_DATASET\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST_DATASET\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 4542/4542 [00:00<00:00, 4536920.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST_DATASET\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data/MNIST_DATASET\\MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = \"./data/MNIST_DATASET\"\n",
    "\n",
    "train_dataset = MNIST(data_path, transform = mnist_transform, train = True, download = True)\n",
    "test_dataset = MNIST(data_path, transform = mnist_transform, train = False, download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28d242db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.MNIST"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50544d4",
   "metadata": {},
   "source": [
    "# 모델 정의\n",
    "\n",
    "- 파이토치에서 모델을 정의하기 위해서는 Module 를 상속한 클래스를 사용\n",
    "    - layer : 모듈 또는 모듈을 구성하는 한 개의 계층\n",
    "        - 예) 합성곱층, 선형계층 등\n",
    "    - module : 한 개 이상의 계층이 모여서 구성된 것, 모듈이 모여 새로운 모듈을 만들 수도 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adfc41e",
   "metadata": {},
   "source": [
    "## nn.Module()을 상속하여 정의하는 방법\n",
    "\n",
    "- 파이토치에서 nn.Module를 상속받는 모델은 기본적으로 \\_\\_init__() 과 forward() 함수를 포함\n",
    "    - \\_\\_init__() 에서는 모델에서 사용될 모듈, 활성화 함수 등을 정의\n",
    "    - forward() 함수에서는 모델에서 실행되어야 하는 연산을 정의\n",
    "    \n",
    "- nn.Sequential 을 사용하면 \\_\\_init__() 에서 사용할 네트워크 모델들을 정의해줄 뿐만 아니라 forward() 함수에서 모델에서 실행되어야 할 계산을 좀 더 가독성이 뛰어나게 코드로 작성할 수 있음\n",
    "- 또한, Sequential 객체에는 그 안에 포함된 각 모듈을 순차적으로 실행해 줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37183bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9fc802d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 5),\n",
    "            nn.ReLU(inplace = True),\n",
    "            # input으로 들어온 값 자체를 수정, 메모리효율이 좋아지지만 input 값이 사라짐(파괴적)\n",
    "            nn.MaxPool2d(2))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 30, kernel_size = 5),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.MaxPool2d(2))\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(in_features = 750, out_features = 10, bias = True),\n",
    "            nn.ReLU(inplace = True))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.layer3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd2e7995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 객체 생성\n",
    "model = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49eb40bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sequential(\n",
       "   (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1))\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Linear(in_features=750, out_features=10, bias=True)\n",
       "   (1): ReLU(inplace=True)\n",
       " )]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b74641f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MLP(\n",
       "   (layer1): Sequential(\n",
       "     (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   )\n",
       "   (layer2): Sequential(\n",
       "     (0): Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1))\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   )\n",
       "   (layer3): Sequential(\n",
       "     (0): Linear(in_features=750, out_features=10, bias=True)\n",
       "     (1): ReLU(inplace=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       " ),\n",
       " Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " Sequential(\n",
       "   (0): Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1))\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       " ),\n",
       " Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " Sequential(\n",
       "   (0): Linear(in_features=750, out_features=10, bias=True)\n",
       "   (1): ReLU(inplace=True)\n",
       " ),\n",
       " Linear(in_features=750, out_features=10, bias=True),\n",
       " ReLU(inplace=True)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델의 네트워크에 대한 모든 노드를 반환\n",
    "list(model.modules())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa0a64a",
   "metadata": {},
   "source": [
    "### 함수로 신경망 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4089b3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP(in_features = 1, hidden_features = 20, out_features = 1):\n",
    "    hidden = nn.Linear(in_features = in_features, out_features = hidden_features, bias = True)\n",
    "    activation = nn.ReLU()\n",
    "    output = nn.Linear(in_features = hidden_features, out_features = out_features, bias = True)\n",
    "    net = nn.Sequential(hidden, activation, output)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5403cff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = MLP(in_features = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e5d05a",
   "metadata": {},
   "source": [
    "- output_tensor = mlp_model(입력값)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bb3da9",
   "metadata": {},
   "source": [
    "# 모델 파라미터 정의\n",
    "\n",
    "- 손실 함수(loss function)\n",
    "    - 학습하는 동안 출력과 실제 값(정답) 사이의 오차를 측정\n",
    "    - wx + b 를 계산한 값과 실제 값 y의 오차를 구해서 모델의 정확성을 측정\n",
    "    - 자주 사용되는 손실 함수\n",
    "        - BCELoss : 이진 분류를 위해 사용\n",
    "        - CrossEntropyLoss : 다중 클래스 분류를 위해 사용\n",
    "        - MSELoss : 회귀 모델에서 사용\n",
    "        \n",
    "- 옵티마이저(optimizer)\n",
    "    - 데이터와 손실함수를 바탕으로 모델의 업데이트 방법을 결정\n",
    "    - 옵티마이저의 주요 특성\n",
    "        - optimizer는 step() 메서드를 통해 전달받은 파라미터를 업데이트\n",
    "        - 모델의 파라미터별로 다른 기준을 적용시킬 수 있음\n",
    "        - torch.optim.Optimizer(params, defaults)는 모든 옵티마이저의 기본이 되는 클래스\n",
    "        - zero_grad() 메서드는 옵티마이저에 사용된 파라미터들의 기울기를 0으로 초기화\n",
    "        - torch.optim.lr_scheduler 는 에포크에 따라 학습률을 조절할 수 있음\n",
    "        \n",
    "- 학습률 스케줄러(learning rate scheduler)\n",
    "    - 미리 지정한 횟수의 에포크를 지날 때 마다 학습률을 감소시킴\n",
    "    - 학습률 스케줄러를 이용하면 학습 초기에는 빠른 학습을 진행하다가 전역 최소점(global minimum) 근처에 다다르면 학습률을 줄여서 최적점을 찾아갈 수 있도록 함\n",
    "    - 학습률 스케줄러의 종류\n",
    "        - optim.lr_scheduler.LambdaLR : 람다 함수를 이용하여 그 함수의 결과를 학습률로 설정\n",
    "        - optim.lr_scheduler.StepLR : 특정 단계(step)마다 학습률을 감마 비율만큼 감소\n",
    "        - optim.lr_scheduler.MultiStepLR : StepLR 과 비슷하지만 특정 단계가 아닌 지정된 에포크에만 감마 비율로 감소시킴\n",
    "        - optim.lr_scheduler.ExponentialLR : 에포크마다 이전 학습률에 감마만큼 곱함\n",
    "        - optim.lr_scheduler.CosineAnnealingLR : 학습률을 코사인 함수의 형태처럼 변화시킴, 학습률이 커지기도 작아지기도 함\n",
    "        - optim.lr_scheduler.ReduceLROnPlateau : 학습이 잘되고 있는지 아닌지에 따라 동적으로 학습률을 변화\n",
    "        \n",
    "- 지표(metrics)\n",
    "    - 훈련과 테스트 단계를 모니터링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97095671",
   "metadata": {},
   "source": [
    "## 전역 최소점과 최적점\n",
    "\n",
    "<img src = \"./image/minimum.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf09a30c",
   "metadata": {},
   "source": [
    "- 손실 함수는 실제 값과 예측값 차이를 수치화해주는 함수\n",
    "- 이 오차 값이 클수록 손실 함수의 값이 크고, 오차 값이 작을수록 손실함수의 값이 작아짐\n",
    "- 손실 함수의 값을 최소화하는 가중치와 바이어스를 찾는 것이 모델 학습의 목표\n",
    "- 전역 최소점(global minimum)은 오차가 가장 작을 대의 값을 의미하므로 우리가 최종적으로 찾고자 하는 것. 최적점\n",
    "- 지역 최소점(local minimum)은 전역 최소점을 찾아가는 과정에서 만나는 홀(hole)과 같은 것으로 옵티마이저가 지역 최소점에서 학습을 멈추면 최솟값을 찾는 오차를 찾을 수 없는 문제가 발생"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae91a87",
   "metadata": {},
   "source": [
    "# 모델 훈련\n",
    "\n",
    "- 모델을 학습시킨다는 것은 y = wx + b 라는 함수에서 w와 b의 적절한 값을 찾는다는 의미\n",
    "- w와 b에 임의의 값을 적용하여 시작하며 오차가 줄어들어 전역 최소점에 이를 때까지 파라미터(w, b)를 계속 수정\n",
    "- 딥러닝 학습 절차\n",
    "    1. 모델, 손실 함수, 옵티마이저 정의\n",
    "    2. 전방향 학습(입력 -> 출력 계산)\n",
    "    3. 손실 함수로 출력과 정답의 차이(오차) 계산\n",
    "    4. 역전파 학습(기울기 계산)\n",
    "    5. 기울기 업데이트\n",
    "    \n",
    "- 파이토치 학습 절차\n",
    "    1. 모델, 손실 함수, 옵티마이저 정의\n",
    "        - optimizer.zero_grad() : 기울기 초기화\n",
    "            - 파이토치는 기울기 값을 계산하기 위해 loss.backward() 메서드를 사용하는데, 이 때 새로운 기울기 값이 이전 기울기 값에 누적하여 계산됨\n",
    "            - 기울기 누적은 순환 신경망을 구현할 때 효과적이지만 누적 계산이 필요하지 않는 모델에서는 불필요함\n",
    "            - 따라서 기울기 누적 계산이 필요하지 않을 때는 입력값을 모델에 적용하기 전에 미분값이 누적되지 않게 초기화해야 함\n",
    "    2. output = model(input) : 출력 계산\n",
    "    3. loss = loss_fn(output, target) : 오차 계산\n",
    "    4. loss.backward() : 역전파 학습\n",
    "    5. optimizer.step() : 기울기 업데이트"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
