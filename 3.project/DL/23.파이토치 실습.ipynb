{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8260df11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e665f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.MNIST(\n",
    "    root = \"./data/\",\n",
    "    train= True,\n",
    "    download = True,\n",
    "    transform = transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "testset = datasets.MNIST(\n",
    "    root = \"./data/\",\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c034c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size = 100)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "287be52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3d0c04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류 클래스 정의\n",
    "labels_map = {0 : \"0\", 1 : \"1\", 2 : \"2\", 3 : \"3\", 4 : \"4\",\n",
    "             5 : \"5\", 6 : \"6\", 7 : \"7\", 8 : \"8\", 9 : \"9\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc26cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU 혹은 GPU 장치 확인\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "056fb342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(labels_map[trainset[0][1]])\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(trainset[0][0][0, :, :], cmap = \"gray\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2096d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset[1][0][0]), len(trainset[1][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dfc0672",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumberCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        # 데이터 크기 28 * 28\n",
    "        super().__init__()\n",
    "        # Sequential 은 forward 함수에서 구현될 순전파를 계층 형태로 더 가독성 있게 만들어줌\n",
    "        # 즉, 계층을 차례대로 쌓을 수 있도록 Wx + b와 같은 수식과 활성화 함수를 연결해주는 역할\n",
    "        # 데이터가 각 계층을 순차적으로 지나갈 때 효과적\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 1, out_channels = 32, kernel_size = 3, padding = 1),\n",
    "            # (28 - 3 + 2 * 1)/1 + 1 = 28\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "            # 28 / 2 = 14\n",
    "        )\n",
    "        self.fc1 = nn.Linear(in_features = 32 * 14 * 14, out_features = 50)\n",
    "        self.drop = nn.Dropout2d(0.25)\n",
    "        self.fc2 = nn.Linear(in_features = 50, out_features = 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "016451b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumberCNN(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=6272, out_features=50, bias=True)\n",
      "  (drop): Dropout2d(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 합성곱 신경망 파라미터 정의\n",
    "learning_rate = 0.0001\n",
    "model = NumberCNN() # 위에서 만든 class를 객체화\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # 손실 함수\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate) # adam\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "271164dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500, Loss: 0.24813717603683472, Accuracy: 94.37000274658203%\n",
      "Iteration: 1000, Loss: 0.17240934073925018, Accuracy: 95.88999938964844%\n",
      "Iteration: 1500, Loss: 0.11079028993844986, Accuracy: 96.37000274658203%\n",
      "Iteration: 2000, Loss: 0.07426141202449799, Accuracy: 96.88999938964844%\n",
      "Iteration: 2500, Loss: 0.025752639397978783, Accuracy: 97.13999938964844%\n",
      "Iteration: 3000, Loss: 0.15908658504486084, Accuracy: 97.36000061035156%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "predictions_list = []\n",
    "labels_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # 모델이 데이터를 처리하기 위해서는 모델과 데이터가 동일한 장치에 있어야 함\n",
    "        \n",
    "        train = Variable(images.view(100, 1, 28, 28))\n",
    "        test = Variable(labels)\n",
    "        # Autograd는 자동 미분을 수행하는 파이토치의 핵심 패키지\n",
    "        # 자동 미분에 대한 값을 저장\n",
    "        \n",
    "        outputs = model(train)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        count += 1\n",
    "        \n",
    "        if not (count % 50):\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                labels_list.append(labels)\n",
    "                \n",
    "                test = Variable(images.view(100, 1, 28, 28))\n",
    "                outputs = model(test)\n",
    "                predictions = torch.max(outputs, 1)[1].to(device)\n",
    "                predictions_list.append(predictions)\n",
    "                correct += (predictions == labels).sum()\n",
    "                total += len(labels)\n",
    "                \n",
    "            accuracy = correct * 100 / total\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "            accuracy_list.append(accuracy)\n",
    "            \n",
    "        if not (count % 500):\n",
    "            print(f\"Iteration: {count}, Loss: {loss.data}, Accuracy: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57ae961",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
